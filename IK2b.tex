%% LyX 2.0.5.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,ngerman,english]{scrreprt}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2.6cm,bmargin=3.5cm,lmargin=2.6cm,rmargin=2.6cm}
\usepackage{fancyhdr}
\pagestyle{fancy}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{color}
\usepackage{babel}
\usepackage{longtable}
\usepackage{textcomp}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{esint}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=false,
 breaklinks=true,pdfborder={0 0 0},backref=page,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Theoretical Solid State and Statistical Physics},
 pdfauthor={Andreas Völklein},
 pdfkeywords={Solid State, Statistical Physics, Physics}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}
\newcommand{\noun}[1]{\textsc{#1}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\usepackage{enumitem}		% customizable list environments
\newlength{\lyxlabelwidth}      % auxiliary length 

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{tikz,pgfplots}
%\usepackage{tikz-3dplot,cancel,polynom}
\usetikzlibrary{matrix,arrows,calc,decorations,decorations.pathmorphing,intersections}
\usetikzlibrary{external}
\tikzexternalize
\usepackage{latexsym,stmaryrd,stackrel,braket,bbm,subfig,framed,booktabs,esvect,scrhack,calc}
\usepackage [OMLmathrm,OMLmathbf,sfdefault=fav]{isomath}
\usepackage[explicit]{titlesec}
\usepackage[activate]{pdfcprot}

\pgfkeys{/pgf/number format/dec sep={\text{,}}}

% Inhaltsverzeichnis
\usepackage[subfigure]{tocloft}

\tocloftpagestyle{fancy}

\renewcommand{\cftchapindent}{1 em}
\renewcommand{\cftchapnumwidth}{1.5 em}

\renewcommand{\cftsecindent}{2.7 em}
\renewcommand{\cftsecnumwidth}{2.5em}

\renewcommand{\cftsubsecindent}{5.2 em}
\renewcommand{\cftsubsecnumwidth}{3.8 em}

\renewcommand{\cftsubsubsecindent}{9 em}
\renewcommand{\cftsubsubsecnumwidth}{4.5 em}

% Mathe-Operatoren
\DeclareMathOperator*{\exsop}{\exists}
\DeclareMathOperator*{\exsgop}{\exists!}
\DeclareMathOperator*{\fallop}{\forall}
\DeclareMathOperator*{\bcupdop}{\dot{\bigcup}}
\DeclareMathOperator*{\bcapdop}{\dot{\bigcap}}

%Operatornorm
\newcommand{\opnor}[1]{\abs{\hspace*{-1.1pt}\norm{#1}\hspace*{-1.1pt}}}

% nicht-totales Differential
\newcommand{\dBar}{\hspace*{1.5pt}\mathchar'26\mkern-12mu \textnormal{d}\hspace*{1.5pt}}

% Angström
\newcommand{\ang}{\textup{\AA}}

% schöne Vektorpfeile
\renewcommand{\vec}[1]{\vv{#1}}

% Rotieren
\newcommand{\Rotate}[1]{
\begin{tikzpicture}
\node[rotate=90] {\ensuremath{#1}};
\end{tikzpicture}
}

%QED-Zeichen (Box)
\newcommand{\qed}{\ensuremath{\Box}}
\newcommand{\qqed}[1][\arabic{chapter}.\arabic{section}\ifnum\arabic{subsection}>0{.\arabic{subsection}}\fi]{\hfill\qed\ensuremath{_{\text{#1}}}}

% Mengen Modulo
\newcommand{\moduloT}[2]{
\mbox{\raisebox{0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large /}
\raisebox{-0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Links Modulo
\newcommand{\lmoduloT}[2]{
\mbox{\raisebox{-0.6ex}{\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\Large \ensuremath{\backslash}}
\raisebox{0.6ex}{\hspace*{-1.5mm}\ensuremath{\displaystyle #2}}
}}

% Für Z/2Z, um nicht soviel schreiben zu müssen
\newcommand{\modloT}[2]{\moduloT{ \mathbb{#1}}{#2\mathbb{#1}}}

%Die Modulo-Kommandos in klein, für die Darstellungen unter Quantoren.
\newcommand{\moduloScriptT}[2]{
\mbox{\raisebox{0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize /}
\raisebox{-0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\lmoduloScriptT}[2]{
\mbox{\raisebox{-0.4ex}{\scriptsize\ensuremath{\displaystyle #1}}
{\hspace*{-1.5mm}\footnotesize \ensuremath{\backslash}}
\raisebox{0.4ex}{\hspace*{-1.5mm}\scriptsize\ensuremath{\displaystyle #2}}
}}

\newcommand{\modloScriptT}[2]{\moduloScriptT{ \mathbb{#1}}{#2\mathbb{#1}}}

% Wurzel mit Häkchen
\newcommand{\hsqrt}[2][{}]{\setbox0=\hbox{$\sqrt[#1]{\phantom{|}\!\! #2\hspace*{1pt}}$}\dimen0=\ht0
  \advance\dimen0-0.2\ht0
  \setbox2=\hbox{\vrule height\ht0 depth -\dimen0}
  {\box0\lower0.4pt\box2}}

% Damit nicht immer "Kapitel 1" etc. über der Kapitelüberschrift steht
\titleformat{\chapter}
  {\huge\bfseries}
  {\textrm{\thechapter} }{0pt}
  {\textrm{#1} \thispagestyle{fancy}
  }

% Neudefinition der Abschnittsmarker für die Kopfzeile
\renewcommand\partmark[1]{\markboth{#1}{}}
\renewcommand\chaptermark[1]{\markright{\arabic{chapter} #1}}
\renewcommand\sectionmark[1]{}
\renewcommand\subsectionmark[1]{}

% Schriften auf Serif umstellen
\addtokomafont{descriptionlabel}{\rmfamily}
\addtokomafont{disposition}{\rmfamily}

% Zeilenumbrüche in Gleichungen
 \allowdisplaybreaks

% Damit auf Teil-Seiten keine Seitennummer angezeigt wird
\fancypagestyle{plain}{\fancyhf{}
  \renewcommand{\headrulewidth}{0pt}
  \renewcommand{\footrulewidth}{0pt}}

% Kopf- und Fußzeile
% Höhe der Kopfzeile
\setlength{\headheight}{14pt}
% obere Trennlinie
%\renewcommand{\headrulewidth}{0.4pt}
\fancyhf{} %alle Kopf- und Fußzeilenfelder bereinigen
\fancyhead[L]{\textbf{IK2b - Solid State and Statistical Physics}} %Kopfzeile links
%\fancyhead[C]{\leftmark} %zentrierte Kopfzeile
\fancyhead[R]{\rightmark} %Kopfzeile rechts
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END-front}} %Seitenzahl der Front-Matter

\AtBeginDocument{
  \def\labelitemi{\normalfont\bfseries{--}}
  \def\labelitemii{\(\circ\)}
  \def\labelitemiii{\(\triangleright\)}
}

\makeatother

\begin{document}




\global\long\def\norm#1{\left\lVert #1\right\rVert }


\global\long\def\abs#1{\left\lvert #1\right\rvert }


\global\long\def\opnorm#1{\opnor{#1}}


\global\long\def\BRA#1{\Bra{#1}}


\global\long\def\KET#1{\Ket{#1}}


\global\long\def\BraKet#1{\Braket{#1}}


\global\long\def\mins{\textnormal{-}}


\global\long\def\LB{\LBO}


\global\long\def\exs{\exsop}


\global\long\def\exsg{\exsgop}


\global\long\def\fall{\fallop}


\global\long\def\bcupd{\bcupdop}


\global\long\def\bcapd{\bcapdop}


\global\long\def\sr#1#2#3{\underset{#3}{\overset{#2}{#1}}}


\global\long\def\dd{\textnormal{d}}


\global\long\def\DD{\textnormal{D}}


\global\long\def\dbar{\dBar}


\global\long\def\TT{\textnormal{T}}


\global\long\def\ii{\textbf{i}}


\global\long\def\modulo#1#2{\moduloT{#1}{#2}}


\global\long\def\lmodulo#1#2{\lmoduloT{#1}{#2}}


\global\long\def\modlo#1#2{\modloT{#1}{#2}}


\global\long\def\moduloScript#1#2{\moduloScriptT{#1}{#2}}


\global\long\def\lmoduloScript#1#2{\lmoduloScriptT{#1}{#2}}


\global\long\def\modloScript#1#2{\modloScriptT{#1}{#2}}


\global\long\def\vek#1{\vectorsym{#1}}


\global\long\def\mat#1{\matrixsym{#1}}


\global\long\def\ten#1{\tensorsym{#1}}


\global\long\def\msd#1{\mathstrut_{#1}}


\global\long\def\msu#1{\mathstrut^{#1}}


\pagenumbering{roman}


\title{\hspace*{1mm}\vspace*{-25mm}\\
{\Huge Integrated Course IIb}\\
{\Huge Theoretical Solid State and}\\
{\Huge Statistical Physics}}


\author{\vspace*{-5mm}\\
\textit{\small lecture by}\\
\textit{\noun{\small Prof. Dr. Milena Grifoni}}\\
\textit{\small during the winter semester 2012/13}\\
\textit{\small revision and layout in \LyX{} by}\\
\textit{\noun{\small Andreas Völklein}}\\
\vspace*{5mm}\\
\includegraphics[clip,width=15cm]{unir}\\
\vspace*{3mm}\\
{\normalsize Last changed: \today}\\
\vspace*{-30mm}}

\maketitle
\fancyhead[R]{License}


\subsubsection*{ATTENTION}

This script does \emph{not} replace the lecture.

Therefore it is recommended \emph{strongly} to attend the lecture.

\vfill{}



\subsubsection*{Copyright Notice}

Copyright © 2012-2013 \noun{Andreas Völklein}

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3
or any later version published by the Free Software Foundation;

with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
Texts.

A copy of the license is included in the document entitled “GFDL”.


\subsubsection*{Disclaimer of Warranty}

\noun{Unless otherwise mutually agreed to by the parties in writing
and to the extent not prohibited by applicable law, }\textbf{\noun{the
Copyright Holders and any other party, who may distribute the Document
as permitted above,   provide the Document “as is}}\textbf{”,}\textbf{\noun{
without warranty of any kind}}\noun{, expressed, implied, statutory
or otherwise, including, but not limited to, the implied warranties
of merchantability, fitness for a particular purpose, non-infringement,
the absence of latent or other defects, accuracy, or the absence of
errors, whether or not discoverable.}


\subsubsection*{Limitation of Liability}

\textbf{\noun{In no event}}\noun{ unless required by applicable law
or agreed to in writing }\textbf{\noun{will the Copyright Holders,
or any other party, who may distribute the Document as permitted above,
be liable to you for any damages}}\noun{, including, but not limited
to, any general, special, incidental, consequential, punitive or exemplary
damages, however caused, regardless of the theory of liability, arising
out of or related to this license or any use of or inability to use
the Document, even if they have been advised of the possibility of
such damages.}

\textbf{\noun{In no event will the Copyright Holders'/Distributor's
liability to you}}\noun{, whether in contract, tort (including negligence),
or otherwise, }\textbf{\noun{exceed the amount you paid the Copyright
Holders/Distributor}}\noun{ for the document under this agreement.}


\subsubsection*{Links}

The text of the “GNU Free Documentation License” can also be read
on the following site:
\begin{quote}
\url{https://www.gnu.org/licenses/fdl-1.3.en.html}
\end{quote}
A transparent copy of the recent version of this document can be downloaded
from:
\begin{quote}
\url{https://github.com/andiv/IK2b}
\end{quote}
\newpage{}

\fancyhead[R]{Literature}


\subsection*{Literature}

Statistical physics:
\begin{itemize}
\item [$\bullet$]\noun{Torsten Fließbach}: \foreignlanguage{ngerman}{\emph{Lehrbuch
zur theoretischen Physik IV: Statistische Physik}; Spektrum Akademischer
Verlag}, 2007; ISBN: 978-3-8274-1684-1
\end{itemize}
Solid state physics:
\begin{itemize}
\item [$\bullet$]\noun{Gerd Czycholl}: \foreignlanguage{ngerman}{\emph{Theoretische
Festkörperphysik}}; Springer, 2008;\\
ISBN: 978-3-540-74789-5
\item [$\bullet$]\noun{Henrik Bruus, Karsten Flensberg:} \emph{Many-body
quantum theory in condensed matter physics}; Oxford University Press,
2007; ISBN: 978-0-19-856633-5
\item [$\bullet$]\noun{Neil W. Ashcroft, N. David Mermin:} \emph{Solid
state physics}; Brooks/Cole Cengage Learning, 2011; ISBN: 978-81-315-0052-1
\end{itemize}
{\small \newpage{}}\fancyhead[R]{Table of Contents}
\fancyhead[C]{}

\tableofcontents{}\label{END-front}\newpage{}\pagenumbering{arabic}
\fancyfoot[C]{\thepage\quad\!\!\!\slash\quad\!\!\!\pageref{END}} % Seitenzahl des Hauptteils
\fancyhead[R]{\rightmark}
%\fancyhead[C]{\leftmark}%DATE: Di 16.10.2012


\part{Thermodynamics}

\setcounter{chapter}{-1}


\chapter{Introduction to Statistical Physics}
\begin{itemize}
\item Within Statistical Physics one considers systems of \emph{many particles}.\\
(e.g. atoms of a gas or of a liquid, phonons in solids, photons in
a plasma, \ldots)\\
$\Rightarrow$\emph{ }\noun{Aim}: \emph{Macroscopic properties} of
systems with \emph{many microscopic} degrees of freedom
\item Although each particle obeys the laws of classical or quantum mechanics,
due to the large number ($N\approx10^{23}$ for a mole of gas), the
\emph{coupled} equations of motion are not solvable.\\
$\Rightarrow$ \noun{Method}: The treatment is \emph{statistical}:
It is based on assumptions about the \emph{probability} of a set of
trajectories or states.
\item In Statistical Physics one starts from microscopic quantities and
the laws of classical or quantum mechanics. One then introduces statistical
hypotheses and on the basis of statistical methods one

\begin{enumerate}[label=\roman*)]
\item defines macroscopic quantities and
\item deduces relations among them.
\end{enumerate}
\end{itemize}
\textcolor{green}{TODO: Abb1}


\chapter{Statistical Methods}

The transition from microscopic to macroscopic degrees of freedom
occurs upon \emph{averaging} over the many degrees of freedom. ($\Rightarrow$
reduction to few degrees of freedom)


\section{Probability}

Let us throw a dice:

\textcolor{green}{TODO: Abb2}
\begin{enumerate}[label=\roman*)]
\item \emph{Accessible states}: 6 possible outcomes $w_{i}\in\left\{ 1,2,3,4,5,6\right\} $,
all other natural numbers in $\mathbb{N}$ are unaccessible.
\item \emph{Probability}: The outcome is probabilistic: By throwing the
dice $N$ times the result $w_{i}$ occurs $N_{i}$ times.\emph{}\\
\emph{Definition}: The probability of outcome $w_{i}$ is defined
as:
\begin{align}
p\left(w_{i}\right) & =p_{i}:=\lim_{N\to\infty}\frac{N_{i}}{N}\label{eq:DefProbability}
\end{align}
Due to $N=\sum_{i}N_{i}$ we get:
\begin{align}
\sum_{i}p_{i} & =1\label{eq:sumPisOne}
\end{align}

\item \emph{Equal a priori probability}: For a ``fair'' dice all the accessible
outcomes have equal probability.
\begin{align}
p_{i} & =p
\end{align}
 \eqref{eq:sumPisOne} implies:
\begin{align*}
\sum_{i=1}^{6}p & =1\quad\Rightarrow\quad p=\frac{1}{6}
\end{align*}
\emph{Note}: The consequences of this a priori assumptions can be
verified a posteriori in experiments.\emph{}\\
\emph{Note}: Besides a dice we could also consider other systems,
e.g. a gas of $N$ atoms or of $N$ molecules. Suppose that the energy
$\varepsilon$ of the atom is measured with some precision $\Delta\varepsilon$.
Then we can assign the possible energies $\varepsilon_{i}=i\cdot\Delta\varepsilon$
with $i\in\mathbb{N}_{0}$. If we now perform a measurement of the
ensemble of $N$ atoms, the probability $p\left(\varepsilon_{i}\right)=p_{i}$
is again:
\begin{align*}
p\left(\varepsilon_{i}\right) & =\frac{N_{i}}{N}
\end{align*}
Here $N_{i}$ is the number of atoms with energy $\varepsilon_{i}$.\\
(This quantity will be explicitly calculated later in the course.)
\item \emph{Addition and multiplication}:

\begin{itemize}
\item Let us consider the probability $p$ that by throwing the dice, we
get one of the two outcomes $w_{i}$ of $w_{j}$ ($i\not=j$). Because
the two events are mutually excluding, we have
\begin{align*}
N_{i\text{ or }j} & =N_{i}+N_{j}
\end{align*}
and from \eqref{eq:DefProbability} follows:
\begin{align}
p_{i\text{ or }j} & =p_{i}+p_{j}
\end{align}

\item If one has two dices, the probability that the first dice is in $w_{i}$
and the second in $w_{j}$ is for independent events:
\begin{align}
p_{ij} & =\lim_{N,M\to\infty}\frac{N_{i}M_{j}}{NM}=p_{i}p_{j}
\end{align}

\end{itemize}
\item \emph{Mean value}:\\
\emph{Experiment 1}: Throw a dice $N$ times and obtain $N$ values
$w_{j}=w\left(t_{j}\right)$, $j\in\left\{ 1,2,\ldots,N\right\} $.
\begin{align}
\Rightarrow\quad\overline{w} & =\frac{1}{N}\sum_{j}w\left(t_{j}\right) &  & \text{time average}\label{eq:DefTimeAverage}
\end{align}
\emph{Experiment 2}: Throw $N$ identical dice once and obtain the
$N$ values $w_{j}$.
\begin{align}
\overline{\overline{w}} & =\frac{1}{N}\sum_{j}w_{j} &  & \text{ensemble average}\label{eq:DefEnsembleAverage}
\end{align}
\emph{Note}: For small $N$ is in general $\overline{w}\not=\overline{\overline{w}}$.\emph{}\\
\emph{Definition}: The \emph{thermodynamic limit} is the limit of
large systems, ideally $N\rightarrow\infty$.\emph{}\\
\emph{Assumption}: In the thermodynamic limit is $\overline{w}=\overline{\overline{w}}$.\\
With the definitions \eqref{eq:DefProbability}, \eqref{eq:DefTimeAverage}
and \eqref{eq:DefEnsembleAverage} follows:
\begin{align}
\overline{\overline{w}} & =\overline{w}=\sum_{\text{\ensuremath{w_{i}\in}accessible states}}w_{i}p_{i}
\end{align}
This relation has predictive power, if the $p_{i}$ are known. For
the case of a dice we have:
\begin{align*}
\overline{w} & =\sum_{\text{a.s.}}w_{i}\cdot\frac{1}{6}=3,5
\end{align*}

\item \emph{Mean square deviation}:

\begin{itemize}
\item \emph{mean deviation}:
\begin{align*}
\overline{w-\overline{w}} & =\sum_{i}p_{i}\left(w_{i}-\overline{w}\right)=\underbrace{\sum_{i}p_{i}w_{i}}_{=\overline{w}}-\overline{w}\underbrace{\sum_{i}p_{i}}_{=1}=0
\end{align*}

\item \emph{mean square deviation}:
\begin{align}
\overline{\left(w-\overline{w}\right)^{2}} & =\overline{w^{2}}-\overline{w}^{2}
\end{align}

\item \emph{standard deviation}:
\begin{align*}
\Delta w & =\sqrt{\,\overline{\left(w-\overline{w}\right)^{2}}\,}
\end{align*}

\end{itemize}
\end{enumerate}

\section{Binomial distribution}

We consider a system of $N$ ``particles'', whose constituents are
characterized by only two possible states. This is called a \emph{binary
system}.


\subsubsection*{Examples}
\begin{enumerate}[label=\roman*)]
\item \emph{Spin chain}: Consider $N$ spins with $S_{z}=\pm\frac{1}{2}$.\\
There are several possible configurations:
\begin{align*}
\uparrow\uparrow\uparrow\uparrow\ldots\uparrow\uparrow &  & \uparrow\downarrow\uparrow\downarrow\ldots\downarrow\uparrow &  & \uparrow\uparrow\downarrow\downarrow\ldots\uparrow\uparrow
\end{align*}

\item \emph{One dimensional random walk}: Go along the $x$-axis in steps
$\pm\Delta x$ (to the right ``$+$'' or to the left ``$-$'')
starting from $x=0$.
\begin{align*}
++++\ldots++ &  & +-+-\ldots-+ &  & ++--\ldots++
\end{align*}

\end{enumerate}
Let us consider the random walk and define $p$ (respectively $q$)
as the probability of step $+\Delta x$ ($-\Delta x$) with $p+q=1$
and $n_{+}$ ($n_{-}$) as the number of steps to the right (left)
with $n_{+}+n_{-}=N$. Define $m:=n_{+}-n_{-}$ to get the position
$m\Delta x$ of the walker after $N$ steps. It holds $n_{+}=\frac{N+m}{2}$.

We wish to calculate the probability $P_{N}\left(m\right)$ that the
walker is in $m\Delta x$ after $N$ steps.\\
Note that $P_{N}\left(m\right)=W_{N}\left(n_{+}\right)$ is the probability
of having performed $n_{+}$ positive steps out of $N$ steps.


\subsubsection*{Calculation of $P_{N}\left(m\right)=W_{N}\left(n_{+}\right)$}
\begin{enumerate}[label=\roman*)]
\item Consider the sequence $+--++$. The probability for this sequence
is $p^{3}q^{2}$.
\item The sequence has $n_{+}=3$ and $N=5$. There are other sequences
which also have $n_{+}=3$ and $N=5$. In general the number of configurations
$\Omega\left(N,n_{+}\right)$ is called ``multiplicity''. For $N=5$,
$n_{+}=3$ it is:
\begin{align*}
\Omega\left(5,3\right) & =\frac{5!}{3!\cdot2!}=\left(\begin{array}{c}
5\\
3
\end{array}\right)
\end{align*}

\item For arbitrary $N$ and $n_{+}$ holds similarly:
\begin{align}
\Omega\left(N,n_{+}\right) & =\frac{N!}{n_{+}!n_{-}!}=\frac{N!}{n_{+}!\left(N-n_{+}\right)!}=\left(\begin{array}{c}
N\\
n_{+}
\end{array}\right)
\end{align}
So the probability $P_{N}\left(m\right)=W_{N}\left(n_{+}\right)$
is:
\begin{align}
W_{N}\left(n_{+}\right) & =\Omega\left(N,n_{+}\right)p^{n_{+}}q^{N-n_{+}}\label{eq:Binomial-distribution}
\end{align}
This is the binomial distribution.
\end{enumerate}
%DATE: Fr 19.10.12

\emph{Note}: In the following we write $n$ instead of $n_{+}$.
\begin{itemize}
\item The Binomial theorem gives:
\begin{align*}
\sum_{n=0}^{N}W_{N}\left(n\right) & =\sum_{n=0}^{N}\left(\begin{array}{c}
N\\
n
\end{array}\right)p^{n}q^{N-n}=\left(p+q\right)^{N}=1
\end{align*}

\item The total number of configurations is:
\begin{align*}
N_{\text{conf}} & =\sum_{n=0}^{N}\Omega\left(N,n\right)=\sum_{n=0}^{N}\left(\begin{array}{c}
N\\
n
\end{array}\right)=\sum_{n=0}^{N}\left(\begin{array}{c}
N\\
n
\end{array}\right)1^{n}1^{N-n}=\left(1+1\right)^{N}=2^{N}
\end{align*}

\item We have:
\begin{align*}
m & =n_{+}-n_{-}=n_{+}-\left(N-n_{+}\right)=2n_{+}-N
\end{align*}
Therefore $m$ lies in $\left\{ -N,N\right\} $ in steps of 2.
\end{itemize}

\subsubsection*{Mean values}

\begin{align*}
\overline{n}_{+} & =\overline{n}=\sum_{n=0}^{N}nW_{N}\left(n\right)=\sum_{n=0}^{N}n\left(\begin{array}{c}
N\\
n
\end{array}\right)p^{n}q^{N-n}=\\
 & =p\frac{\partial}{\partial p}\underbrace{\left(\sum_{n=0}^{N}\left(\begin{array}{c}
N\\
n
\end{array}\right)p^{n}q^{N-n}\right)}_{=\left(p+q\right)^{N}}=pN\left(p+q\right)^{N-1}=pN
\end{align*}
Analogously follows:
\begin{align*}
\overline{n}_{-} & =qN\\
\overline{m} & =\overline{n}-\overline{n}_{-}=N\left(p-q\right)
\end{align*}



\subsubsection*{Variance}

\begin{align*}
\overline{n^{2}} & =\sum_{n=0}^{N}n^{2}\left(\begin{array}{c}
N\\
n
\end{array}\right)p^{n}q^{N-n}=p\frac{\partial}{\partial p}\left(p\frac{\partial}{\partial p}\left(\sum_{n=0}^{N}\left(\begin{array}{c}
N\\
n
\end{array}\right)p^{n}q^{N-n}\right)\right)=Npq+\overline{n}^{2}
\end{align*}
Therefore we get the standard deviation:
\begin{align*}
\Delta n & =\sqrt{\overline{n^{2}}-\overline{n}^{2}}=\sqrt{Npq}\\
\Delta m & =2\sqrt{Npq}
\end{align*}



\subsubsection*{Law of large numbers}

\begin{align}
\fbox{\ensuremath{{\displaystyle \frac{\Delta n}{n}=\sqrt{\frac{q}{p}}\frac{1}{\sqrt{n}}}}} & \xrightarrow[\Rightarrow\ n\to\infty]{N\to\infty}0
\end{align}
I.e. for large numbers $N$, the distribution $W_{N}\left(n\right)$
approaches a distribution strongly peaked around $\overline{n}$.
Let us e.g. consider $p=q=\frac{1}{2}$, for example for a spin chain
in zero magnetic field.
\begin{align*}
W_{N}\left(n\right) & =\frac{1}{2^{n}}\left(\begin{array}{c}
N\\
n
\end{array}\right)=\frac{\Omega\left(N,n\right)}{\sum_{m=0}^{N}\Omega\left(N,m\right)}=P_{N}\left(m\right)
\end{align*}
Therefore it is enough to focus on $\Omega\left(N,n\right)$.\\
\emph{Example}: $N=10$
\begin{align*}
\Omega\left(N,0\right) & =1 & \Omega\left(N,3\right) & =120\\
\Omega\left(N,1\right) & =10 & \Omega\left(N,4\right) & =210\\
\Omega\left(N,2\right) & =45 & \Omega\left(N,5\right) & =252
\end{align*}
The other $\Omega\left(N,n\right)$ follow from $\Omega\left(N,n\right)=\Omega\left(N,N-n\right)$.
The total number of possibilities is:
\begin{align*}
\sum_{m=0}^{N}\Omega\left(N,m\right) & =2^{10}=1024
\end{align*}
We can plot now $\Omega\left(N,n\right)$ or $\tilde{\Omega}\left(N,m\right)=\Omega\left(N,\frac{N+m}{2}\right)$.

\textcolor{green}{TODO: Abb1 }


\section{Normal distribution}

In the limit of large $N$ (and $Npq\gg1$) the binomial distribution
approaches a Gauss function, also known as \emph{normal distribution}.
This is a special case of the \emph{central limit theorem}.
\begin{itemize}
\item To this extent it is convenient to investigate the behavior of $\ln\left(W_{N}\left(n\right)\right)$,
which has a smoother variation in $n$, than $W_{N}\left(n\right)$.
\item From \eqref{eq:Binomial-distribution} follows:
\begin{align*}
\ln\left(W_{N}\left(n\right)\right) & =\ln\left(N!\right)-\ln\left(n!\right)-\ln\left(\left(N-n\right)!\right)+n\ln\left(p\right)+\left(N-n\right)\ln\left(q\right)
\end{align*}
Moreover holds:
\begin{align*}
\frac{\dd}{\dd n}\ln\left(n!\right) & \stackrel{n\gg1}{\approx}\frac{\ln\left(\left(n+1\right)!\right)-\ln\left(n!\right)}{n+1-n}=\ln\left(n+1\right)\stackrel{n\gg1}{\approx}\ln\left(n\right)
\end{align*}
\begin{align}
\Rightarrow\qquad\frac{\dd}{\dd n}\ln\left(W_{N}\left(n\right)\right) & \approx-\ln\left(n\right)+\ln\left(N-n\right)+\ln\left(p\right)-\ln\left(q\right)\stackrel{n=\overline{n}}{=}0\label{eq:DerivativeW_N}
\end{align}
Whereby $\overline{n}=Np\gg1$ holds and:
\begin{align}
\overline{n}_{-}=Nq\gg1 & \qquad\Leftrightarrow\qquad Npq\gg1
\end{align}
After \eqref{eq:DerivativeW_N} the first derivative vanishes at $n=\overline{n}$,
and thus follows that $\ln\left(W_{N}\left(n\right)\right)$ and hence
$W_{N}\left(n\right)$ have a stationary point at $n=\overline{n}$.
\item Likewise it holds:
\begin{align*}
\frac{\dd^{2}}{\dd n^{2}}\ln\left(W_{N}\left(n\right)\right) & =-\frac{1}{n}-\frac{1}{N-n}\stackrel{n=\overline{n}}{=}-\frac{1}{Npq}=-\frac{1}{\left(\Delta n\right)^{2}}<0
\end{align*}
Therefore $W_{N}\left(n\right)$ has a maximum at $n=\overline{n}$.
\item Furthermore follows:
\begin{align*}
\frac{\dd^{3}}{\dd n^{3}}\ln\left(W_{N}\left(n\right)\right) & =\frac{1}{n^{2}}-\frac{1}{\left(N-n\right)^{2}}\stackrel{n=\overline{n}}{=}\frac{q^{2}-p^{2}}{N^{2}p^{2}q^{2}}
\end{align*}

\item Thus the Taylor expansion is:
\begin{align*}
\ln W_{N}\left(n\right) & =\ln W_{N}\left(\overline{n}\right)+\frac{\dd}{\dd n}W_{N}\left(n\right)\bigg|_{\overline{n}}\left(n-\overline{n}\right)+\frac{1}{2}\frac{\dd^{2}}{\dd n^{2}}W_{N}\left(n\right)\bigg|_{\overline{n}}\left(n-\overline{n}\right)^{2}+\\
 & \qquad+\frac{1}{6}\frac{\dd^{3}}{\dd n^{3}}W_{N}\left(n\right)\bigg|_{\overline{n}}\left(n-\overline{n}\right)^{3}+o_{0}\left(\left(n-\overline{n}\right)^{3}\right)\\
 & \approx\ln W_{N}\left(\overline{n}\right)-\frac{1}{2}\frac{\left(n-\overline{n}\right)^{2}}{Npq}=\ln W_{N}\left(\overline{n}\right)-\frac{\left(n-\overline{n}\right)^{2}}{2\left(\Delta n\right)^{2}}
\end{align*}

\end{itemize}

\subsubsection{Gauss distribution}

This gives the following probability distribution, called \emph{Gauss
distribution}:\stepcounter{equation}

\begin{align}
\fbox{\ensuremath{{\displaystyle W_{N}\left(n\right)=W_{N}\left(\overline{n}\right)\exp\left(-\frac{\left(n-\overline{n}\right)^{2}}{2\left(\Delta n\right)^{2}}\right)}}}\tag{\arabic{chapter}.\arabic{equation}a}\label{eq:Gauss-distribution}
\end{align}
It is a good approximation for:
\begin{align*}
\abs{\frac{\left(\ln W\right)'''\left(n-\overline{n}\right)^{3}}{\left(\ln W\right)''\left(n-\overline{n}\right)^{2}}} & \approx\frac{\abs{n-\overline{n}}}{Npq}\ll1
\end{align*}
For $n-\overline{n}\approx\Delta n=\sqrt{Npq}$ this means:
\begin{align*}
\frac{1}{\sqrt{Npq}} & \ll1
\end{align*}
\emph{Note}: The condition $N\gg1$ is not sufficient to get \eqref{eq:Gauss-distribution}.
For example if $p\ll1$ it could still be $Np=\overline{n}\ll1$.
One approaches in this case from a binomial distribution the \emph{Poisson
distribution}:
\begin{align*}
P\left(\lambda,n\right) & =\frac{\lambda^{n}}{n!}e^{-\lambda} & \lambda & =Np
\end{align*}

\begin{itemize}
\item To determine $W_{N}\left(\overline{n}\right)$ we observe:
\begin{align*}
1 & =\sum_{n=0}^{N}W_{N}\left(n\right)\approx\int_{0}^{N}\dd xW_{N}\left(x\right)\approx\int_{-\infty}^{\infty}\dd xW_{N}\left(x\right)=\\
 & =W_{N}\left(\overline{n}\right)\int_{-\infty}^{\infty}\dd xe^{-\frac{\left(x-\overline{n}\right)^{2}}{2\left(\Delta n\right)^{2}}}=W_{N}\left(\overline{n}\right)\sqrt{2\pi}\Delta n
\end{align*}
The first approximation is good, because the relative variation of
$W_{N}\left(n\right)$ between $n$ and $n+1$ is small around the
average $\overline{n}$ and the second is good, because we make only
an exponentially small error. So we get:
\begin{align}
W_{N}\left(n\right) & =\frac{1}{\sqrt{2\pi}\Delta n}e^{-\frac{\left(n-\overline{n}\right)^{2}}{2\left(\Delta n\right)^{2}}}\tag{\arabic{chapter}.\arabic{equation}b}\label{eq:Gauss-distribution_b}
\end{align}

\item Let us introduce the length $l$ and define $x=nl$, $\overline{x}=\overline{n}l$,
$\sigma:=\Delta x=\Delta nl=\sqrt{Npq}\cdot l$.\\
Now the probability density $P\left(x\right)$ along the $x$-axis
is defined by setting $P\left(x\right)\dd x$ as the probability to
find the random variable between $x$ and $x+\dd x$.
\begin{align*}
P\left(x\right)\dd x & \approx\frac{\dd x}{l}W_{N}\left(\frac{x}{l}\right)
\end{align*}
Now follows from \eqref{eq:Gauss-distribution_b} the \emph{normal
distribution}:
\begin{align}
P\left(x\right) & =\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{\left(x-\overline{x}\right)^{2}}{2\sigma^{2}}\right)\label{eq:normal-distribution}
\end{align}
\emph{Note}: For $x=\left(n_{+}-n_{-}\right)l$ we have $\overline{x}=N\left(p-q\right)l$
and $\sigma=2\sqrt{Npq}l$, but the form \eqref{eq:normal-distribution}
still holds.
\item \emph{Properties of the Gauss distribution}:
\begin{align*}
\int_{-\infty}^{\infty}\dd xP\left(x\right) & =1 & \int_{\overline{x}-\nu\sigma}^{\overline{x}+\nu\sigma}\dd xP\left(x\right) & =\begin{cases}
0{,}683 & \nu=1\\
0{,}954 & \nu=2\\
0{,}997 & \nu=3
\end{cases}
\end{align*}
This means, that an event outside of the $3\sigma$ range occurs with
probability $0,3\%$, which is highly improbable!
\end{itemize}

\section{Central limit theorem}

If the quantity ${\displaystyle x=\sum_{i}s_{i}}$ is the sum of \emph{many}
independent random variables, then the probability function $P\left(x\right)$
for $x$ is the normal distribution.


\subsubsection{Proof}

Let us consider a variable $x$ such that
\begin{align*}
x & =s_{1}+s_{2}+\ldots+s_{N}=\sum_{i=1}^{N}s_{i}
\end{align*}
where \emph{$s_{i}$} are \emph{random variables} with:
\begin{enumerate}[label=\roman*)]
\item $w_{i}\left(s_{i}\right)\dd s_{i}$ is the probability to find the
$i$-th variable with values between $s_{i}$ and $s_{i}+\dd s_{i}$.\\
\emph{Example}s:

\begin{itemize}
\item If $s_{i}$ is the $i$-th step in a random walk, then $x$ is the
particle's position after $N$ steps.
\item If $s_{i}$ is the energy of the $i$-th atom of a gas, then $x$
is the total energy.
\end{itemize}
\item For all $i$ holds:
\begin{align*}
\int_{-\infty}^{\infty}\dd sw_{i}\left(s\right) & =1\\
\overline{s}_{i} & =\int_{-\infty}^{\infty}\dd sw_{i}\left(s\right)s<\infty\\
\left(\Delta s_{i}\right)^{2} & =\int_{-\infty}^{\infty}\dd s\left(s-\overline{s}_{i}\right)^{2}w_{i}\left(s\right)<\infty
\end{align*}

\item The $s_{i}$ are independent variables.
\end{enumerate}
Then the average value of $x$ is:
\begin{align*}
\overline{x} & =\int_{-\infty}^{\infty}\dd s_{1}W_{1}\left(s_{1}\right)\ldots\int_{-\infty}^{\infty}\dd s_{N}W_{N}\left(s_{N}\right)\left(s_{1}+s_{2}+\ldots+s_{n}\right)=\sum_{i=1}^{N}\overline{s}_{i}
\end{align*}
The mean square deviation is:
\begin{align*}
\left(\Delta x\right)^{2} & =\int_{-\infty}^{\infty}\dd s_{1}W_{1}\left(s_{1}\right)\ldots\int_{-\infty}^{\infty}\dd s_{N}W_{n}\left(s_{N}\right)\left(x-\overline{x}\right)^{2}=\\
 & =\int_{-\infty}^{\infty}\ldots\left(\sum_{i=1}^{N}\left(s_{i}-\overline{s}_{i}\right)\right)^{2}=\int_{-\infty}^{\infty}\ldots\sum_{i=1}^{N}\left(s_{i}-\overline{s}_{i}\right)\sum_{j=1}^{N}\left(s_{j}-\overline{s}_{j}\right)=\\
 & =\int_{-\infty}^{\infty}\ldots\Bigg[\sum_{i=1}^{N}\left(s_{i}-\overline{s}_{i}\right)^{2}+\underbrace{\sum_{\sr{}{i,j=1}{i\not=j}}^{N}\left(s_{i}-\overline{s}_{i}\right)\left(s_{j}-\overline{s}_{j}\right)}_{\int_{-\infty}^{\infty}\ldots=0}\Bigg]=\\
 & =\int_{-\infty}^{\infty}\ldots\sum_{i=1}^{N}\left(s_{i}-\overline{s}_{i}\right)^{2}=\sum_{i=1}^{N}\left(\Delta s_{i}\right)^{2}
\end{align*}
Therefore follows:
\begin{align*}
\frac{\Delta x}{\overline{x}} & =\frac{\sqrt{\sum_{i=1}^{N}\left(\Delta s_{i}\right)^{2}}}{\sum_{i=1}^{N}\overline{s}_{i}}=\mathcal{O}_{\infty}\left(\frac{1}{\sqrt{N}}\right)
\end{align*}
This amounts to the law of large numbers.

E.g. for $w_{i}\left(s\right)=w\left(s\right)$ follows $\overline{s}_{i}=\overline{s}$,
$\overline{x}=N\overline{s}$ and $\left(\Delta x\right)^{2}=N\left(\Delta s\right)^{2}$.
\begin{align}
\Rightarrow\quad\frac{\Delta x}{\overline{x}} & =\frac{\Delta s}{\overline{s}}\cdot\frac{1}{\sqrt{N}}
\end{align}
\emph{Example}: Consider a gas of $N=10^{24}$ atoms. The $i$-th
atom has the energy $\varepsilon_{i}$ with probability $w\left(\varepsilon_{i}\right)=\exp\left(-\frac{\varepsilon_{i}}{k_{B}T}\right)$,
where $k_{B}$ Boltzmann constant and $T$ the temperature.
\begin{align*}
\overline{\varepsilon} & \approx\Delta\varepsilon\approx k_{B}T\\
\Rightarrow\qquad\frac{\Delta\varepsilon}{\overline{\varepsilon}} & \approx1
\end{align*}
But $E=\sum_{i}\varepsilon_{i}$ is sharply peaked!
\begin{align*}
\frac{\Delta E}{\overline{E}} & =\frac{\Delta\varepsilon}{\overline{\varepsilon}\sqrt{N}}\approx10^{-12}
\end{align*}


%DATE: Di 23.10.12

In general the probability density for $x$ is:

\begin{align*}
P\left(x\right) & =\int_{-\infty}^{\infty}\dd s_{1}w_{1}\left(s_{1}\right)\ldots\int_{-\infty}^{\infty}\dd s_{N}w_{N}\left(s_{N}\right)\delta\left(s-\sum_{i=1}^{N}s_{i}\right)
\end{align*}
The trick is to Fourier transform the delta distribution:
\begin{align*}
\delta\left(y\right) & =\frac{1}{2\pi}\int_{-\infty}^{\infty}\dd ke^{\ii ky}
\end{align*}
With the inverse Fourier transformation of this follows:
\begin{align*}
P\left(x\right) & =\frac{1}{2\pi}\int_{-\infty}^{\infty}\dd k\int_{-\infty}^{\infty}\dd s_{1}w_{1}\left(s_{1}\right)\ldots\int_{-\infty}^{\infty}\dd s_{N}w_{N}\left(s_{N}\right)e^{\ii k\left(s_{1}+\ldots+s_{N}\right)}e^{-\ii kx}=\\
 & =\frac{1}{2\pi}\int_{-\infty}^{\infty}\dd ke^{-\ii kx}\left(\prod_{j=1}^{N}W_{j}\left(k\right)\right)
\end{align*}
\begin{align*}
W_{j}\left(k\right) & :=\int_{-\infty}^{\infty}\dd s_{j}w_{j}\left(s_{j}\right)e^{\ii ks_{j}}
\end{align*}
Let us expand $W_{j}\left(k\right)$ for small $k$:
\begin{align*}
W_{j}\left(k\right) & =1+\ii k\overline{s}-\frac{1}{2}k^{2}\overline{s_{j}^{2}}+\mathcal{O}_{0}\left(k^{3}\right)
\end{align*}
Hence we get:
\begin{align*}
\ln\left(\prod_{j=1}^{N}W_{j}\left(k\right)\right) & =\sum_{j=1}^{N}\ln\left(1+\ii k\overline{s}_{j}-\frac{1}{2}k^{2}\overline{s_{j}^{2}}+\mathcal{O}_{0}\left(k^{3}\right)\right)
\end{align*}
Expanding the logarithm gives:
\begin{align*}
\ln\left(1+y\right) & =y-\frac{y^{2}}{2}+\mathcal{O}_{0}\left(y^{3}\right)
\end{align*}
\begin{align*}
\Rightarrow\quad\ln\left(\prod_{j=1}^{N}W_{j}\left(k\right)\right) & =\ii k\sum_{j=1}^{N}\overline{s}_{j}-\frac{1}{2}k^{2}\sum_{j=1}^{N}\left(\Delta s_{j}\right)^{2}+\mathcal{O}\left(k^{3}\right)\approx\\
 & \approx\ii k\overline{x}-\frac{k^{2}}{2}\left(\Delta x\right)^{2}
\end{align*}
Now follows
\begin{align*}
\prod_{j=i}^{N}W_{j}\left(k\right) & \approx e^{\ii k\overline{x}-\frac{k^{2}}{2}\left(\Delta x\right)^{2}}
\end{align*}
and hence:
\begin{align*}
P\left(x\right) & \approx\frac{1}{2\pi}\int_{-\infty}^{\infty}\dd ke^{-\ii\left(x-\overline{x}\right)k}e^{-\left(\Delta x\right)^{2}\frac{k^{2}}{2}}
\end{align*}
Calculating the integral gives:
\begin{align*}
\fbox{\ensuremath{{\displaystyle P\left(x\right)=\frac{1}{\sqrt{2\pi}\Delta x}\exp\left(-\frac{\left(x-\overline{x}\right)^{2}}{2\left(\Delta x\right)^{2}}\right)}}}
\end{align*}
$P\left(x\right)$ is, as stated before, a Gaussian distribution.\qqed


\subsubsection*{Regime of validity}

The theorem is based on the truncation of the expansion of the function
$W\left(k\right)$, which is good for:
\begin{align*}
\left|\frac{\overline{s^{n+1}}k^{n+1}}{\overline{s^{n}}k^{n}}\right| & \ll1
\end{align*}
Our case is $n=2$. One can estimate:
\begin{align*}
k & \approx\frac{1}{\Delta x}\approx\frac{1}{\sqrt{N}\Delta s}
\end{align*}
\begin{align*}
\Rightarrow\quad\left|\frac{\overline{s^{n+1}}}{\overline{s^{n}}}k\right| & \approx\left|\frac{\overline{s^{n+1}}}{\overline{s^{n}}}\frac{1}{\Delta s}\right|\frac{1}{\sqrt{N}}\approx\frac{1}{\sqrt{N}}\xrightarrow{N\to\infty}0
\end{align*}



\chapter{Fundamentals of statistical physics}


\section{Fundamental postulate}


\subsubsection*{Microstate}

A \emph{microstate} is defined by specifying completely the microscopic
state of a system.
\begin{itemize}
\item \emph{Example 1}: Let the system be a group of $N$ dices. Hence the
microstate $r$ is defined upon assigning the values $n_{i}\in\left\{ 1,2,\ldots,6\right\} $
to each of the $N$ dices.
\begin{align}
r & =\left(n_{1},n_{2},\ldots,n_{N}\right)
\end{align}
The possible number of microstates is:
\begin{align*}
\Omega\left(N\right) & =6^{N}
\end{align*}

\item \emph{Example 2}: Let the system be a physical system with $f$ degrees
of freedom. We consider a \emph{closed system}, such that the associated
Hamilton function/operator does not depend on time. In this case the
Hamilton function/operator yields the \emph{energy} of the microstate.
\item \emph{Quantum mechanical case}: As microstates we choose the eigenstates
$\left\{ \KET r\right\} $ of the Hamilton operator $\hat{H}$ determined
by the time independent Schrödinger equation:
\begin{align}
\hat{H}\KET r & =E_{r}\KET r
\end{align}
Here $E_{r}$ is the energy of the microstate. For a system with $f$
degrees of freedom the eigenstates depend on $f$ quantum numbers:
\begin{align*}
r & =\left(n_{1},n_{2},\ldots,n_{f}\right)
\end{align*}
\emph{Note}: We assumed here that the closed system is restricted
to a finite volume $V$, such that the quantum numbers are discrete.
\item \emph{Ideal gas of $N$ particles in a box of volume $V$}: The interaction
between gas particles is neglected (ideal gas). The total Hamilton
operator is the sum of the Hamilton operators $\hat{h}_{\nu}$ of
the $\nu$-th particle:
\begin{align}
\hat{H} & =\sum_{\nu=1}^{N}\hat{h}_{\nu}=\sum_{\nu=1}^{N}\frac{\hat{p}_{\nu}^{2}}{2m}\label{eq:Hamiltonian-ideal-gas}
\end{align}
Specifically, it holds:
\begin{align*}
\hat{h}_{\nu}\KET s_{\nu} & =\varepsilon_{\nu}\left(s\right)\KET s_{\nu}
\end{align*}
In the position representation
\begin{align*}
\psi_{s,\nu}\left(\vec{r}\right) & =\BraKet{\vec{r}|s}_{\nu}
\end{align*}
we get:
\begin{align*}
-\frac{\hbar^{2}}{2m}\nabla^{2}\psi_{s,\nu}\left(\vec{r}\right) & =\varepsilon_{\nu}\left(s\right)\psi_{s,\nu}\left(\vec{r}\right)
\end{align*}
For a particle in a box, $\psi_{s,\nu}\left(\vec{r}\right)$ vanishes
at the boundaries. With $V=L^{3}$ it holds:
\begin{align*}
0 & =\psi_{s,\nu}\left(0,y,z\right)=\psi_{s,\nu}\left(x,0,z\right)=\psi_{s,\nu}\left(x,y,0\right)\\
0 & =\psi_{s,\nu}\left(L,y,z\right)=\psi_{s,\nu}\left(x,L,z\right)=\psi_{s,\nu}\left(x,y,L\right)
\end{align*}
This gives for $n_{\nu x},\, n_{\nu y},\, n_{\nu z}\in\mathbb{N}_{\ge1}$:
\begin{align}
\begin{array}{rl}
{\displaystyle \psi_{s,\nu}\left(\vec{r}\right)} & {\displaystyle =A\sin\left(\frac{n_{\nu x}\pi x}{L}\right)\sin\left(\frac{n_{\nu y}\pi y}{L}\right)\sin\left(\frac{n_{\nu z}\pi z}{L}\right)}\\
{\displaystyle \varepsilon_{\nu}\left(s\right)} & {\displaystyle =\frac{\hbar^{2}}{2m}\left(\frac{\pi}{L}\right)^{2}\left(n_{\nu x}^{2}+n_{\nu y}^{2}+n_{\nu z}^{2}\right)}
\end{array}\label{eq:Energy-ideal-gas}
\end{align}
Therefore the state $\KET s_{\nu}$ and the energy $\varepsilon_{\nu}\left(s\right)$
are fixed by the quantum numbers $n_{\nu x}$, $n_{\nu y}$ and $n_{\nu z}$.
Thus the microstate $r$ of the system of $N$ atoms is defined by
assigning the $3N$ quantum numbers $r=\left(n_{1},n_{2},\ldots,n_{3N}\right)$
with the following order:
\begin{align*}
\left(n_{1},n_{2},n_{3}\right) & =\left(n_{1x},n_{1y},n_{1z}\right)\\
\left(n_{4},n_{5},n_{6}\right) & =\left(n_{2x},n_{2y},n_{2z}\right)\\
 & \ \ \vdots
\end{align*}
\emph{Note}: There are infinitely many microstates $r$ as each quantum
number $n_{k}$ can take infinitely many values. However, for \emph{fixed
energy}, the number becomes \emph{finite}.\emph{}\\
\emph{Note}: \emph{Phase-space volume per quantum state}\\
The available states can be represented on a three-dimensional lattice
in the space of the $\left\{ p_{x},p_{y},p_{z}\right\} $ with $p_{i}=\frac{\hbar\pi}{L}n_{i}$.
Due to $n_{i}>0$, all \emph{distinct} points are within the octant
with $p_{i}>0$.\\
\textcolor{green}{TODO: Abb1}\\
The number of states in a shell with radii between $p=\sqrt{p_{x}^{2}+p_{y}^{2}+p_{z}^{2}}$
and $p+\dd p$ is:
\begin{align*}
\frac{1}{8}\cdot\frac{4\pi p^{2}\dd p}{\left(\frac{\hbar\pi}{L}\right)^{3}} & =\frac{4\pi p^{2}\dd p}{h^{3}}V
\end{align*}
In general, the number of states with energy $\varepsilon\left(p\right)\le\varepsilon$
is:
\begin{align*}
\frac{V}{h^{3}}\cdot4\pi\int_{0}^{p_{m}}p^{2}\dd p & =\frac{1}{h^{3}}\cdot\int_{V}\dd^{3}r\int_{p\le p_{m}}\dd^{3}p
\end{align*}
So the minimal volume in phase space is $2\pi\hbar=h$.\emph{}\\
\emph{Note}: Consider the free particle with periodic boundary conditions.
\begin{align*}
\psi\left(x\right) & =Ae^{\ii kx} & \psi\left(0\right) & =\psi\left(L\right)\quad\Rightarrow\quad k=\frac{2\pi n}{L} & n & \in\mathbb{Z}
\end{align*}
Because $p_{x},\, p_{y},\, p_{z}$ can now assume both positive and
negative values, one has to consider a full sphere. In this case the
infinitesimal number of states is:
\begin{align*}
\frac{4\pi p^{2}\dd p}{\left(\hbar\frac{2\pi}{L}\right)^{3}}
\end{align*}
Again the minimal volume in phase space is $h=2\pi\hbar$.
\item \emph{Classical case}: In the classical case, a system with $f$ degrees
of freedom is characterized by assigning the values of $f$ generalized
coordinates $q_{1},q_{2},\ldots,q_{f}$ as well as generalized impulses
$p_{1},p_{2},\ldots,p_{f}$. Hence there are $2f$ microstates:
\begin{align*}
r & =\left(q_{1},\ldots,q_{f},p_{1},\ldots,p_{f}\right)
\end{align*}
For an ideal classical gas of $N$ particles there are $2f=6N$ microstates
and a microstate is:
\begin{align*}
r & =\left(\vec{r}_{1},\,\vec{r}_{2},\ldots,\vec{r}_{N}\,,\vec{p}_{1}\,,\vec{p}_{2},\ldots,\vec{p}_{N}\right)=\left(x_{1},\, y_{1},\, z_{1},\, x_{2},\ldots,z_{N},\, p_{x1},\, p_{y1},\, p_{z1},\ldots,p_{zN}\right)
\end{align*}
The energy is given by $H\left(q_{1},\, q_{2},\ldots,q_{f},\, p_{1},\ldots,p_{f}\right)$\emph{.}
\item \emph{Phase space}: The $2f$-dimensional space spanned by the variables
$\left\{ q_{1},p_{1},\ldots\right\} $ is called phase-space. So to
each classical microstate $r$ is associated a point in phase-space.\\
\textcolor{green}{TODO: Abb2}\\
For a statistical description we need to be able to \emph{enumerate}
the number of microstates $r$. To this extent we observe that in
general it is neither necessary nor possible to give the values $\left(q_{i},p_{i}\right)$
exactly. According to the uncertainty principle it holds:
\begin{align}
\fbox{\ensuremath{{\displaystyle \Delta q\Delta p\ge\frac{\hbar}{2}}}}
\end{align}
We count thus the number of classical states upon observing that for
the quantum case to one state corresponds a surface $h$ in phase
space. With the $2f$-dimensional phase space volume $V_{ps}$ the
number of states is therefore:
\begin{align}
N_{\text{states}} & =\frac{V_{ps}}{h^{f}}
\end{align}

\end{itemize}
%DATE: Fr 26.10.12


\subsubsection*{Macrostate}

For a many-particle-system with a very large number $N$ of particles,
the number of microstates with the same energy is also very large.
The system will constantly perform transitions $r\to r'$ between
(accessible) microstates.\\
In general we are not interested to know details of the evolution
of a microstate. Rather we are interested in:
\begin{enumerate}[label=\Roman*)]
\item \emph{Which} are the accessible microstates.
\item \emph{What} is the probability $P_{r}$ of occurrence of the microstate
$r$.
\end{enumerate}
A \emph{macrostate} is the state of a system defined only through
the set of probabilities $P_{r}$ for every configuration $r$.
\begin{align}
\left\{ P_{r}\right\}  & =\left\{ P_{1},P_{2},\ldots\right\} 
\end{align}
These probabilities are defined according to equation \eqref{eq:DefProbability}:
\begin{align}
P_{r} & =\lim_{M\to\infty}\frac{M_{r}}{M}
\end{align}
Here one has $M$ identical systems and the microstate $r$ occurs
upon measurement $M_{r}$ times.


\subsubsection*{Fundamental postulate}

Let us consider a closed system. From experience we know that independent
of the initial preparation, a closed system will evolve after some
time to a certain macrostate, which is called \emph{equilibrium state}.
The \emph{macroscopically measurable quantities} are those, that attain
\emph{constant} values, which are typically averages of a microscopic
quantity over all particles. The \emph{fundamental postulate} states:
\begin{quote}
``A closed system in equilibrium is with equal probability in any
of its accessible microstates.'' (ergodic hypothesis)
\end{quote}
(This is due to the chaotic behavior of practically any system of
many particles.)

\emph{Note}: The fundamental postulate defines the connection between
the microscopic structure, i.e. the accessible microstates $\left\{ r\right\} $,
and macroscopic quantities of the equilibrium state, i.e. the probabilities
$\left\{ P_{r}\right\} $.
\begin{itemize}
\item \emph{Example 1}: System of $N$ dices\\
The number of accessible states is $6^{N}$, so the probability for
each is:
\begin{align*}
P_{r} & =\frac{1}{6^{N}}
\end{align*}

\item \emph{Example 2}: Four electrons in a magnetic field $\vec{B}$\\
The relevant degrees of freedom are the spin $\hat{s}_{z}$ of each
electron along the quantization axis defined by $\vec{B}=B\vec{e}_{z}$.
\begin{align*}
\hat{L}_{i} & =-\hat{\vec{\mu_{i}}}\cdot\vec{B} & \hat{\vec{\mu_{i}}} & =-\mu_{B}g\frac{\hat{\vec{s_{i}}}}{\hbar}
\end{align*}
So a microstate is characterized by $r=\left(s_{z,1},\, s_{z,2},\, s_{z,3},\, s_{z,4}\right)$
with $s_{z,j}\in\pm\frac{\hbar}{2}$. Its energy is:
\begin{align*}
E_{r} & =2\mu_{B}B\sum_{j=1}^{4}s_{z,j}
\end{align*}
Suppose that the energy in the equilibrium state is $E=2\mu_{B}B$.\\
The accessible states (for distinguishable spins, e.g. sitting on
a lattice) are (denoting $s_{z}=\frac{\hbar}{2}$ by $\uparrow$ and
$s_{z}=-\frac{\hbar}{2}$ by $\downarrow$):
\begin{align*}
r & \in\left\{ \left(\uparrow\uparrow\uparrow\downarrow\right),\,\left(\uparrow\uparrow\downarrow\uparrow\right),\,\left(\uparrow\downarrow\uparrow\uparrow\right),\,\left(\downarrow\uparrow\uparrow\uparrow\right)\right\} =:M
\end{align*}
For example you can't find $\left(\uparrow\uparrow\uparrow\uparrow\right)$,
because this state has a different energy. The fundamental postulate
yields the probability:
\begin{align*}
P_{r} & =\begin{cases}
\frac{1}{4} & \text{for }r\in M\\
0 & \text{otherwise}
\end{cases}
\end{align*}

\end{itemize}

\subsubsection*{Alternative formulation of the fundamental postulate}

Let $\Omega$ be the number of accessible states. Then the fundamental
postulate can be written as:

\begin{align}
P_{r} & =\begin{cases}
\frac{1}{\Omega} & \text{for accessible microstates}\\
0 & \text{otherwise}
\end{cases}
\end{align}

\begin{itemize}
\item For a closed system, $\Omega$ depends on the energy $E$ and a family
$x=\left(x_{1},\ldots,x_{n}\right)$ additional external parameters.
For this one writes
\begin{align}
\Omega & =\Omega\left(E,x\right)
\end{align}
and calls $\Omega$ the \emph{microcanonical partition function}.
For a Hamiltonian $H=H\left(q,p,x\right)$, the Hamilton operator
$\hat{H}=\hat{H}\left(x\right)$ depends on $x$, so in general the
energies $E_{r}=E_{r}\left(x\right)$ also depend on $x$. For example
for a gas of $N$ atoms in a box of volume $V$ we have $x=\left(V,N\right)$.
\item As the energy $E$ can be assigned only with some uncertainty $\delta E$,
the partition function is the number of microstates with energies
$E_{r}\left(x\right)$ in the range $\left(E-\delta E,\, E\right)$:
\begin{align}
\Omega\left(E,x\right) & =\sum_{\sr{}r{E-\delta E\le E_{r}\left(x\right)\le E}}1
\end{align}
This yields:
\begin{align}
P_{r}\left(E,x\right) & =\begin{cases}
\frac{1}{\Omega\left(E,x\right)} & E-\delta E\le E_{r}\left(x\right)\le E\\
0 & \text{otherwise}
\end{cases}\label{eq:microcanonical-partition-function}
\end{align}

\end{itemize}

\section{Partition function of the ideal gas}

The external variables are $x=\left(V,N\right)$. These are \emph{extensive}
variables, i.e. if you take two of the system and consider them together,
these variables double, in contrast to \emph{intensive} variables,
which stay the same. We now proceed with the following steps:
\begin{align}
\hat{H}\left(V,N\right) & \xrightarrow{\text{1.}}\varepsilon_{r}\left(V,N\right)\xrightarrow{\text{2.}}\Omega\left(E,V,N\right)\xrightarrow{\text{3.}}\ln\left(\Omega\right)
\end{align}



\subsubsection*{Step 1: Eigenvalues of $\hat{H}\left(V,N\right)$}
\begin{itemize}
\item Form \eqref{eq:Hamiltonian-ideal-gas} we know:
\begin{align*}
\hat{H}\left(V,N\right) & =\sum_{\nu=1}^{N}\hat{h}_{\nu}
\end{align*}
So for a microstate $r=\left(n_{1},\ldots,n_{3N}\right)$ with $n_{k}\in\mathbb{N}_{\ge1}$
we have from \eqref{eq:Energy-ideal-gas}:
\begin{align}
E_{r}\left(V,N\right) & =\sum_{\nu=1}^{3N}\frac{p_{\nu}^{2}}{2m}=\sum_{\nu=1}^{3N}\frac{\pi^{2}\hbar^{2}n_{\nu}^{2}}{2mL^{2}}\label{eq:energy-ideal-gas}
\end{align}

\item \emph{Indistinguishability of particles}: When evaluating properties
of the ideal gas, we should account for the fact that in quantum mechanics,
upon exchanging particles, the wave function changes at most its sign
due to the particles indistinguishability, i.e. an exchange of two
particles yields the \emph{same state}.\\
In general for a given microstate $r=\left(n_{1},\ldots,n_{3N}\right)$
one can generate $N!$ representations of the \emph{same} macrostate
upon exchange of particle indices. Thus when counting states, we have
to take care, not to count the same microstate more than once.
\end{itemize}

\subsubsection*{Step 2: Evaluation of $\Omega\left(E,V,N\right)$}

Now we introduce:
\begin{align}
\phi\left(E,V,N\right) & :=\sum_{\sr{}r{E_{r}\left(V,N\right)\le E}}1
\end{align}
Given this, we can calculate the partition function:
\begin{align}
\Omega\left(E,V,N\right) & =\phi\left(E\right)-\phi\left(E-\delta E\right)
\end{align}
Hence we focus on $\phi$.
\begin{align*}
\phi\left(E\right) & =\underbrace{\sum_{n_{1}}\sum_{n_{2}}\ldots\sum_{n_{3N}}}_{E_{r}\le E}\frac{1}{N!}
\end{align*}
The $\frac{1}{N!}$ accounts for the indistinguishability of the particles.
The average momentum $\overline{p_{r}}$ per particle is:
\begin{align*}
\overline{p_{r}} & =\frac{\pi\hbar}{L}\overline{n_{r}}
\end{align*}
For $\overline{n_{r}}\gg1$, i.e. $\overline{p_{r}}\gg\frac{\pi\hbar}{L}$,
the steps for increasing a quantum number are small compared to the
value of $\overline{p_{r}}$ and we can replace the sums with integrals:
\begin{align}
\phi\left(E\right) & \approx\frac{1}{N!}\underbrace{\int\dd n_{1}\ldots\int\dd n_{3N}}_{E_{R}\le E}1=\frac{1}{N!}\left(\frac{L}{\pi\hbar}\right)^{3N}\underbrace{\int_{0}^{\infty}\dd p_{1}\ldots\int_{0}^{\infty}\dd p_{3N}}_{\sum_{\nu}p_{\nu}^{2}\le2mE}1=\nonumber \\
 & =\frac{1}{N!}\cdot\frac{1}{2^{3N}}\cdot\frac{1}{\left(\pi\hbar\right)^{3N}}\underbrace{\int_{-\infty}^{\infty}\dd p_{1}\ldots\int_{-\infty}^{\infty}\dd p_{3N}}_{\sum_{\nu}p_{\nu}^{2}\le2mE}\int_{0}^{L}\dd x_{1}\ldots\int_{0}^{L}\dd x_{n}1=\nonumber \\
 & =\frac{\text{phase-space volume}}{N!\cdot h^{3N}}
\end{align}
The integral
\begin{align}
\underbrace{\int_{-\infty}^{\infty}\dd p_{1}\ldots\int_{-\infty}^{\infty}\dd p_{3N}}_{\sum_{\nu}p_{\nu}^{2}\le2mE} & =V_{\sqrt{2mE}}^{3N}
\end{align}
is the volume of a $3N$-dimensional sphere of radius $\sqrt{2mE}$.
Using the $\Gamma$-function with the fundamental property $\Gamma\left(m+1\right)=m!$
for $m\in\mathbb{N}$, this volume can be expressed as:
\begin{align*}
V_{R}^{3N} & =c_{3n}R^{3N} & c_{n} & =\frac{\pi^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}+1\right)}
\end{align*}
This gives:
\begin{align}
\phi\left(E,V,N\right) & =\frac{1}{N!}\tilde{c}_{3N}V^{N}E^{\frac{3N}{2}} & \tilde{c}_{3N} & =c_{3N}\frac{\left(2m\right)^{\frac{3N}{2}}}{h^{3N}}\label{eq:phi(E-V-N)}
\end{align}
For example for $\frac{3N}{2}=10^{24}$ and $\frac{\delta E}{E}=10^{-5}$
this gives:
\begin{align*}
\frac{\phi\left(E\right)}{\phi\left(E-\delta E\right)} & =\frac{E^{10^{24}}}{\left(E-\delta E\right)^{10^{24}}}=\frac{1}{\left(1-10^{-5}\right)^{10^{24}}}\approx\left(1+\frac{10^{19}}{10^{24}}\right)^{10^{24}}\stackrel{\text{definition of exp}}{\approx}\exp\left(10^{19}\right)
\end{align*}
So we can practically neglect $\phi\left(E-\delta E\right)$:
\begin{align}
\fbox{\ensuremath{{\displaystyle \Omega\left(E,V\right)=\phi\left(E,V\right)-\phi\left(E-\delta E,V\right)\approx\phi\left(E,V\right)}}}
\end{align}
This is independent of $\delta E$.


\subsubsection*{Step 3: $\ln\left(\Omega\right)$}

With the approximation $\Gamma\left(x+1\right)\approx\left(\frac{x}{e}\right)^{x}$
with Euler's number $e\approx2{,}718$ and remembering
\begin{align*}
\Gamma\left(N+1\right) & =N!
\end{align*}
for $N\in\mathbb{N}$, we get from equation \eqref{eq:phi(E-V-N)}:

\begin{align}
\phi\left(E,V,N\right) & \approx\left(\frac{e}{N}\right)^{N}\frac{\pi^{\frac{3N}{2}}}{\left(\frac{3N}{2e}\right)^{\frac{3N}{2}}}\frac{\left(2m\right)^{\frac{3N}{2}}}{h^{3N}}V^{N}E^{\frac{3N}{2}}=\nonumber \\
 & =\left(\frac{V}{N}\right)^{N}\Bigg(\underbrace{\left(\frac{4}{3}m\pi\frac{e}{h^{2}}\right)^{\frac{3}{2}}}_{=:c}\bigg)^{N}\left(\frac{E}{N}\right)^{\frac{3N}{2}}
\end{align}
This gives the microcanonical partition function ideal gas:\stepcounter{equation}
\begin{align}
\ln\left(\Omega\left(E,V,N\right)\right) & \approx\frac{3}{2}N\ln\left(\frac{E}{N}\right)+N\ln\frac{V}{N}+N\ln\left(c\right)\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}


%DATE: Di 30.10.12

\emph{Note}: $f=3N$ is the number of degrees of freedom.
\begin{align}
\Omega\left(E\right) & \sim\left(\frac{E}{N}\right)^{\frac{3N}{2}}\sim\left(\frac{E}{f}\right)^{\gamma f}\tag{{\arabic{chapter}.\arabic{equation}b}}\label{eq:partion-fuction_deegrees_of_freedom}
\end{align}
This dependence holds also for other systems with many degrees of
freedom under the condition, that by increasing the energy also the
number of accessible states increases. This condition does not hold
in general for spin systems.

\emph{Example}:\emph{ }The energy for $N$ electrons in a magnetic
field $B$ is:
\begin{align*}
E_{r} & =2\mu_{B}\frac{B}{\hbar}\sum_{\nu=1}^{N}s_{z,\nu}
\end{align*}
So only $E\in\left[E_{\text{min}},E_{\text{max}}\right]$ is possible,
i. e. the energy is bounded by:
\begin{align*}
E_{\text{min}/\text{max}} & =\mp N\mu_{B}B
\end{align*}
Since at $E_{\text{min}}$ and $E_{\text{max}}$ only one state is
possible, \eqref{eq:partion-fuction_deegrees_of_freedom} only holds
if:
\begin{align*}
\mu_{B}B & \ll E-E_{\text{min}}\ll N\mu_{B}B
\end{align*}



\section{Thermodynamic processes and the first law}
\begin{itemize}
\item \emph{Mean value of the energy}: From the Hamiltonian $\hat{H}\left(x\right)$
we can derive the energies $E_{r}\left(x\right)$. The probabilities
$P_{r}$ then define a macrostate. This allows us to define the mean
energy of the macrostate:
\begin{align}
\overline{E}_{r} & =\sum_{\sr{}r{E-\delta E\le E_{r}\left(x\right)\le E}}P_{r}E_{r}\left(x\right)\label{eq:average-energy}
\end{align}
Because $\delta E\ll E$ holds $\overline{E}_{r}\approx E$.
\item \emph{Thermodynamic process}: Let us consider a situation whereby
the system performs a transition from a macrostate $a$ with $\overline{E}_{a}$
to a macrostate $b$ with $\overline{E}_{b}$. We are interested in:
\begin{align*}
\Delta E & =E_{b}-E_{a}
\end{align*}
\emph{Note}: A transition where $E_{b}\not=E_{a}$ can only occur,
when the system is interacting with the surroundings. The interaction
can yield a change of $x$ (and hence of $E_{r}\left(x\right)$) and/or
of $P_{r}$.
\item \emph{Heat and work}: The energy change $\Delta E$ can be decomposed
into two contributions:

\begin{enumerate}
\item The average energy changes, while the external parameters $x$ are
kept constant, so this must be due to a change of the $P_{r}$.\stepcounter{equation}
\begin{align}
\Delta E & :=\Delta Q\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}
One says the variation occurs in form of \emph{heat} transferred \emph{to}
the system.
\begin{align*}
\Delta Q & >0 &  & \text{heat is added to the system}\\
\Delta Q & <0 &  & \text{heat is extracted from the system}\\
\Delta Q & =0 &  & \text{the system is thermally isolated (adiabatic process)}
\end{align*}

\item The parameters $x$ are changed, while the system is thermally isolated.
\begin{align}
\Delta E & :=\Delta W\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
One says the variation occurs in form of \emph{work} done \emph{on}
the system.
\end{enumerate}

In general holds:
\begin{align}
\fbox{\ensuremath{\Delta E=\Delta Q+\Delta W}}\tag{\arabic{chapter}.\arabic{equation}c}\label{eq:first-law-thermodynamics}
\end{align}
This is known as the \emph{first law of thermodynamics}.


\emph{Note}: If the system is closed holds $\Delta E=0$ and even
$\Delta W=\Delta Q=0$.


\emph{Note}: The heat transfer is associated to changes in $P_{r}$.
This is because if e.g. heat is added, the states with larger energy
have larger probability of being occupied.\\
In general this implies a non-equilibrium probability distribution
during the heat transfer. After waiting long enough, a new equilibrium
configuration characterized by $P_{r}\left(E_{b},\, x_{b}\right)$
is reached.\\
If, however, the heat transfer is \emph{quasi-static}, i.e. very slow,
then one can at each instant of time use the initial probability distribution
$P_{r}\left(E,x\right)$ with the actual value of the energy.


\emph{Note}: When the $x$-parameter is changed, this in general induces
a change of $E_{r}\left(x\right)$ and $P_{r}$. This is because $E_{r}=E_{r}\left(x\right)$
and due to the time-dependent perturbation, transitions between microstates
can occur and hence $P_{r}$ can change to a non-equilibrium distribution.
But if the process is quasi-static, the change in $x$ does not induce
a change in $P_{r}$.

\item \emph{Example}:

\begin{enumerate}[label=\alph*)]
\item A container with gas is heated up. There is no change in $x$, so
$\Delta E=\Delta Q$.\\
\textcolor{green}{TODO: Abb3}
\item The volume of gas is reduce/increased. If the system is thermally
isolated, we have $\Delta E=\Delta W$.\\
\textcolor{green}{TODO: Abb4}
\end{enumerate}
\item \emph{Differentials}: Very often we shall consider infinitesimal changes.
Then equation \eqref{eq:first-law-thermodynamics} becomes:
\begin{align}
\dd E & =\dbar W+\dbar Q
\end{align}
The notation ``$\dbar$'' means, that $\Delta Q$ and $\Delta W$
are no \emph{state variables} (``\foreignlanguage{ngerman}{Zustandsgrößen}'').
In other words
\begin{align*}
\Delta W & \not=\Delta W\left(x\right) & \Delta Q & \not=\Delta Q\left(x\right)
\end{align*}
and hence are not set when e.g. the equilibrium state characterized
by $E$ and $x$ is reached (in contrast to $E=E\left(x\right)$).\\
To see, why $\dbar Q$ and $\dbar W$ are not associated to state
variables, let us look at processes, which yield the \emph{same} final
state with $E_{b}=E_{a}+\Delta E$ and $V_{a}=V_{b}$.

\begin{enumerate}[label=\roman*)]
\item The heat $\Delta Q=\Delta E$ is added.
\item The work $\Delta W=\Delta E$ is added to the system by varying in
a time dependent way the volume of the gas with $V_{a}=V_{b}$ at
the end.
\end{enumerate}

So $\dbar Q$ and $\dbar W$ are no exact differentials.However from
$E=E\left(x\right)=E\left(x_{1},\ldots,x_{n}\right)$ follows: 
\begin{align}
\dd E & =\sum_{i=1}^{n}\left(\frac{\partial E}{\partial x_{i}}\right)\dd x_{i}
\end{align}
So this is an exact differential and hence:
\begin{align*}
\oint\dd E & =0
\end{align*}
Here $\oint$ means that we are considering a cyclic process, i.e.
$E_{a}=E_{b}$.

\end{itemize}

\section{Quasi-static processes}
\begin{itemize}
\item \emph{Definition}: A process is \emph{quasi-static} if the changes
on the system are so slow, that it evolves through a sequence of \emph{equilibrium
configurations}.\\
Let $\tau_{\text{ext}}$ be the timescale, on which changes occur
(e.g. heat transfer, change in $x$) and $\tau_{\text{rel}}$ the
time, the system needs to relax to equilibrium. So a process is quasi-static
if and only if:
\begin{align*}
\tau_{\text{ext}} & \gg\tau_{\text{rel}}
\end{align*}

\item \emph{Example}:\\
\textcolor{green}{TODO: Abb5}\\
The gas is expanded by slowly moving the piston and the container
is thermally isolated. The external parameter is $x_{1}=L\left(t\right)$,
and hence the parameters characterizing the timescales are:
\begin{align*}
v_{1} & =\frac{\dd x_{1}}{\dd t} &  & \text{velocity of the piston}\\
\overline{v} &  &  & \text{average velocity of gas particles}
\end{align*}
\begin{align*}
\Rightarrow\qquad\tau_{\text{ext}}\gg\tau_{\text{rel}} & \qquad\Leftrightarrow\qquad v_{1}\ll\overline{v}
\end{align*}
Non quasi-static effects are proportional to ${\displaystyle \frac{v_{1}}{\overline{v}}}$.
Quantum numbers do not change if this is small.
\end{itemize}
%DATE: Fr 02.11.12


\subsubsection{Generalized forces}

Consider a quasi-static process where $x_{1}$ changes and $x_{2},\ldots,\, x_{n}$
remain constant. From equation \eqref{eq:average-energy} follows:
\begin{align}
\dd E & =\dd\left(\sum_{r}P_{r}E_{r}\left(x_{1},x_{2},\ldots,x_{n}\right)\right)=\sum_{r}\left(\dd P_{r}\right)E_{r}+\sum P_{r}\frac{\partial E_{r}}{\partial x_{1}}\dd x_{1}=\nonumber \\
 & =\sum_{r}\left(\dd P_{r}\right)E_{r}+\overline{\,\frac{\partial E_{r}}{\partial x_{1}}\,}\dd x_{1}\sr ={\text{quasi-static}}{}\dbar Q_{\text{qs}}+\underbrace{\frac{\overline{\partial E_{r}}}{\partial x_{1}}\dd x_{1}}_{=:\dbar W_{\text{qs}}}\sr ={\text{adiabatic}}{}\dbar W_{\text{qs}}
\end{align}

\begin{itemize}
\item \emph{Definition}: The \emph{generalized force} associated to $x_{i}$
is:
\begin{align}
X_{i} & =-\frac{\partial E\left(x_{1},x_{2},\ldots,x_{n}\right)}{\partial x_{i}}\label{eq:generalized-force}
\end{align}
\emph{Note}: The $X_{i}$ are intensive quantities, associated to
the extensive external parameters $x_{i}$.\emph{}\\
\emph{Note}: If also other parameters are exchanged, we get:
\begin{align}
\dbar W_{\text{qs}} & =-\sum_{i=1}^{n}X_{i}\dd x_{i}\label{eq:dW_qs}
\end{align}

\item \emph{Pressure}: Let us consider a gas enclosed in a container with
a piston.\textcolor{green}{}\\
\textcolor{green}{TODO: Abb6}
\begin{align*}
x_{1} & =L
\end{align*}
The gas exerts a force $F$ on the piston, so for an infinitesimal
change $\dd L$ follows:
\begin{align}
\dbar W_{\text{qs}} & =-F\dd L=-\frac{F}{A}A\dd L=-P\dd V
\end{align}
This is the work performed on the gas. Then equation \eqref{eq:dW_qs}
yields:
\begin{align*}
\dbar W_{\text{qs}} & =-X_{1}\dd x_{1}=\frac{\overline{\partial E_{r}\left(V\right)}}{\partial V}\dd V
\end{align*}
And hence we get the microscopic definition of pressure:
\begin{align}
\fbox{\ensuremath{{\displaystyle P=-\frac{\overline{\partial E_{r}\left(V\right)}}{\partial V}}}}
\end{align}
\emph{Note}: For a gas the pressure $P$ is always positive.
\begin{align}
\Rightarrow\quad & \begin{cases}
\dd V>0 & \Rightarrow\quad\dbar W_{\text{qs}}<0\quad\text{the system performs work}\\
\dd V<0 & \Rightarrow\quad\dbar W_{\text{qs}}>0\quad\text{work is done on the system}
\end{cases}
\end{align}

\end{itemize}

\subsubsection*{Pressure of an ideal gas}

Consider the quantum mechanical point of view!\\
As usual let the gas of $N$ particles be contained in a box of volume
$V=L_{1}L_{2}L_{3}$.\\
Now we vary $x_{1}=L_{1}$. From equation \eqref{eq:average-energy}
we get:
\begin{align*}
E_{r}\left(V,N\right) & =\sum_{\nu=1}^{N}\sum_{j=1}^{3}\frac{\hbar^{2}\pi^{2}}{2mL_{j}^{2}}n_{3\nu+j-3}^{2}
\end{align*}
\begin{align*}
\dbar W_{\text{qs}} & =\frac{\overline{\partial E_{r}}}{\partial L_{1}}\dd L_{1}=-\frac{2}{L_{1}}\sum_{\nu=1}^{N}\frac{\hbar^{2}\pi^{2}}{2mL_{1}^{2}}n_{3\nu-2}^{2}\dd L_{1}
\end{align*}
In equilibrium all accessible states are equiprobable, therefore all
impulse directions are equiprobable and hence the average kinetic
energy is the same for all three directions:
\begin{align*}
\overline{\sum_{\nu=1}^{N}\frac{\hbar^{2}\pi^{2}}{2mL_{1}^{2}}n_{3\nu-2}^{2}} & =\frac{1}{3}\sum_{j=1}^{3}\sum_{\nu=1}^{N}\frac{\hbar^{2}\pi^{2}}{2mL_{j}^{2}}n_{3\nu+j-3}^{2}=\frac{1}{3}\overline{E_{r}}=\frac{E}{3}
\end{align*}
Hence we get:
\begin{align}
\dbar W_{\text{qs}} & =-\frac{2}{L_{1}}\frac{E}{3}\dd L_{1}=-\frac{2}{3}\frac{E}{V}\dd V
\end{align}
This gives the pressure for the ideal gas:
\begin{align}
\fbox{\ensuremath{{\displaystyle P=\frac{2}{3}\frac{E}{V}}}}
\end{align}
\emph{Note}: The classical description is discussed by \noun{Fließbach}
in chapter 8, page 60.

\emph{Note on reversible and irreversible processes}: Corrections
to the quasi-static result are of the order of ${\displaystyle \frac{v_{1}}{\overline{v}}}$
with ${\displaystyle v_{1}=\frac{\dd x_{1}}{\dd t}}$. For a generic
process thus follows:
\begin{align}
\frac{\dd E}{E} & =\left(\frac{\dd E}{E}\right)_{\text{qs}}+\mathcal{O}_{0}\left(\frac{v_{1}}{\overline{v}}\right)=\left(\frac{\dd E}{E}\right)_{\text{reversible}}+\left(\frac{\dd E}{E}\right)_{\text{irreversible}}
\end{align}
Here the reversible part would vanish when considering a full expansion-compression
cycle. The second term does not vanish and accounts for the positive
increase of energy due to the conversion of work into heat. In general
holds:
\begin{align}
\dbar W & \ge\dbar W_{\text{qs}}
\end{align}



\section{Entropy and temperature}

Consider two systems $A$ and $B$ in thermal contact with each other
and with the external parameters $x_{A}$ and $x_{B}$ kept constant.

\textcolor{green}{TODO: Abb7}

How is the total energy
\begin{align*}
E & =E_{B}+E_{A}
\end{align*}
distributed in equilibrium? Or equivalently, what is the probability
$W(E_{A})$ for an energy $E_{A}$?
\begin{enumerate}[label=\roman*)]
\item Step: In equilibrium all of the accessible states of the \emph{total}
system are equiprobable:
\begin{align*}
P_{r} & =\frac{1}{\Omega_{0}\left(E\right)}
\end{align*}
$\Omega_{0}\left(E\right)$ is the partition function of the composite
system.
\item Step:
\begin{align}
W\left(E_{A}\right) & =\sum_{\sr{}r{E_{A},E_{B}=E-E_{A}}}P_{r}=\sum_{E_{r,A}=E_{A}}\sum_{E_{r,B}=E-E_{A}}\frac{1}{\Omega_{0}\left(E\right)}=\frac{\Omega_{A}\left(E_{A}\right)\Omega_{B}\left(E-E_{A}\right)}{\Omega_{0}\left(E\right)}
\end{align}

\item Step: Remember now equation \eqref{eq:partion-fuction_deegrees_of_freedom}:
\begin{align*}
\Omega\left(E\right) & =c\left(\frac{E}{f}\right)^{\gamma f} & \gamma & \approx1
\end{align*}
Assuming $\gamma_{A}=\gamma_{B}=\gamma$ we get:
\begin{align*}
\Rightarrow\quad\ln\left(W\left(E_{A}\right)\right) & =\ln\left(\Omega_{A}\left(E_{A}\right)\right)+\ln\left(\Omega_{B}\left(E-E_{A}\right)\right)-\ln\Omega_{0}\left(E\right)=\\
 & =\gamma f_{A}\ln E_{A}+\gamma f_{B}\ln\left(E-E_{A}\right)+\text{const.}
\end{align*}

\end{enumerate}
The function $\ln\left(W\left(E_{A}\right)\right)$ has a maximum
in the interval $\left[0,E\right]$ set by:
\begin{align*}
\frac{\dd}{\dd E_{A}}\ln\left(W\left(E_{A}\right)\right) & =\frac{\gamma f_{A}}{E_{A}}-\frac{\gamma f_{B}}{E-E_{A}}\stackrel{!}{=}0
\end{align*}
So we have a maximum at $E_{A,\text{max}}=\overline{E_{A}}$ with:
\begin{align}
\frac{\overline{E_{A}}}{f_{A}} & =\frac{\overline{E_{B}}}{f_{B}}\label{eq:energy-per-degree-of-freedom-constant}\\
\overline{E_{B}} & =E-\overline{E_{A}}\nonumber 
\end{align}
So the energy per degree of freedom is the same in the system $A$
and $B$!
\begin{itemize}
\item Expanding about the maximum yields:
\begin{align*}
\ln\left(W\left(E_{A}\right)\right) & \approx\ln\left(W\left(\overline{E}_{A}\right)\right)-\frac{\left(E-\overline{E}_{A}\right)^{2}}{2\Delta E_{A}^{2}}\\
\Rightarrow\quad W\left(E_{A}\right) & =W\left(\overline{E}_{A}\right)e^{-\frac{\left(E-\overline{E}_{A}\right)^{2}}{2\Delta E_{\! A}^{2}}}
\end{align*}
\begin{align}
\frac{1}{\Delta E_{A}^{2}} & =-\frac{\dd^{2}\ln W}{\dd E_{A}^{2}}=\frac{\gamma f_{A}}{\overline{E}_{A}^{2}}+\frac{\gamma f_{B}}{\overline{E}_{B}^{2}}
\end{align}
This equation gives:
\begin{align*}
\Delta E_{A} & =\left(\frac{\gamma f_{A}}{\overline{E}_{A}^{2}}+\frac{\gamma f_{B}}{\overline{E}_{B}^{2}}\right)^{-\frac{1}{2}}<\frac{\overline{E}_{A}}{\sqrt{\gamma f_{A}}}
\end{align*}
So if $f_{A}$ is very large, the probability $W\left(E_{A}\right)$
sharply peaked around $\overline{E}_{A}$:
\begin{align}
W\left(E_{A}\right) & \approx\begin{cases}
W\left(\overline{E}_{A}\right) & E_{A}=\overline{E_{A}}\\
0 & \text{otherwise}
\end{cases}
\end{align}
This means $E_{A}=\overline{E}_{A}$ with $\overline{E}_{A}$ given
by \eqref{eq:energy-per-degree-of-freedom-constant} sets the condition
for equilibrium after heat exchange.
\item \emph{Entropy} $S$ and \emph{temperature} $T$ are defined as:
\begin{align}
S & =S\left(E,x\right):=k_{B}\cdot\ln\left(\Omega\left(E,\, x\right)\right) &  & \text{Entropy}\\
\frac{1}{T} & =\frac{1}{T\left(E,x\right)}:=\frac{\partial S\left(E,x\right)}{\partial E} &  & \text{Temperature}
\end{align}
Here $\Omega$ is the multiplicity of the considered system and $k_{B}$
is the Boltzmann constant:
\begin{align*}
k_{B} & \approx1{,}38\cdot10^{-23}\,\frac{\text{J}}{\text{K}}
\end{align*}

\item The equilibrium condition yields:
\begin{align*}
\ln\left(\Omega_{A}\left(E_{A}\right)\Omega_{B}\left(E-E_{A}\right)\right) & =\text{max.}
\end{align*}
\begin{align}
\Leftrightarrow\qquad S\left(E_{A}\right) & =k_{B}\ln\left(\Omega_{A}\Omega_{B}\right)=S_{A}\left(E_{A},x\right)+S_{B}\left(E-E_{A},x\right)=\text{max.}
\end{align}
This means:
\begin{align}
0 & =\frac{\partial S}{\partial E_{A}}=\frac{\partial S_{A}}{\partial E_{A}}-\frac{\partial S_{B}}{\partial E_{B}}\nonumber \\
\Leftrightarrow\quad T_{A} & =T_{B}
\end{align}
So a temperature difference induces an exchange of heat.


\emph{Notes}:
\begin{enumerate}[label=\roman*)]
\item Entropy is additive and therefore an extensive variable.
\item If there is only one accessible microstate, i.e. $\Omega=1$, then
follows $S=0$.
\item The temperature is a measure of the mean energy per degree of freedom.
Indeed we have:
\begin{align*}
\Omega & \sim\left(\frac{E}{f}\right)^{\gamma f}
\end{align*}
\begin{align*}
\frac{1}{k_{B}T} & =\frac{1}{k_{B}}\frac{\partial S}{\partial E}=\frac{\partial}{\partial E}\ln\left(\Omega\left(E,V\right)\right)=\frac{\gamma f}{E}
\end{align*}
Now follows:
\begin{align}
\fbox{\ensuremath{{\displaystyle k_{B}T=\frac{E}{\gamma f}}}}
\end{align}
Because $E$ is the energy of the excitations, it is non negative
and therefore $T\ge0$.\\
Note, that we are going to find for some special systems, where this
law does not hold, negative temperatures.
\end{enumerate}
\end{itemize}
%DATE: Di 6.11.12
\begin{itemize}
\item We consider the case, where the system can also have energy exchange
via variation of $x$. In equilibrium the probability $W(E,x)$ is
proportional to the number of configurations $\Omega\left(E,x\right)$
with a proportionality constant $C$:
\begin{align*}
W(E,x) & =C\Omega\left(E,x\right)=C\exp\left(\frac{S\left(E,x\right)}{k_{B}}\right)
\end{align*}
Upon expanding $\ln\left(W\left(x\right)\right)$ around the maximum
of $S\left(E,x\right)$ at $\overline{x}$ and performing the same
steps as for $W\left(E_{A}\right)$ we obtain $\left(x=x_{A}\right)$:
\begin{align*}
W\left(x\right) & =\frac{1}{\sqrt{2\pi}\Delta x}\exp\left(-\frac{\left(x-\overline{x}\right)^{2}}{2\left(\Delta x\right)^{2}}+\mathcal{O}_{0}\left(x-\overline{x}\right)^{3}\right)\\
\Delta x & =\sqrt{\frac{-k_{B}}{\frac{\partial^{2}S}{\partial x^{2}}\big|_{x=\overline{x}}}}
\end{align*}
Since $x$ is extensive, it holds $x=\mathcal{O}_{\infty}\left(N\right)$.
Additionally we get
\begin{align*}
\Delta x & =\mathcal{O}_{\infty}\left(\left(\frac{N}{N^{2}}\right)^{-\frac{1}{2}}\right)=\mathcal{O}_{\infty}\left(\sqrt{N}\right)
\end{align*}
and thus:
\begin{align*}
\frac{\Delta x}{x} & =\mathcal{O}_{\infty}\left(\frac{1}{\sqrt{N}}\right)\xrightarrow{N\to\infty}0
\end{align*}
Hence again all microstates are located at the maximum for very large
$N$. And hence the maximum determines also the equilibrium configuration:
\begin{align}
\fbox{\ensuremath{{\displaystyle S\left(E,x\right)=\text{max.}}}}\label{eq:equilibrium-condition}
\end{align}

\end{itemize}

\section{Generalized forces}

We have introduced the generalized forces in equation \eqref{eq:generalized-force}
as:
\begin{align*}
X_{i} & =-\overline{\frac{\partial E_{r}\left(x\right)}{\partial x_{i}}}
\end{align*}
Let us now consider:
\begin{align*}
\frac{\partial}{\partial x_{i}}\ln\Omega\left(E,x\right) & =\frac{\ln\left(\Omega\left(E,x+\dd x_{i}\right)\right)-\ln\left(\Omega\left(E,x\right)\right)}{\dd x_{i}}\stackrel{\star}{=}X_{i}\frac{\partial\ln\Omega}{\partial E}=\frac{X_{i}}{k_{B}T}
\end{align*}
For $\star$ compare \noun{Fließbach}, chapter 10, page 78. This yields:
\begin{align}
\fbox{\ensuremath{{\displaystyle X_{i}=k_{B}T\frac{\partial\ln\Omega\left(E,x\right)}{\partial x_{i}}=T\frac{\partial S\left(E,x\right)}{\partial x_{i}}}}}
\end{align}
This equation will provide e. g. the caloric equation of state.
\begin{itemize}
\item \emph{Example}: For $x=V$ we have $X=P$ and hence:
\begin{align*}
P & =T\frac{\partial S\left(E,V\right)}{\partial V}
\end{align*}

\item \emph{Note}: The equilibrium condition \eqref{eq:equilibrium-condition}
corresponds to the equality of the associated generalized forces.\\
\textcolor{green}{TODO: Abb8}
\begin{align*}
E & =E_{A}+E_{B}=\text{const.}\\
V & =V_{A}+V_{B}=\text{const.}
\end{align*}
In equilibrium holds:
\begin{align*}
S\left(E_{A},V_{A}\right) & =S_{A}\left(E_{A},V_{A}\right)+S_{B}\left(E-E_{A},V-V_{A}\right)=\text{max.}
\end{align*}
Then follows:
\begin{align*}
\frac{\partial S}{\partial E_{A}} & =0 & \Rightarrow\qquad\frac{1}{T_{A}}-\frac{1}{T_{B}} & =0 & \Leftrightarrow\qquad T_{A} & =T_{B}\\
\frac{\partial S}{\partial V_{A}} & =0 & \Rightarrow\qquad\frac{P_{A}}{T_{A}}-\frac{P_{B}}{T_{B}} & =0 & \Leftrightarrow\qquad P_{A} & =P_{B}
\end{align*}

\item \emph{Note on differentials}:\stepcounter{equation}
\begin{align}
S\left(E,x\right)\quad\Rightarrow\quad\dd S & =\frac{\partial S}{\partial E}\dd E+\sum_{i}\frac{\partial S}{\partial x_{i}}\dd x_{i}\nonumber \\
\dd S & =\frac{1}{T}\dd E+\frac{1}{T}\sum_{i}X_{i}\dd x_{i}\tag{\arabic{chapter}.\arabic{equation}a}\label{eq:dS_1TdE+1TXdx}\\
\dd E & =T\dd S-\sum_{i}X_{i}\dd x_{i}\tag{\arabic{chapter}.\arabic{equation}b}\label{eq:dE_TdS-Xdx}
\end{align}

\end{itemize}

\section{Chemical potential}

So far, we have considered situations with fixed $N$. However, there
can be cases, where $N$ changes. In this case, we define the \emph{chemical
potential} $\mu$ as the negative generalized force associated to
$N$:
\begin{align}
\fbox{\ensuremath{{\displaystyle \mu:=-k_{B}T\frac{\partial\ln\Omega\left(E,N\right)}{\partial N}}}}\label{eq:chemisches-Potential}
\end{align}
Hence follows:
\begin{align*}
\mu & \stackrel{\text{definiton of }S}{=}-T\frac{\partial S\left(E,N,V\right)}{\partial N}\stackrel{\text{definition of }T}{=}\frac{\partial E\left(S,N,V\right)}{\partial N}
\end{align*}
It is the energy necessary to add an extra particle to the system.

\emph{Note}: From \eqref{eq:dE_TdS-Xdx} and \eqref{eq:chemisches-Potential}
follows with $E=E\left(V,N\right)$ the \emph{Gibbs fundamental form}:
\begin{align}
\fbox{\ensuremath{{\displaystyle \dd E=T\dd S-P\dd V+\mu\dd N}}}
\end{align}



\subsubsection{Equilibrium condition for exchange of heat, volume and particle number}

\textcolor{green}{TODO: Abb9}

\begin{align*}
E & =E_{A}+E_{B}=\text{const.}\\
V & =V_{A}+V_{B}=\text{const.}\\
N & =N_{A}+N_{B}=\text{const.}
\end{align*}
From $S\left(E_{A},V_{A},N_{A}\right)=\text{max.}$ we get:
\begin{align*}
T_{A} & =T_{B} & P_{A} & =P_{B} & \mu_{A} & =\mu_{B}
\end{align*}
In general the generalized forces are the same in equilibrium.


\section{Thermodynamic potentials}

Depending on which variables are varied in a thermodynamic process,
it might be convenient to introduce a specific thermodynamic function,
which is a \emph{state function} with \emph{dimension of energy}.
Given a system with energy $E=E\left(S,V,N\right)$ one introduces:
\begin{itemize}
\item \emph{Internal energy}:\stepcounter{equation}
\begin{align}
E\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}

\item \emph{Free energy}:
\begin{align}
F & =E-TS\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}

\item \emph{Enthalpy}:
\begin{align}
H & =E+PV\tag{\arabic{chapter}.\arabic{equation}c}
\end{align}

\item \emph{Free enthalpy} also called \emph{Gibbs energy}:
\begin{align}
G & =E-TS+PV\tag{\arabic{chapter}.\arabic{equation}d}\label{eq:gibbs_enthalpy}
\end{align}

\end{itemize}
Then follows:\stepcounter{equation}
\begin{align}
\dd E & =\phantom{-}T\dd S-P\dd V+\mu\dd N\tag{\arabic{chapter}.\arabic{equation}a}\label{eq:dE}\\
\dd F & =-S\dd T-P\dd V+\mu\dd N\tag{\arabic{chapter}.\arabic{equation}b}\\
\dd H & =\phantom{-}T\dd S+V\dd P+\mu\dd N\tag{\arabic{chapter}.\arabic{equation}c}\\
\dd G & =-S\dd T+V\dd P+\mu\dd N\tag{\arabic{chapter}.\arabic{equation}d}\label{eq:dG}
\end{align}
The \emph{natural variables} are therefore:
\begin{align*}
E & =E\left(S,V,N\right)\\
F & =F\left(T,V,N\right)\\
H & =H\left(S,P,N\right)\\
G & =G\left(T,P,N\right)
\end{align*}
A fifth thermodynamic potential of interest for later purposes is:\stepcounter{equation}
\begin{align}
J & =E-TS-\mu N=F-\mu N\tag{\arabic{chapter}.\arabic{equation}a}\label{eq:J}\\
\dd J & =-S\dd T-P\dd V-N\dd\mu\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
In this case the natural variables are:
\begin{align*}
J & =J\left(T,V,\mu\right)
\end{align*}



\subsubsection{Equilibrium conditions}

How does the equilibrium condition ``$S$ maximal'' for the closed
system $A+B$ translate to equilibrium conditions for the thermodynamic
potentials?\stepcounter{equation}
\begin{align}
E_{A}\text{ is minimal given } & S,V,N.\tag{\arabic{chapter}.\arabic{equation}a}\\
F_{A}\text{ is minimal given } & T,V,N.\tag{\arabic{chapter}.\arabic{equation}b}\label{eq:free-energy}\\
H_{A}\text{ is minimal given } & T,P,N.\tag{\arabic{chapter}.\arabic{equation}c}\\
G_{A}\text{ is minimal given } & S,P,N.\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}


Let us proof e.g. \eqref{eq:free-energy}:

We start again from $A$ and $B$ being in thermal contact with each
other. Let us assume, that $A$ is much smaller than $B$, i.e. $B$
acts as a thermal bath:
\begin{align*}
E_{A} & \ll E=E_{A}+E_{B}\\
V_{A} & \ll V=V_{A}+V_{B}
\end{align*}
Therefore the contact with $B$ fixes $T:=T_{B}$ and $P:=P_{B}$
for the system $A$. Suppose now only heat is exchanged.
\begin{align*}
S\left(E_{A}\right) & =S_{A}\left(E_{A},V_{A}\right)+S_{B}\left(E-E_{A},V_{B}\right)=\text{max.}
\end{align*}
Taylor expanding yields:
\begin{align*}
S & =S_{A}+S_{B}\left(E,V_{B}\right)-\frac{\partial S_{B}\left(E_{B},V_{B}\right)}{\partial E_{B}}E_{A}=\\
 & =\text{const.}+S_{A}-\frac{E_{A}}{T}=\text{max.}
\end{align*}
So $S$ being maximal is equivalent to:
\begin{align*}
F_{A} & =E_{A}-TS_{A}=\text{min.}
\end{align*}



\subsubsection{Relation between $G$ and $\mu$}

From $G=G\left(T,P,N\right)$ follows, because $G$ is an extensive
quantity and among $T,P$ and $N$ only $N$ is extensive:
\begin{align*}
G & =N\cdot g\left(T,P\right)
\end{align*}
From \eqref{eq:dG} follows:
\begin{align}
\mu & =\frac{\partial G\left(T,P,N\right)}{\partial N}=g\left(T,P\right)=\frac{G}{N}\nonumber \\
\Rightarrow\quad G & =N\mu\label{eq:G_Nmu}
\end{align}
Moreover holds:
\begin{align*}
\mu\dd N+N\dd\mu=\dd G & \stackrel{\eqref{eq:gibbs_enthalpy}}{=}-S\dd T+V\dd P+\mu\dd N\\
\Rightarrow\qquad\dd\mu & =-\frac{S}{N}\dd T+\frac{V}{N}\dd P:=-s\dd T+v\dd P
\end{align*}
This is the \emph{Duhem-Gibbs relation} and so $\mu=\mu\left(P,T\right)$.
The equilibrium condition demands $\mu$ to be minimal.\\
Finally, \eqref{eq:gibbs_enthalpy} and \eqref{eq:G_Nmu} imply:
\begin{align}
\fbox{\ensuremath{{\displaystyle J=E-TS-\mu N=-PV}}}\label{eq:J_-PV}
\end{align}
For applications see the thermodynamic part of the integrated course
IIa.

%DATE: Fr 9.11.12


\section{Second and third law of thermodynamics}


\subsubsection*{Second law}
\begin{itemize}
\item \emph{Closed system}: We have demonstrated that a closed system tends
to an equilibrium situation, whereby the entropy $S$ acquires its
maximal value. So in a process $a\to b$ the entropy change is:
\begin{align*}
\Delta S & =S_{b}-S_{a}\ge0
\end{align*}
This is the \emph{second law} of thermodynamics for \emph{closed}
systems:
\begin{align}
\fbox{\ensuremath{{\displaystyle \Delta S\ge0}}}
\end{align}

\item \emph{Open system}: Let us consider the differential of the entropy
\eqref{eq:dS_1TdE+1TXdx}:
\begin{align*}
\dd S & =\frac{\dd E}{T}+\frac{1}{T}\sum_{i=1}^{n}X_{i}\dd x_{i}\stackrel{\eqref{eq:dW_qs}}{=}\frac{\dd E}{T}-\frac{\dd W_{\text{qs}}}{T}=\\
 & \stackrel{\text{1.law}}{=}\frac{1}{T}\left(\dbar Q+\dbar W-\dbar W_{\text{qs}}\right)
\end{align*}
So for a quasi-static process holds:
\begin{align}
\fbox{\ensuremath{{\displaystyle \dd S_{\text{qs}}=\frac{\dbar Q_{\text{qs}}}{T}}}}
\end{align}
From $\dbar W\ge\dbar W_{\text{qs}}$ follows directly the \emph{second
law} of thermodynamics for \emph{open} systems:
\begin{align}
\fbox{\ensuremath{{\displaystyle \dd S\ge\frac{\dbar Q}{T}}}}
\end{align}

\end{itemize}

\subsubsection*{Third Law}

Now we investigate the limiting behavior of the entropy for $E\to0$.

When lowering the energy the system approaches the lowest lying states
and in particular its ground state with energy $E_{0}$. Corresponding
to $E_{0}$, there exists usually only one possible state of the system,
or, if the ground state is degenerate, only a small number of states.
In this low temperature regime $\Omega\approx f$ and hence:
\begin{align*}
S & \approx k_{B}\ln\left(f\right)
\end{align*}
At higher energies holds
\begin{align*}
\Omega & \sim\left(E-E_{0}\right)^{\gamma f}
\end{align*}
and hence:
\begin{align*}
S & \approx k_{B}\gamma f\ln\left(E-E_{0}\right)\sim k_{B}\gamma f
\end{align*}
Because we have many degrees of freedom, it follows:
\begin{align*}
k_{B}\ln f & \ll k_{B}\gamma f
\end{align*}
Therefore the following is an excellent approximation:\stepcounter{equation}
\begin{align}
\fbox{\ensuremath{{\displaystyle S\xrightarrow{E\to E_{0}}0}}}\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}
Due to ${\displaystyle \frac{\partial S}{\partial E}>0}$ follows
that with $E\to E_{0}$ also converges $T\to T_{0}$, whereby $T_{0}$
is the smallest achievable temperature. Now the \emph{third law},
also called \emph{Nernst theorem}, states:
\begin{align}
\fbox{\ensuremath{{\displaystyle S\xrightarrow{T\to T_{0}}0}}}\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
\emph{Note}:
\begin{align}
\frac{1}{k_{B}T} & =\frac{\partial\ln\Omega}{\partial E}\approx\frac{\gamma f}{E-E_{0}}\xrightarrow{E\to E_{0}}\infty\nonumber \\
k_{B}T & \xrightarrow{E\to E_{0}}0\nonumber \\
\Rightarrow\qquad T_{0} & =0\tag{\arabic{chapter}.\arabic{equation}c}
\end{align}



\chapter{Statistical ensembles}


\section{Partition functions}

\emph{Recall}: The microcanonical partition function $\Omega\left(E,x\right)$
defines the equilibrium state given by the energy $E$ of a closed
system via the relation \eqref{eq:microcanonical-partition-function}:
\begin{align*}
P_{r}\left(E,x\right) & =\begin{cases}
\frac{1}{\Omega\left(E,x\right)} & E-\delta E\le E_{r}\le E\\
0 & \text{otherwise}
\end{cases}
\end{align*}
The ensemble with such a probability is called \emph{microcanonical}.


\subsubsection*{Canonical ensemble}

Similarly, we wish to determine the probability for a subsystem, which
can exchange heat with a heat bath of temperature $T$. The statistical
ensemble defined now by $P_{r}\left(T,x\right)$ is called \emph{canonical}.
\begin{align}
P_{r} & =\begin{cases}
P_{r}\left(E,x\right) & \text{microcanonical}\\
P_{r}\left(T,x\right) & \text{canonical (Gibbs ensemble)}
\end{cases}
\end{align}
\textcolor{green}{TODO: Abb10}

Now let us determine $P_{r}$ for the canonical ensemble: The subsystem
$A$ can exchange energy (in form of heat) with a thermal bath $B$.
\begin{align*}
A+B & =\text{closed}\\
\Rightarrow\quad E_{A}+E_{B} & =\text{const.}
\end{align*}

\begin{enumerate}[label=\roman*)]
\item The energies $\left\{ E_{r}\right\} $ of the small system should
be much smaller than the total energy $E$:
\begin{align}
E_{r} & \ll E
\end{align}

\item The probability that $A$ is in a given state $r$ is:
\begin{align}
P_{r} & =\frac{\overbrace{1}^{A\text{ is in }r}\cdot\Omega_{B}\left(E-E_{r}\right)}{\Omega\left(E\right)}
\end{align}

\item A Taylor expansion yields:
\begin{align*}
\ln\left(\Omega_{B}\left(E-E_{r}\right)\right) & \approx\ln\left(\Omega_{B}\left(E\right)\right)-\frac{\partial}{\partial E}\ln\left(\Omega_{B}\left(E\right)\right)\cdot E_{r}=\\
 & =\ln\left(\Omega_{B}\left(E\right)\right)-\frac{E_{r}}{k_{B}T}
\end{align*}
\begin{align*}
\Rightarrow\quad\Omega_{B}\left(E-E_{r}\right) & \approx\Omega_{B}\left(E\right)e^{-\beta E_{r}\left(x\right)} & \beta & :=\frac{1}{k_{B}T}
\end{align*}
This gives the \emph{Boltzmann distribution}:
\begin{align}
\fbox{\ensuremath{{\displaystyle P_{r}\left(T,x\right)=\frac{1}{Z}e^{-\beta E_{r}\left(x\right)}}}}
\end{align}
From
\begin{align*}
\sum_{r}P_{r} & =1
\end{align*}
follows for the \emph{canonical partition function}:
\begin{align}
\fbox{\ensuremath{{\displaystyle Z=\sum_{r}e^{-\beta E_{r}}}}}\label{eq:can_part_f}
\end{align}

\end{enumerate}

\subsubsection*{Grandcanonical Ensemble}

Analogously one can determine the probability
\begin{align}
P_{r} & =P_{r}\left(T,x,\mu\right)
\end{align}
of occurrence of $r$ for the \emph{grandcanonical ensemble}, when
particles and heat can be exchanged with a bath characterized by $T$
and $\mu$. The probability is now calculated:

\textcolor{green}{TODO: Abb11}
\begin{align*}
E_{A}+E_{B} & =\text{const.}\\
N_{A}+N_{B} & =\text{const.}
\end{align*}

\begin{enumerate}[label=\roman*)]
\item $E_{r}\ll E$, $N_{r}\ll N$
\item ${\displaystyle P_{r}=\frac{1\cdot\Omega_{B}\left(E-E_{r},N-N_{r}\right)}{\Omega\left(E,N\right)}}$
\item $\ln\left(\Omega_{B}\left(E-E_{r},N-N_{r}\right)\right)\approx\ln\left(\Omega_{B}\left(E,N\right)\right)-\beta E_{r}+\beta\mu N_{r}$
\begin{align*}
\Omega_{B}\left(E-E_{r},N-N_{r}\right) & =\Omega_{B}\left(E,N\right)\cdot\exp\left(-\beta\left(E_{r}\left(x,N_{r}\right)-\mu N_{r}\right)\right)
\end{align*}
And hence follow the \emph{grandcanonical probability}
\begin{align}
P_{r}\left(T,x,\mu\right) & =\frac{1}{Y}e^{-\beta\left(E_{r}-\mu N_{r}\right)}
\end{align}
and the \emph{grandcanonical partition function}:
\begin{align}
\fbox{\ensuremath{{\displaystyle Y=\sum_{r}e^{-\beta\left(E_{r}-\mu N_{r}\right)}}}}\label{eq:grand-can_partition_funktion}
\end{align}
\emph{Note}: In general we have $r=\left(r',N_{r}\right)$, whereby
$r'$ is the microstate for a given particle number $N_{r}$ and hence:
\begin{align*}
Y\left(T,x,\mu\right) & =\sum_{N_{r}=0}^{N}\sum_{r'}e^{-\beta\left(E_{r'}-\mu N_{r}\right)}\approx\sum_{N'=0}^{\infty}Z\left(T,x,N'\right)e^{\beta\mu N'}
\end{align*}

\end{enumerate}

\section{Relation to the thermodynamic potentials}

Similar to the case of the microcanonical ensemble, knowledge of $Z$
or $Y$ is enough to determine all relevant thermodynamic quantities
and thermodynamic relations (e.g. the caloric equation of state).
\begin{align*}
\hat{H}\left(V,N\right) & \to E_{r}\left(V,N\right)\to\left\{ \begin{array}{c}
\Omega\left(E,V,N\right)\to S\left(E,V,N\right)\\
Z\left(T,V,N\right)\to F\left(T,V,N\right)\\
Y\left(T,V,\mu\right)\to J\left(T,V,\mu\right)
\end{array}\right.\to\text{all thermodynamic relations}
\end{align*}


%DATE: Di 13.11.12
\begin{enumerate}[label=\roman*)]
\item \emph{Relation between $Z$ and $F$}:
\begin{align*}
Z & =Z\left(T,V,N\right)\\
\Rightarrow\qquad\dd\left(\ln Z\right) & \stackrel{\beta=\frac{1}{k_{B}T}}{=}\frac{\partial\ln\left(Z\right)}{\partial\beta}\dd\beta+\frac{\partial\ln\left(Z\right)}{\partial V}\dd V+\frac{\partial\ln\left(Z\right)}{\partial N}\dd N
\end{align*}
From \eqref{eq:can_part_f} we know:
\begin{align*}
Z & =\sum_{r}e^{-\beta E_{r}}
\end{align*}
\begin{align}
\frac{\partial\ln\left(Z\right)}{\partial\beta} & =\frac{1}{Z}\frac{\partial Z}{\partial\beta}=-\frac{1}{Z}\sum_{r}E_{r}e^{-\beta E_{r}}=-\sum_{r}E_{r}P_{r}=-\overline{E_{r}}=-E\\
\frac{\partial\ln\left(Z\right)}{\partial V} & =\frac{1}{Z}\frac{\partial Z}{\partial V}=-\frac{\beta}{Z}\sum_{r}\frac{\partial E_{r}}{\partial V}e^{-\beta E_{r}}=-\beta\overline{\frac{\partial E_{r}}{\partial V}}=\beta P\\
\frac{\partial\ln\left(Z\right)}{\partial N} & =\frac{1}{Z}\frac{\partial Z}{\partial N}=-\frac{\beta}{Z}\sum_{r}\frac{\partial E_{r}}{\partial N}e^{-\beta E_{r}}=-\beta\overline{\frac{\partial E_{r}}{\partial N}}=-\beta\mu
\end{align}
So we get
\begin{align*}
\dd\left(\ln\left(Z\left(\beta,V,N\right)\right)\right) & =-E\dd\beta+\beta P\dd V-\beta\mu\dd N
\end{align*}
and thus:
\begin{align*}
\dd\left(\ln\left(Z\right)+\beta E\right) & =\beta\left(\dd E+P\dd V-\mu\dd N\right)\stackrel{\eqref{eq:dE}}{=}\beta T\dd S=\frac{\dd S}{k_{B}}
\end{align*}
This gives:
\begin{align}
S & =k_{B}\left(\ln\left(Z\right)+\beta E\right)+\text{const.}\label{eq:S_lnZ}
\end{align}
To determine the constant, let us consider a quantum mechanical system
with energies $E_{0}<E_{1}<E_{2}<\ldots$ and $\Delta:=E_{1}-E_{0}$.
(Here we assume that there is no degeneracy.)
\begin{align*}
Z & =e^{-\beta E_{0}}+e^{-\beta E_{1}}+\ldots\\
 & =e^{-\beta E_{0}}\left(1+e^{-\beta\Delta}+\ldots\right)\xrightarrow[\beta\to\infty]{T\to0\ \left(k_{B}T\ll\Delta\right)}e^{-\beta E_{0}}\\
\Rightarrow\qquad\ln\left(Z\right) & \xrightarrow{T\to0}-\beta E_{0}
\end{align*}
Likewise follows:
\begin{align*}
E & =\overline{E_{r}}=E_{0}+E_{1}e^{-\beta\Delta}+\ldots\xrightarrow{T\to0}E_{0}
\end{align*}
From the third law $S\xrightarrow{T\to0}0$ follows with \eqref{eq:S_lnZ}:
\begin{align*}
\text{const.} & =S-k_{B}\left(\ln Z+\beta E\right)\xrightarrow{T\to0}0-k_{B}\left(-\beta E_{0}+\beta E_{0}\right)=0
\end{align*}
\begin{align}
\Rightarrow\qquad\fbox{\ensuremath{{\displaystyle E-TS=F=-k_{B}T\ln Z}}}
\end{align}

\item \emph{Relation between $Y$ and $J$}: One proceeds analogously:
\begin{align*}
Y & =\sum_{r}e^{-\beta\left(E_{r}-\mu N_{r}\right)}
\end{align*}
\begin{align}
\frac{\partial\ln\left(Y\right)}{\partial\beta} & =-\frac{1}{Y}\sum_{r}\left(E_{r}-\mu N_{r}\right)e^{-\beta\left(E_{r}-\mu N_{r}\right)}=-\overline{\left(E_{r}-\mu N_{r}\right)}=-E+\mu N\\
\frac{\partial\ln\left(Y\right)}{\partial V} & =-\frac{\beta}{Y}\sum_{r}\frac{\partial E_{r}}{\partial V}e^{-\beta\left(E_{r}-\mu N_{r}\right)}=-\beta\overline{\left(\frac{\partial E_{r}}{\partial V}\right)}=\beta P\\
\frac{\partial\ln\left(Y\right)}{\partial\mu} & =-\frac{\beta}{Y}\sum_{r}\left(-N_{r}\right)e^{-\beta\left(E_{r}-\mu N_{r}\right)}=\beta\overline{N_{r}}=\beta N
\end{align}
\begin{align*}
\dd\left(\ln\left(Y\left(\beta,V,\mu\right)\right)\right) & =\frac{\partial\ln Y}{\partial\beta}\dd\beta+\frac{\partial\ln Y}{\partial V}\dd V+\frac{\partial\ln Y}{\partial\mu}\dd\mu=\\
 & =\left(-E+\mu N\right)\dd\beta+\beta P\dd V+\beta N\dd\mu\\
\dd\left(\ln\left(Y\left(\beta,V,\mu\right)\right)\right)+E\dd\beta-\mu N\dd\beta-\beta N\dd\mu & =\beta P\dd V\\
\dd\left(\ln\left(Y\right)+\beta E-\beta\mu N\right) & =\beta\left(\dd E+P\dd V-\mu\dd N\right)=\beta T\dd S=\frac{\dd S}{k_{B}}
\end{align*}
\begin{align*}
\Rightarrow\qquad S & =k_{B}\left(\ln\left(Y\right)+\beta E-\beta\mu N\right)\\
k_{B}T\ln\left(Y\right) & =TS-E+\mu N\stackrel{\eqref{eq:J}}{=}-J
\end{align*}
\begin{align}
\Rightarrow\qquad\fbox{\ensuremath{{\displaystyle J=-k_{B}T\ln\left(Y\right)}}}\label{eq:J_ln(Y)}
\end{align}

\end{enumerate}

\chapter{Applications}


\section{Ideal gas}


\subsubsection{Calculation of $Z\left(T,V,N\right)$}

Remember:
\begin{align*}
E_{r} & =\sum_{k=1}^{3N}\frac{p_{k}^{2}}{2m}=\sum_{k=1}^{3N}\frac{\hbar^{2}k^{2}}{2m} & k & =\frac{\pi n_{k}}{L}
\end{align*}
Accounting for the indistinguishability of particles yields:
\begin{align*}
Z & =\sum_{r}e^{-\beta E_{r}}\approx\frac{1}{N!}\int\dd n_{1}\ldots\int\dd n_{3N}e^{-\beta E_{r}}=\\
 & =\frac{V^{N}}{N!\cdot h^{3N}}\int_{-\infty}^{\infty}\dd p_{1}\ldots\int_{-\infty}^{\infty}\dd p_{3N}e^{-\beta\sum_{k=1}^{3N}\frac{p_{k}^{2}}{2m}}=\\
 & =\frac{1}{N!}\left(\frac{V}{h^{3}}\int_{-\infty}^{\infty}\dd^{3}p\cdot e^{-\beta\frac{\vec{p}^{2}}{2m}}\right)^{N}
\end{align*}
In the exponent is $-\beta\frac{\vec{p}^{2}}{2m}$ and with $p=\norm{\vec{p}}$
we get:
\begin{align*}
Z & =\frac{1}{N!}\left(\frac{V}{h^{3}}\int_{0}^{\infty}4\pi p^{2}\dd p\cdot e^{-\beta\frac{p^{2}}{2m}}\right)^{N}=\\
 & \sr ={x=\frac{p}{\sqrt{2mk_{B}T}}}{\dd p=\sqrt{2mk_{B}T}\dd x}\frac{1}{N!}\Bigg(\frac{4\pi V}{h^{3}}\left(2mk_{B}T\right)^{\frac{3}{2}}\underbrace{\int_{0}^{\infty}x^{2}\dd xe^{-x^{2}}}_{=\frac{1}{4}\sqrt{\pi}}\Bigg)^{N}=\\
 & =\frac{1}{N!}\left(\frac{V}{h^{3}}\left(2\pi mk_{B}T\right)^{\frac{3}{2}}\right)^{N}
\end{align*}
This can be written as
\begin{align}
\fbox{\ensuremath{{\displaystyle Z=\frac{1}{N!}\left(\frac{V}{\lambda^{3}}\right)^{N}}}}
\end{align}
with the De Broglie thermal wave length: 
\begin{align}
\lambda & =\frac{h}{\sqrt{2\pi mk_{B}T}}
\end{align}
This $\lambda$ can be interpreted as the quantum mechanical wavelength
of a particle with an energy of the order $k_{B}T$:
\begin{align*}
\frac{\hbar^{2}}{2m}\left(\frac{2\pi}{\lambda}\right)^{2} & =\pi k_{B}T
\end{align*}


Now introduce the single particle partition function
\begin{align}
z & :=\sum_{\vec{p}}e^{-\beta\varepsilon\left(\vec{p}\right)}=\frac{V}{h^{3}}\int\dd^{3}p\cdot e^{-\beta\frac{\vec{p}^{2}}{2m}}=\frac{V}{\lambda^{3}}
\end{align}
to get:
\begin{align}
\fbox{\ensuremath{{\displaystyle Z=\frac{z^{N}}{N!}}}}\label{eq:Z_z}
\end{align}
\emph{Note}: This equation holds for any system of \emph{independent}
particles.


\subsubsection*{Equation of state of the ideal gas}

From \eqref{eq:Z_z} follows:
\begin{align}
\ln\left(Z\right) & =N\ln\left(z\right)-\ln\left(N!\right)\sr{\approx}{\text{Striling's formula}}{\ln\left(N!\right)\approx N\ln\left(N\right)-N}N\ln\left(\frac{z}{N}\right)+N
\end{align}
And hence we get:
\begin{align*}
P & =\frac{1}{\beta}\frac{\partial\ln\left(Z\right)}{\partial V}=Nk_{B}T\frac{\partial\ln\left(z\right)}{\partial V}=Nk_{B}T\frac{\partial\ln\left(V\right)}{\partial V}=\frac{Nk_{B}T}{V}\\
E & =-\frac{\partial\ln\left(Z\right)}{\partial\beta}=-N\frac{\partial\ln\left(z\right)}{\partial\beta}=N\frac{\partial\ln\lambda^{3}}{\partial\beta}=\frac{3}{2}N\frac{\partial\ln\beta}{\partial\beta}=\frac{3}{2}Nk_{B}T
\end{align*}
These are the equations of state:

\begin{framed}
\begin{align}
PV & =Nk_{B}T &  & \text{thermal equation of state}\\
E & =\frac{3}{2}Nk_{B}T &  & \text{caloric equation of state}\label{eq:caloricState}
\end{align}
\end{framed}

\emph{Note}: Equation \eqref{eq:caloricState} is a particular realization
of the ``equipartition theorem'', which states:
\begin{quote}
``Each variable occurring \emph{quadratically} in the Hamiltonian
yields a contribution of $\frac{1}{2}k_{B}T$ to the average temperature.''
\end{quote}

\subsubsection*{Calculation of $Y\left(T,V,\mu\right)$}

From equation \eqref{eq:grand-can_partition_funktion} we get:
\begin{align*}
Y\left(T,V,N\right) & =\sum_{N=0}^{\infty}Z\left(T,V,N\right)e^{\beta\mu N}
\end{align*}
For the ideal gas follows:
\begin{align*}
Y\left(T,V,N\right) & =\sum_{N=0}^{\infty}\frac{1}{N!}\frac{V^{N}}{\lambda^{3N}}e^{\beta\mu N}
\end{align*}
So with
\begin{align}
y= & \frac{V}{\lambda^{3}}e^{\beta\mu}
\end{align}
we get:
\begin{align}
Y\left(T,V,N\right) & =\sum_{N=0}^{\infty}\frac{y^{N}}{N!}=e^{y}\label{eq:Y_exp(y)}
\end{align}
We obtain now the various equations of state:
\begin{align}
N & =\frac{1}{\beta}\frac{\partial\ln\left(Y\right)}{\partial\mu}=\frac{1}{\beta}\frac{\partial y}{\partial\mu}=\frac{\beta}{\beta}y=\ln\left(Y\right)\\
P & =\frac{1}{\beta}\frac{\partial\ln\left(Y\right)}{\partial V}=\frac{1}{\beta}\frac{\partial y}{\partial V}=k_{B}T\frac{e^{\beta\mu}}{\lambda^{3}}=k_{B}T\frac{y}{V}=\frac{Nk_{B}T}{V}\\
E & =-\frac{\partial\ln\left(Y\right)}{\partial\beta}+\mu N=-\frac{\partial y}{\partial\beta}+\mu N=-\lambda^{3}y\frac{\partial\lambda^{-3}}{\partial\beta}=\frac{3}{2}Nk_{B}T
\end{align}



\section{Interacting gas}

We would like to address the situation, where particles in a dilute
system can interact with each other. We start from the Hamiltonian:
\begin{align}
\hat{H} & =\sum_{\nu=1}^{N}\frac{\hat{p}_{\nu}^{2}}{2m}+\sum_{\nu=2}^{N}\sum_{\nu'=1}^{\nu-1}\hat{w}\left(\abs{\vec{r}_{\nu}-\vec{r}_{\nu'}}\right)
\end{align}
In general, this problem can not be solved \emph{exactly}, but it
can be solved approximately if the system is \emph{dilute}, i.e.:
\begin{align}
v & =\frac{V}{N}\gg d^{3}
\end{align}
Here $d$ is the average size of a particle.
\begin{itemize}
\item The starting point is:
\begin{align}
Y\left(T,V,\mu\right) & =\sum_{N=0}^{\infty}Z\left(N\right)e^{\beta\mu N}=1+\underbrace{Z\left(1\right)e^{\beta\mu}+Z\left(2\right)e^{2\beta\mu}+\ldots}_{=x}\nonumber \\
\ln\left(Y\right) & \stackrel{\ln\left(1+x\right)\approx x-\frac{x^{2}}{2}}{\approx}Z\left(1\right)e^{\beta\mu}+\underbrace{\left(Z\left(2\right)-\frac{\left(Z\left(1\right)\right)^{2}}{2}\right)}_{=:Z_{2}}e^{2\beta\mu}
\end{align}
For $\hat{w}=0$ holds $Z_{2}=0$ due to:
\begin{align*}
Z\left(N\right) & =\frac{\left(Z\left(1\right)\right)^{N}}{N!}
\end{align*}
This also holds true for the next terms, so for $\hat{w}=0$ we get
(cf. \eqref{eq:Y_exp(y)}):
\begin{align*}
\ln\left(Y\right) & =Z\left(1\right)e^{\beta\mu}
\end{align*}
One can consider $Z_{2}$ as a \emph{correction} to the ideal gas
result, when only two-body interactions are considered.
\item Let us then introduce:
\begin{align}
Z_{1} & =Z\left(1\right)=\frac{V}{\lambda^{3}} & Z_{2} & =Z\left(2\right)-\frac{\left(Z\left(1\right)\right)^{2}}{2}
\end{align}
So we get:
\begin{align*}
P & \sr ={\eqref{eq:J_-PV}}{\eqref{eq:J_ln(Y)}}\frac{k_{B}T\ln\left(Y\right)}{V}=\frac{k_{B}T}{V}\left(Z_{1}e^{\beta\mu}+Z_{2}e^{2\beta\mu}+\ldots\right)\\
N & =\frac{1}{\beta}\frac{\partial\ln\left(Y\right)}{\partial\mu}=Z_{1}e^{\beta\mu}+2Z_{2}e^{2\beta\mu}+\ldots
\end{align*}
Solving the second equation for $e^{\beta\mu}$ gives:
\begin{align*}
e^{\beta\mu} & =\frac{N}{Z_{1}}-2\frac{Z_{2}}{Z_{1}}e^{2\beta\mu}+\ldots
\end{align*}
Inserting this into the first equation yields:
\begin{align}
\frac{PV}{k_{B}T} & =\ln Y\approx N-Z_{2}e^{2\beta\mu}\stackrel{e^{\beta\mu}\approx\frac{N}{Z_{1}}}{\approx}N-Z_{2}\left(\frac{N}{Z_{1}}\right)^{2}=\nonumber \\
 & =N\left(1-\frac{Z_{2}V}{Z_{1}^{2}}\frac{N}{V}\right)=:N\left(1+\frac{B\left(T\right)}{v}\right)
\end{align}
The $B\left(T\right)$ here is known as \emph{virial coefficient}.%DATE: Fr 16.11.12
\begin{align*}
Z_{2} & =\frac{1}{2!\cdot h^{6}}\int_{V}\dd^{3}r_{1}\int_{V}\dd^{3}r_{2}\int\dd^{3}p_{1}\int\dd^{3}p_{2}e^{-\beta\left(\frac{1}{2}\left(p_{1}^{2}+p_{2}^{2}\right)+w\left(r_{12}\right)\right)}=\\
 & =\frac{1}{2\lambda^{6}}\int_{V}\dd^{3}r_{1}\int_{V}\dd^{3}r_{2}e^{-\beta w\left(r_{1}-r_{2}\right)}
\end{align*}
\begin{align*}
B\left(T\right) & :=-\frac{Z_{2}V}{Z_{1}^{2}}=-\frac{V}{\left(\frac{V}{\lambda^{3}}\right)^{2}}\left(Z\left(2\right)-\frac{\left(Z\left(1\right)\right)^{2}}{2}\right)=\\
 & =-V\left(\frac{\lambda^{6}}{V^{2}}\cdot\frac{1}{2\lambda^{6}}\int_{V}\dd^{3}r_{1}\int_{V}\dd^{3}r_{2}e^{-\beta w\left(r_{12}\right)}-\frac{1}{2}\right)=\\
 & =-\frac{1}{2V}\left(\int_{V}\dd^{3}r_{1}\int_{V}\dd^{3}r_{2}e^{-\beta w\left(r_{12}\right)}-V^{2}\right)=\\
 & =-\frac{1}{2V}\left(\int_{V}\dd^{3}r_{1}\int_{V}\dd^{3}r_{2}\left(e^{-\beta w\left(r_{12}\right)}-1\right)\right)
\end{align*}
Now change the variables:
\begin{align*}
\vec{R} & :=\frac{\vec{r}_{1}+\vec{r}_{2}}{2} & \vec{r} & :=\vec{r}_{2}-\vec{r}_{1}
\end{align*}
Then follows:
\begin{align}
B\left(T\right) & =-\frac{1}{2V}\left(\int_{V}\dd^{3}R\int\dd^{3}r\left(e^{-\beta w\left(r\right)}-1\right)\right)=\nonumber \\
 & =-\frac{1}{2}\left(\int4\pi r^{2}\dd r\left(e^{-\beta w\left(r\right)}-1\right)\right)=-2\pi\int\dd r\cdot r^{2}\left(e^{-\beta w\left(r\right)}-1\right)
\end{align}
\emph{Note}: $B\left(T\right)$ is a macroscopically measurable quantity,
which yields information about $w\left(r\right)$.
\item Now make the assumption of an ``hard core'' potential:
\begin{align*}
w\left(r\right) & =\begin{cases}
\infty & r<d\\
<0 & r\gtrapprox d\\
\approx0 & r\gg d
\end{cases}
\end{align*}
\textcolor{green}{TODO: Plot $w\left(r\right)$}\\
Here $d$ is the order of the particle size. For $r>d$ the potential
is attractive due to (instantaneous) dipole interactions. The sketch
mimics more realistic potentials (e.g. Lennard-Jones potential).\\
Due to the attractive potential, the gas exhibits a transition to
a liquid phase at low temperatures. The transition occurs, when $k_{B}T$
is about as large as the attractive potential~$\abs w$. In the following
we only consider:
\begin{align*}
\frac{\abs w}{k_{B}T} & \ll1\qquad\text{for }r\gtrapprox d
\end{align*}
Then holds:
\begin{align*}
e^{-\beta w}-1 & \approx\begin{cases}
-1 & r<d\\
-\beta\omega & r>d
\end{cases}
\end{align*}
\begin{align*}
\Rightarrow\qquad B\left(T\right) & \approx2\pi\int_{0}^{d}\dd r\cdot r^{2}+2\pi\beta\int_{d}^{\infty}\dd r\cdot r^{2}\omega\left(r\right):=b-\frac{a}{k_{B}T}
\end{align*}
\begin{align}
b & =\frac{2\pi}{3}d^{3}>0 & a & =-2\pi\int_{d}^{\infty}\dd r\cdot r^{2}\omega\left(r\right)>0
\end{align}
Thus we find:
\begin{align*}
P & =\frac{k_{B}T}{v}\left(1+\frac{B\left(T\right)}{v}\right)=\frac{k_{B}T}{v}\left(1+\frac{b-\frac{a}{k_{B}T}}{v}\right)=\frac{k_{B}T}{v}\left(1+\frac{b}{v}\right)-\frac{a}{v^{2}}\approx\\
 & \approx\frac{k_{B}T}{v}\cdot\frac{1}{1-\frac{b}{v}}-\frac{a}{v^{2}}
\end{align*}
This yields the equation of the \emph{van-der-Waals gas}:
\begin{align}
\fbox{\ensuremath{{\displaystyle P=-\frac{a}{v^{2}}+\frac{k_{B}T}{v-b}}}}
\end{align}
This gives the corrections to the ideal gas:

\begin{itemize}
\item The atoms have finite size, so the accessible volume per atom is $v-b$.
\item The attractive interactions for $r>d$ diminish the pressure by $\frac{a}{v^{2}}$.
\end{itemize}
\end{itemize}
\emph{Note}: The necessary condition for this to work is $B\left(T\right)\ll v$,
i.e. $\frac{b}{v}\ll1$ and $\frac{a}{vk_{B}T}\ll1$.

\emph{Note}: At high enough temperatures is $d^{3}\gg\lambda^{3}$
and thus $\frac{d^{3}}{v}\ll1$ implies also $\frac{\lambda^{3}}{v}\ll1$.
But for the ideal gas is $e^{\beta\mu}\approx\frac{\lambda^{3}}{v}$
and thus follows $\mu<0$.

\emph{Note}: ${\displaystyle E=-\frac{\partial\ln\left(Y\right)}{\partial\beta}+\mu N}$
is obtained to be:
\begin{align}
E & =N\left(\frac{3}{2}k_{B}T-\frac{a}{v}\right)
\end{align}



\section{Indistinguishability of particles\label{sec:Indistinguishability-of-particles}}

So far we have taken into account the indistinguishability of particles
by adding the prefactor $\frac{1}{N!}$ in our sum over the microstates.
However, indistinguishability has a more profound consequence on the
form of a many body wave function. Specifically, let us consider the
$N$-particle Hamiltonian $\hat{H}_{N}$
\begin{align}
\hat{H}_{N}\KET{\psi} & =E_{N}\KET{\psi}
\end{align}
and a complete orthonormal single-particle basis $\left\{ \KET{\nu}\right\} $.

In general any $N$-particle state lies in the $N$-th tensor product
and thus can be written as a linear combination of products of $N$
single-particle states:
\begin{align}
\KET{\psi} & =\sum_{\nu_{1},\ldots,\nu_{N}}A_{\nu_{1}\nu_{2}\ldots\nu_{N}}\KET{\nu_{1}}\otimes\KET{\nu_{2}}\otimes\ldots\otimes\KET{\nu_{N}}\label{eq:N-particle-state_tensor-product-basis}
\end{align}



\subsubsection*{Example: $N=2$}

\begin{align}
\KET{\psi} & =\sum_{\nu_{1},\nu_{2}}A_{\nu_{1}\nu_{2}}\KET{\nu_{1}}\otimes\KET{\nu_{2}}
\end{align}
Let us introduce the permutation operator $\hat{P}_{12}$ by:
\begin{align}
\hat{P}_{12}\KET{\psi} & =\hat{P}_{12}\sum_{\nu_{1},\nu_{2}}A_{\nu_{1}\nu_{2}}\KET{\nu_{1}}\otimes\KET{\nu_{2}}=\sum_{\nu_{1},\nu_{2}}A_{\nu_{2}\nu_{1}}\KET{\nu_{1}}\otimes\KET{\nu_{2}}
\end{align}
Because of the indistinguishability of the particles, $\KET{\psi}$
and $\hat{P}_{12}\KET{\psi}$ must represent the same state and thus
follows:
\begin{align}
\hat{P}_{12}\KET{\psi} & =\lambda\KET{\psi}
\end{align}
Moreover holds:
\begin{align*}
\hat{P}_{12}^{2} & =\mathbbm{1} & \Rightarrow\qquad\lambda^{2} & =1 & \Rightarrow\qquad\lambda & =\pm1
\end{align*}
\begin{align}
\Rightarrow\qquad A_{\nu_{1}\nu_{2}} & =\pm A_{\nu_{2}\nu_{1}}\label{eq:A-(anti)symmetrisch}
\end{align}
Let us for simplicity restrict the sum $\sum_{\nu_{1},\nu_{2}}$ to
two states $\KET a$ and $\KET b$ only.
\begin{itemize}
\item $\lambda=1$:
\begin{align}
\KET{\psi} & =A_{aa}\KET a\otimes\KET a+A_{bb}\KET b\otimes\KET b+A_{ab}\left(\KET a\KET b+\KET b\KET a\right)
\end{align}
The state is symmetric upon exchange of the particles 1 and 2.
\item $\lambda=-1$: From equation \eqref{eq:A-(anti)symmetrisch} follows:\stepcounter{equation}
\begin{align}
A_{\nu_{j}\nu_{j}} & =0\tag{\arabic{chapter}.\arabic{equation}a}\\
\KET{\psi} & =A_{ab}\left(\KET a\KET b-\KET b\KET a\right)\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
The state is antisymmetric upon exchange of the particles 1 and 2.
\end{itemize}
So there are only symmetrized/antisymmetrized baiss states. In general
this property is closely related to the spin of the considered particles
(quasi-particles):
\begin{align}
\begin{array}{c}
\text{integer spin }\leftrightarrow\text{ symmetric }\leftrightarrow\text{ bosons}\\
\text{half-integer spin }\leftrightarrow\text{ antisymmetric }\leftrightarrow\text{ fermions}
\end{array}
\end{align}
(cf. \noun{W. Pauli}: Physical Review 58, 716 (1940))

We have seen in equation \eqref{eq:N-particle-state_tensor-product-basis}:
\begin{align*}
\KET{\psi} & =\sum_{\nu_{1},\ldots,\nu_{N}}A_{\nu_{1}\nu_{2}\ldots\nu_{N}}\KET{\nu_{1}}\otimes\KET{\nu_{2}}\otimes\ldots\otimes\KET{\nu_{N}}
\end{align*}
Here the symmetry requirements are hidden in $A_{\nu_{1},\ldots,\nu_{N}}$.\\
So a physically meaningful $N$-particle basis is the one, which incorporates
symmetrized (antisymmetrized) products of single particle states.
This is accomplished by symmetrization (antisymmetrization) operators
$\hat{S}_{+}$ ($\hat{S}_{-}$).


\subsubsection*{Example}

\begin{align}
\BraKet{\vec{r}_{1}\vec{r}_{2}\ldots\vec{r}_{N}|\psi} & =\sum_{\nu_{1},\ldots,\nu_{N}}A_{\nu_{1},\ldots,\nu_{N}}\psi_{\nu_{1}}\left(\vec{r}_{1}\right)\ldots\psi_{\nu_{N}}\left(\vec{r}_{N}\right)
\end{align}
\begin{align}
\hat{S}_{\pm}\prod_{j=1}^{N}\psi_{\nu_{j}}\left(\vec{r}_{j}\right) & :=\frac{\mathcal{N}}{\sqrt{N!}}\abs{\begin{array}{ccc}
\psi_{\nu_{1}}\left(\vec{r}_{1}\right) & \ldots & \psi_{\nu_{1}}\left(\vec{r}_{N}\right)\\
\vdots & \ddots & \vdots\\
\psi_{\nu_{N}}\left(\vec{r}_{1}\right) & \ldots & \psi_{\nu_{N}}\left(\vec{r}_{N}\right)
\end{array}}_{\pm}
\end{align}
Here $\abs ._{+}$ is the permanent (without sign change) and $\abs ._{-}$
the normal determinant (Slater determinant). Moreover the normalization
factor is:
\begin{align}
\mathcal{N} & =\frac{1}{\prod_{\left\{ \nu_{i}\right\} }\sqrt{n_{\nu_{i}}!}}
\end{align}
Here $n_{\nu}$ is the number of times the state $\KET{\nu}$ appears
in the set $\left\{ \KET{\nu_{1}},\ldots,\KET{\nu_{N}}\right\} $.
It holds:
\begin{align*}
n_{\nu} & \in\left\{ 0,1\right\}  &  & \text{fermions}\\
n_{\nu} & \in\left\{ 0,1,\ldots,N\right\}  &  & \text{bosons}
\end{align*}



\subsubsection*{Example: $N=3$}

\begin{align}
\hat{S}_{\pm}\KET{\nu_{1}\nu_{2}\nu_{3}} & =\frac{\mathcal{N}}{\sqrt{3!}}\left(\KET{\nu_{1}\nu_{2}\nu_{3}}\pm\KET{\nu_{1}\nu_{3}\nu_{2}}\pm\KET{\nu_{3}\nu_{2}\nu_{1}}\pm\KET{\nu_{2}\nu_{1}\nu_{3}}+\KET{\nu_{2}\nu_{3}\nu_{1}}+\KET{\nu_{3}\nu_{1}\nu_{2}}\right)
\end{align}
The generic $N$-particles state is:
\begin{align}
\KET{\psi} & =\sum_{\nu_{1},\ldots,\nu_{N}}B_{\nu_{1}\ldots\nu_{N}}\hat{S}_{\pm}\underbrace{\KET{\nu_{1},\nu_{2},\ldots,\nu_{N}}}_{=\KET{\nu_{1}}\otimes\ldots\otimes\KET{\nu_{N}}}
\end{align}


%DATE: Di 20.11.12


\subsection{Occupation number representation}

The symmetrized/antisymmetrized states are fully characterized by
the occupation numbers $\left\{ n_{\nu}\right\} $, where $\nu$ runs
over \emph{all} single particle states. To such extent one orders
the one-particle states in a sequence $\nu_{1}<\nu_{2}<\nu_{3}<\ldots$,
where energetically lower states come before energetically higher
states:
\begin{align*}
\varepsilon_{\nu_{1}} & \le\varepsilon_{\nu_{2}}\le\ldots
\end{align*}
Introduce the notation, called \emph{occupation number representation}:
\begin{align}
\KET{n_{\nu_{1}},n_{\nu_{2}},\ldots}
\end{align}
For an $N$-particle system must hold:
\begin{align}
\sum_{\nu}n_{\nu} & =N
\end{align}
\emph{Note}: Due to the Pauli principle, the number of available states
for fermions of bosons is very different.

\noindent \begin{center}
\begin{tabular}{c|c|c}
$N$ & fermion basis $\KET{n_{\nu_{1}},n_{\nu_{2}},\ldots}$ & boson basis $\KET{n_{\nu_{1}},n_{\nu_{2}},\ldots}$\tabularnewline
\hline 
\hline 
0 & $\KET{0,0,\ldots}$ & $\KET{0,0,\ldots}$\tabularnewline
\hline 
1 & $\KET{1,0,\ldots},\KET{0,1,0,\ldots},\ldots$ & $\KET{1,0,\ldots},\KET{0,1,0,\ldots},\ldots$\tabularnewline
\hline 
2 & $\KET{1,1,0,\ldots},\KET{1,0,1,0,\ldots},\ldots,$ & $\KET{2,0,\ldots},\KET{0,2,0,\ldots},\ldots,$\tabularnewline
 & $\KET{0,1,1,0,\ldots},\ldots$ & $\KET{1,1,0,\ldots},\ldots$\tabularnewline
\hline 
$\vdots$ & $\vdots$ & $\vdots$\tabularnewline
\end{tabular}
\par\end{center}

So the art of particles (bosons/fermions) determines their statistics,
i.e. the number of possibilities one has to distribute particles on
the occupation number basis states.\\
In particular, a microstate $r$ with $N_{r}$ particles is defined
upon assigning $\left(n_{\nu}\right)$:
\begin{align}
r & =\left(n_{\nu_{1}},n_{\nu_{2}},\ldots\right)=\left(n_{\nu}\right)
\end{align}
If the particle number is not fixed, we write:
\begin{align}
r & =\left(r',N_{r}\right)=\left(\left(n_{\nu}\right),N_{r}\right)
\end{align}

\begin{enumerate}[label=\Alph*)]
\item \emph{Particle number fixed}:

\begin{enumerate}[label=\alph*)]
\item One considers only microstates $r$ with $N_{r}=N$ and evaluates:
\begin{align}
Z\left(T,x,N\right) & =\sum_{r}e^{-\beta E_{r}\left(x,N\right)}
\end{align}

\item Or one does not constrain the number $N_{r}$ of the microstate $r$
and evaluates:
\begin{align}
Y\left(T,x,\mu\right) & =\sum_{r}e^{-\beta\left(E_{r}\left(x,N_{r}\right)-\mu N_{r}\right)}
\end{align}
Here $\mu$ is chosen such that holds:
\begin{align}
\frac{1}{\beta}\frac{\partial\ln\left(Y\right)}{\partial\mu} & =\overline{N_{r}}=N
\end{align}

\end{enumerate}
\item \emph{Particle number cannot be determined:}

\begin{itemize}
\item Particles can be exchanged.
\item To this second class belong e.g. systems made of bosonic quasi-particles
like photons and phonons. These are excitations and therefore their
average number depends on the temperature and cannot be fixed. For
these systems, the particle number does not enter the Hamiltonian
and therefore the energy $E_{r}$ of the microstate $r$ is independent
of $N$.
\begin{align}
\mu & =\frac{\overline{\partial E_{r}}}{\partial N}=0
\end{align}

\end{itemize}
\end{enumerate}

\subsection{Independent particles}
\begin{itemize}
\item For a system of $N$ independent particles holds
\begin{align}
\hat{H}_{N} & =\sum_{j=1}^{N}\hat{h}_{j} & \hat{H}_{N}\KET{\psi} & =E_{N}\KET{\psi} & \hat{h}_{j}\KET{\nu_{j}} & =\varepsilon_{j}\KET{\nu_{j}}
\end{align}
and hence:
\begin{align}
E_{N} & =\sum_{j=1}^{N}\varepsilon_{j}
\end{align}
In terms of occupation numbers with $N=\sum_{\nu}\overline{n}_{\nu}$:\stepcounter{equation}
\begin{align}
E_{N} & =\sum_{\nu}\overline{n}_{\nu}\varepsilon_{\nu}\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}

\item For the energy $E_{r}$ of the microstate $r=\left(n_{\nu}\right)$
holds:
\begin{align}
E_{r} & =\sum_{\nu}n_{\nu}\varepsilon_{\nu}\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
\emph{ Example}: Consider a gas of $N$ electrons in a box (with spin
included!):
\begin{align*}
\left(\KET{\nu}\right) & =\left(\left(\vec{p}_{1},\uparrow\right),\left(\vec{p}_{1},\downarrow\right),\left(\vec{p}_{2},\uparrow\right),\left(\vec{p}_{2},\downarrow\right),\ldots\right)
\end{align*}
\begin{align*}
\abs{\vec{p}_{1}}\le\abs{\vec{p}_{2}}\le\abs{\vec{p}_{3}}\le\ldots
\end{align*}
\begin{align*}
\Rightarrow\quad r & =\left(n_{\vec{p}_{1}}^{\uparrow},n_{\vec{p}_{1}}^{\downarrow},\ldots\right)\\
\sum_{\vec{p},s_{z}}n_{\vec{p}}^{s_{z}} & =N_{r}=N
\end{align*}
\emph{Note}:\stepcounter{equation}
\begin{align}
E & =-\frac{\partial\ln\left(Y\right)}{\partial\beta}+\mu N\sr ={\text{independent}}{\text{particles}}\sum_{\nu}\varepsilon_{\nu}\overline{n}_{\nu}\tag{\arabic{chapter}.\arabic{equation}a}\\
N & =\frac{1}{\beta}\frac{\partial\ln Y}{\partial\beta}=\sum_{\nu}\overline{n}_{\nu}\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
Here $\overline{n}_{\nu}$ is the \emph{average occupation} \emph{number}
of the level $\nu$. So we have:
\begin{align}
P & =-\frac{\overline{\partial E_{r}}}{\partial V}=-\sum_{\nu}\frac{\partial\varepsilon_{\nu}}{\partial V}\overline{n}_{\nu}
\end{align}
\emph{Example}: Consider an ideal gas with:
\begin{align*}
\varepsilon_{\nu} & =\varepsilon_{p}=\frac{p^{2}}{2m}=\frac{\hbar^{2}\pi^{2}n^{2}}{2mL^{2}}
\end{align*}
From $L^{3}=V$ we get:
\begin{align*}
\frac{\partial\varepsilon_{\nu}}{\partial V} & =-\frac{2}{3}\frac{\varepsilon_{p}}{V}
\end{align*}
\begin{align}
\Rightarrow\qquad\fbox{\ensuremath{{\displaystyle P=\frac{2}{3}\frac{E}{V}}}}
\end{align}

\end{itemize}

\subsection{Fermi-Dirac statistics}

Consider a gas of independent fermions and look for $\overline{n}_{\nu}$.
To this extent we start from the grandcanonical partition function
$Y\left(T,x,\mu\right)$.
\begin{align}
Y\left(T,x,\mu\right) & =\sum_{r}e^{-\beta\left(E_{r}-\mu N_{r}\right)}\stackrel{\text{fermions}}{=}\sum_{n_{1}\in\left\{ 0,1\right\} }\sum_{n_{2}\in\left\{ 0,1\right\} }\ldots e^{-\beta\sum_{\nu}\left(n_{\nu}\varepsilon_{\nu}-\mu n_{\nu}\right)}=\nonumber \\
 & =\prod_{\nu}\left(\sum_{n_{\nu}\in\left\{ 0,1\right\} }e^{-\beta\left(\varepsilon_{\nu}-\mu\right)n_{\nu}}\right)=\prod_{\nu}\left(1+e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\right)
\end{align}


The average occupation number is:

\begin{align*}
\overline{n}_{\nu} & =\frac{1}{Y}\sum_{n_{1}\in\left\{ 0,1\right\} }\sum_{n_{2}\in\left\{ 0,1\right\} }\ldots n_{\nu}e^{-\beta\sum_{\nu'}\left(\varepsilon_{\nu'}-\mu\right)n_{\nu'}}=\\
 & =1\cdot e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\frac{1}{Y}\prod_{\nu\not=\nu'}\left(1+e^{-\beta\left(\varepsilon_{\nu'}-\mu\right)}\right)=\\
 & =\frac{e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}}{1+e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}}
\end{align*}
This gives the \emph{Fermi-Dirac} function:
\begin{align}
\fbox{\ensuremath{{\displaystyle \overline{n}_{\nu}:=f\left(\varepsilon_{\nu}\right):=\frac{1}{e^{\beta\left(\varepsilon_{\nu}-\mu\right)}+1}}}}
\end{align}
The Fermi-Dirac function $f$ yields the occupation number of a level
$\nu$ for a system of independent fermions.

\emph{Note:} For $T=0$ holds:
\begin{align*}
\lim_{T\to0}f\left(\varepsilon_{\nu}\right) & =\Theta\left(\mu-\varepsilon_{\nu}\right)=\begin{cases}
1 & \varepsilon_{\nu}<\mu\\
0 & \varepsilon_{\nu}>\mu
\end{cases}
\end{align*}
\textcolor{green}{TODO: Abb12: ground state of $s=\frac{1}{2}$ particles}

This ground state configuration is known as the ``\emph{Fermi sea}''.
\begin{itemize}
\item For fixed $N$, the chemical potential $\mu=\mu\left(T,v\right)$
is a function of $T$ and $v$. Define the \emph{Fermi energy} as:
\begin{align*}
\varepsilon_{F} & :=\lim_{T\to0}\mu\left(T\right)
\end{align*}


\begin{itemize}
\item For a metal the Fermi energy $\varepsilon_{F}$ is the energy of the
\emph{highest occupied level} at zero temperature:
\begin{align*}
\varepsilon_{F} & =\mu\left(T=0,v\right)
\end{align*}

\item For a gapped structure (semiconductor), $\varepsilon_{F}=\mu\left(T=0\right)$
lies in the middle of the gap.\\
\textcolor{green}{TODO: Abb13; semi conductor}
\end{itemize}
\item The Fermi momentum $p_{F}$ is defined by:
\begin{align*}
\varepsilon_{F} & =\frac{p_{F}^{2}}{2m}
\end{align*}

\item The Fermi wave vector $\vec{k}_{F}$ is defined by:
\begin{align*}
\vec{p}_{F} & =\hbar\vec{k}_{F}
\end{align*}
The Fermi momentum $p_{F}$ can be determined from:
\begin{align*}
N & =\sum_{\nu}n_{\nu}=\underbrace{\left(2s+1\right)}_{\text{spin degeneracy}}\sum_{\norm{\vec{p}}\le p_{F}}1\approx\frac{V\left(2s+1\right)}{h^{3}}\cdot\frac{4}{3}\pi p_{F}^{3}\stackrel{s=\frac{1}{2}}{=}\frac{V}{h^{3}}\cdot\frac{8}{3}\pi p_{F}^{3}
\end{align*}
\begin{align}
p_{F} & =\left(\frac{3}{\pi}\frac{N}{V}\frac{2}{\left(2s+1\right)}\right)^{\frac{1}{3}}\frac{h}{2}\stackrel{s=\frac{1}{2}}{=}\left(3\pi^{2}\right)^{\frac{1}{3}}\frac{\hbar}{v^{\frac{1}{3}}}\label{eq:Fermi-momentum}\\
\varepsilon_{F} & =\left(\frac{3}{\pi}\frac{N}{V}\frac{2}{\left(2s+1\right)}\right)^{\frac{2}{3}}\frac{h^{2}}{4}\stackrel{s=\frac{1}{2}}{=}\left(3\pi^{2}\right)^{\frac{2}{3}}\frac{\hbar^{2}}{2mv^{\frac{2}{3}}}\nonumber 
\end{align}
\emph{Note:} The Fermi momentum $p_{F}\sim n^{\frac{1}{3}}$ and the
Fermi energy $\varepsilon_{F}\sim n^{\frac{2}{3}}$. Likewise follows:
\begin{align}
E & =\sum_{\nu}\varepsilon_{\nu}\overline{n}_{\nu}=\underbrace{\left(2s+1\right)}_{\text{spin degeneracy}}\sum_{\abs{\vec{p}}\le p_{F}}\frac{p^{2}}{2m}\approx\frac{V}{mh^{3}}\int_{\abs{\vec{p}}\le p_{F}}p^{2}\dd^{3}p=\nonumber \\
 & =\frac{4\pi V}{mh^{3}}\int_{p\le p_{F}}p^{4}\dd p=\frac{4\pi V}{5mh^{3}}p_{F}^{5}=\frac{3}{5}\cdot\underbrace{\frac{8\pi V}{3h^{3}}p_{F}^{3}}_{=N}\cdot\frac{1}{2m}p_{F}^{2}=\frac{3}{5}N\varepsilon_{F}\label{eq:E0}
\end{align}
For $T\not=0$ we have:\\
\textcolor{green}{TODO: Abb14}
\end{itemize}
%DATE: Fr 23.11.12


\subsection{Bose-Einstein statistics}

\emph{Partition function}: For bosons any $n_{\nu}\in\mathbb{N}_{0}$
is possible. So for a system of independent bosons holds:
\begin{align}
Y\left(T,x,\mu\right) & =\sum_{r}e^{-\beta\left(E_{r}-\mu N_{r}\right)}=\prod_{\nu}\left(\sum_{n_{\nu}}e^{-\beta\left(\varepsilon_{\nu}-\mu\right)n_{\nu}}\right)\sr ={\sum_{n=0}^{\infty}x^{n}=\frac{1}{1-x}}{}\prod_{\nu}\frac{1}{1-e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}}
\end{align}
\emph{Average occupation number:}
\begin{align*}
\overline{n_{\nu}} & =\frac{1}{Y}\sum_{r}n_{\nu}e^{-\beta\left(E_{r}-\mu N_{r}\right)}=\frac{1}{Y}\sum_{n_{\nu}}n_{\nu}e^{-\beta\left(\varepsilon_{\nu}-\mu\right)n_{\nu}}\prod_{\nu\not=\nu'}\frac{1}{1-e^{-\beta\left(\varepsilon_{\nu'}-\mu\right)}}=\\
 & =\sum_{n_{\nu}}\frac{\frac{1}{\beta}\left(\frac{\partial}{\partial\mu}e^{-\beta\left(\varepsilon_{r}-\mu\right)n_{\nu}}\right)}{\left(1-e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\right)^{-1}}=\left(1-e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\right)\frac{1}{\beta}\frac{\partial}{\partial\mu}\frac{1}{1-e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}}=\\
 & =\frac{e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}}{1-e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}}
\end{align*}
So we get the \emph{Bose-Einstein function}:
\begin{align}
\fbox{\ensuremath{{\displaystyle \overline{n_{\nu}}=\frac{1}{e^{\beta\left(\varepsilon_{\nu}-\mu\right)}-1}}}}\label{eq:BoseEinstein}
\end{align}
Let us call \eqref{eq:BoseEinstein} from now on $n_{\text{BE}}\left(\varepsilon\right)$.

\emph{Note:} $n_{\text{BE}}\left(\varepsilon_{\nu}\right)\xrightarrow{\varepsilon_{\nu}\to\mu}\infty$\\
If one also imposes $n_{\text{BE}}\left(\varepsilon_{\nu}\right)\ge0$,
then
\begin{align}
\varepsilon_{\nu}-\mu & >0
\end{align}
must hold for all $\nu$.

\emph{Note:} For bosons with $\mu=0$ (photons, phonons), the Bose-Einstein
function reduces to the \emph{Planck function}:
\begin{align*}
n_{\text{BE}}\left(\varepsilon\right) & \to\frac{1}{e^{\beta\varepsilon}-1}
\end{align*}



\subsection{Quantum mechanical corrections}

We found that for fermions/bosons holds:
\begin{align*}
\overline{n}_{\nu} & =\frac{1}{e^{\beta\left(\varepsilon_{\nu}-\mu\right)}\pm1}
\end{align*}
For
\begin{align*}
e^{\beta\left(\varepsilon_{\nu}-\mu\right)} & \gg1
\end{align*}
we clearly recover the \emph{Boltzmann function}:
\begin{align*}
\overline{n}_{\nu} & =e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}
\end{align*}
Due to $\varepsilon_{1}\le\varepsilon_{2}\le\ldots$ for this\stepcounter{equation}
\begin{align}
e^{\beta\left(\varepsilon_{1}-\mu\right)} & \gg1\tag{\arabic{chapter}.\arabic{equation}a}\label{eq:Semiclassical-Condition}
\end{align}
is enough. In this case the semi-classical approximation is valid.


\subsubsection*{Specific case of the ideal gas}

We have $\varepsilon_{1}=0$ and so \eqref{eq:Semiclassical-Condition}
becomes $e^{\beta\mu}\ll1$. For the ideal gas holds:
\begin{align*}
e^{\beta\mu} & =\frac{\lambda^{3}}{v}
\end{align*}
So we get as condition for validity of semi-classical description:
\begin{align}
\fbox{\ensuremath{{\displaystyle \lambda^{3}\ll v}}}\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
The higher $T$, the lower is $\lambda$ and the better for validity
of the semi-classical derivation.

Now we would like to investigate the leading order correction in $e^{\beta\mu}$
to the quantum statistics. Let us then start from $\ln\left(Y\right)$:
\begin{align*}
\ln\left(Y\right) & =\pm\ln\left(\prod_{\nu}\left(1\pm e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\right)\right)=\pm\sum_{\nu}\ln\left(1\pm e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\right)
\end{align*}
We expand in powers of $e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}$
and remember $\ln\left(1\pm x\right)=\pm x-\frac{x^{2}}{2}+\mathcal{O}\left(x^{3}\right)$.
We then have:
\begin{align*}
\ln\left(Y\right) & =\sum_{\nu}e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\mp\frac{1}{2}e^{-2\beta\left(\varepsilon_{\nu}-\mu\right)}+\ldots
\end{align*}
This shows that to the leading order no influence of the statistics
is seen.


\subsubsection*{Lowest order}

\begin{align*}
\ln\left(Y\right) & =\sum_{\nu}e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\\
\Rightarrow\qquad N & =\frac{1}{\beta}\frac{\partial\ln\left(Y\right)}{\partial\mu}=\frac{1}{2s+1}\frac{\lambda^{3}}{v}e^{\beta\mu}=\ln\left(Y\right)\stackrel{J=-k_{B}T\ln\left(Y\right)=-PV}{=}\frac{PV}{k_{B}T}
\end{align*}
\begin{align*}
\Rightarrow\qquad e^{\beta\mu} & =\frac{1}{2s+1}\frac{\lambda^{3}}{V}
\end{align*}



\subsubsection*{Next leading order}

\begin{align*}
N & =\frac{1}{\beta}\frac{\partial\ln\left(Y\right)}{\partial\mu}=\sum_{\nu}\left(e^{-\beta\left(\varepsilon_{\nu}-\mu\right)}\mp e^{-2\beta\left(\varepsilon_{\nu}-\mu\right)}\right)=\\
 & =\ln\left(Y\right)\mp\frac{1}{2}\sum_{\nu}e^{-2\beta\left(\varepsilon_{\nu}-\mu\right)}=\frac{PV}{k_{B}T}\mp\frac{1}{2}\sum_{\nu}e^{-2\beta\left(\varepsilon_{\nu}-\mu\right)}
\end{align*}
So the equation of state is:
\begin{align*}
PV=Nk_{B}T\mp\frac{1}{2\beta}\sum_{\nu}e^{-2\beta\left(\varepsilon_{\nu}-\mu\right)}
\end{align*}



\subsubsection*{Ideal gas}

\begin{align*}
\sum_{\nu}e^{-2\beta\left(\varepsilon_{\nu}-\mu\right)} & =\frac{2s+1}{2^{\frac{3}{2}}}\frac{V}{\lambda^{3}}e^{2\beta\mu}=\frac{2s+1}{2^{\frac{3}{2}}}\frac{V}{\lambda^{3}}\left(\frac{1}{2s+1}\frac{\lambda^{3}}{V}\right)^{2}=\\
 & =\frac{\lambda^{3}}{2^{\frac{3}{2}}\cdot\left(2s+1\right)V}
\end{align*}
\begin{align*}
\Rightarrow\qquad\fbox{\ensuremath{{\displaystyle PV=NK_{B}T\left(1+\frac{B_{\text{qm}}\left(T\right)}{v}\right)}}}
\end{align*}
\begin{align*}
B_{\text{qm}}\left(T\right) & =\pm\frac{\lambda^{3}}{2^{\frac{5}{2}}\cdot\left(2s+1\right)}
\end{align*}
$B_{\text{qm}}\left(T\right)$ are the quantum mechanical corrections.
For the energy follows:
\begin{align*}
E & =\frac{3}{2}Nk_{B}T\left(1+\frac{B_{\text{qm}}\left(T\right)}{v}\right)
\end{align*}



\section{Density of states}

Let us calculate the average energy and particle number of an ensemble
of independent particles.
\begin{align*}
E\left(T,v,\mu\right) & =\sum_{\nu}\varepsilon_{\nu}\overline{n}_{\nu}\left(\varepsilon_{\nu}\right)\\
N\left(T,v,\mu\right) & =\sum_{\nu}\overline{n}_{\nu}\left(\varepsilon_{\nu}\right)
\end{align*}
We introduce the \emph{density of states}:
\begin{align}
\mathcal{D}\left(\varepsilon\right) & =\sum_{\nu}\delta\left(\varepsilon_{\nu}-\varepsilon\right)
\end{align}
For the ideal gas holds:
\begin{align*}
\mathcal{D}\left(\varepsilon\right) & =\sum_{s_{z},\vec{p}}\delta\left(\varepsilon_{p}-\varepsilon\right)=\left(2s+1\right)\frac{V}{h^{3}}\int\dd^{3}p\delta\left(\frac{p^{2}}{2m}-\varepsilon\right)=\\
 & =\left(2s+1\right)\frac{4\pi V}{h^{3}}\int p^{2}\dd p\delta\left(\frac{p^{2}}{2m}-\varepsilon\right)=\\
 & \sr ={x=\frac{p^{2}}{2m}}{2p\dd p=2m\dd x}\left(2s+1\right)\frac{4\pi mV}{h^{3}}\int\sqrt{2mx}\dd x\delta\left(x-\varepsilon\right)=\\
 & =\left(2s+1\right)\left(2\pi V\right)\frac{\left(2m\right)^{\frac{3}{2}}}{h^{3}}\sqrt{\varepsilon}=\left(2s+1\right)\frac{V}{4\pi^{2}\hbar^{3}}\left(2m\right)^{\frac{3}{2}}\sqrt{\varepsilon}=\\
 & =\frac{3N}{2}\cdot\underbrace{\frac{\left(2s+1\right)\left(2m\right)^{\frac{3}{2}}v}{6\pi^{2}\hbar^{3}}}_{=\varepsilon_{F}^{-\frac{3}{2}}}\sqrt{\varepsilon}=\frac{3}{2}\cdot\frac{N}{\varepsilon_{F}}\cdot\sqrt{\frac{\varepsilon}{\varepsilon_{F}}}\sim\sqrt{\varepsilon}
\end{align*}
The density of states per particle is:
\begin{align}
d\left(\varepsilon\right) & :=\frac{\mathcal{D}\left(\varepsilon\right)}{N}=\frac{3}{2\varepsilon_{F}}\sqrt{\frac{\varepsilon}{\varepsilon_{F}}}\label{eq:ideal_gas-density-of-states-pp}
\end{align}
It holds:
\begin{align*}
E\left(T,V,\mu\right) & =\int_{0}^{\infty}\dd\varepsilon\cdot\varepsilon\mathcal{D}\left(\varepsilon\right)n\left(\varepsilon\right)\\
N\left(T,V,\mu\right) & =\int_{0}^{\infty}\dd\varepsilon\cdot\mathcal{D}\left(\varepsilon\right)n\left(\varepsilon\right)
\end{align*}



\section{Independent Fermi systems}


\subsubsection*{Sommerfeld expansion}

It is an approximation, which enables us to calculate integrals of
the form
\begin{align*}
\int\dd\varepsilon g\left(\varepsilon\right)f\left(\varepsilon\right)
\end{align*}
with the Fermi-Dirac function $f\left(\varepsilon\right)$ for a system
with density of states per particle $d\left(\varepsilon\right)$.
\begin{enumerate}
\item Step: Introduce:
\begin{align*}
\eta\left(x\right) & \sr ={x=\beta\left(\varepsilon-\mu\right)}{}f\left(\varepsilon\right)-\Theta\left(\mu-\varepsilon\right)=\frac{1}{e^{x}+1}-\Theta\left(-x\right)
\end{align*}
\textcolor{green}{TODO: Plot $\left(e^{x}+1\right)^{-1}$, $\Theta\left(-x\right)$,
$\eta\left(x\right)$}
\item Step: Consider:
\begin{align*}
\int_{0}^{\infty}\dd\varepsilon g\left(\varepsilon\right)f\left(\varepsilon\right) & =\int_{0}^{\mu}\dd\varepsilon g\left(\varepsilon\right)+\int_{0}^{\infty}\dd\varepsilon g\left(\varepsilon\right)\underbrace{\left(f\left(\varepsilon\right)-\Theta\left(\mu-\varepsilon\right)\right)}_{=\eta\left(x\right)}
\end{align*}
We expand $g\left(\varepsilon\right)$ around $\mu$ in the second
integral
\begin{align*}
g\left(\varepsilon\right) & =g\left(\mu\right)+g'\left(\mu\right)\left(\varepsilon-\mu\right)+\frac{g''\left(\mu\right)}{2}\left(\varepsilon-\mu\right)^{2}+\ldots
\end{align*}
to get:
\begin{align}
\int_{0}^{\infty}\dd\varepsilon g\left(\varepsilon\right)f\left(\varepsilon\right) & \sr ={x=\beta\left(\varepsilon-\mu\right)}{}\int_{0}^{\mu}\dd\varepsilon g\left(\varepsilon\right)+\frac{1}{\beta}\int_{-\beta\mu}^{\infty}\dd x\left(g\left(\mu\right)+g'\left(\mu\right)\frac{x}{\beta}+\ldots\right)\eta\left(x\right)\approx\nonumber \\
 & \approx\int_{0}^{\mu}\dd\varepsilon g\left(\varepsilon\right)+\frac{1}{\beta}\int_{-\infty}^{\infty}\dd x\left(g\left(\mu\right)+g'\left(\mu\right)\frac{x}{\beta}+\ldots\right)\eta\left(x\right)=\nonumber \\
 & \stackrel{\eta\left(x\right)\text{ is odd}}{=}\int_{0}^{\mu}\dd\varepsilon g\left(\varepsilon\right)+\frac{g'\left(\mu\right)}{\beta^{2}}\underbrace{\int_{-\infty}^{\infty}\dd x\cdot x\eta\left(x\right)}_{=2\int_{0}^{\infty}\dd x\frac{x}{e^{x}+1}=\frac{\pi^{2}}{6}}+\,\mathcal{O}\left(\left(\frac{T}{\varepsilon_{F}}\right)^{4}\right)\approx\nonumber \\
 & \approx\int_{0}^{\mu}\dd\varepsilon g\left(\varepsilon\right)+\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}g'\left(\mu\right)\label{eq:naeherungIntG}
\end{align}

\item Step: We still must consider the dependence $\mu=\mu\left(T\right)$.
\begin{align}
\int_{0}^{\mu}\dd\varepsilon g\left(\varepsilon\right) & =\int_{0}^{\varepsilon_{F}}\dd\varepsilon g\left(\varepsilon\right)+\int_{\varepsilon_{F}}^{\mu}\dd\varepsilon g\left(\varepsilon\right)
\end{align}
Recall now $N=\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)f\left(\varepsilon\right)$
to get:
\begin{align*}
1 & =\int\dd\varepsilon d\left(\varepsilon\right)f\left(\varepsilon\right)\\
\stackrel{\text{at }T=0}{\Rightarrow}\qquad1 & =\int_{0}^{\varepsilon_{F}}\dd\varepsilon d\left(\varepsilon\right)
\end{align*}
Applying \eqref{eq:naeherungIntG} this gives:
\begin{align*}
1 & =\frac{1}{N}\int_{0}^{\infty}\dd\varepsilon\mathcal{D}\left(\varepsilon\right)f\left(\varepsilon\right)\approx\int_{0}^{\mu}\dd\varepsilon d\left(\varepsilon\right)+\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}d'\left(\mu\right)
\end{align*}
\begin{align*}
\int_{\varepsilon_{F}}^{\mu}\dd\varepsilon d\left(\varepsilon\right) & \sr ={\text{mean value theorem}}{\tilde{\varepsilon}\,\in\,\left[\varepsilon_{F},\mu\right]}\left(\mu-\varepsilon_{F}\right)d\left(\tilde{\varepsilon}\right)
\end{align*}
\begin{align}
1 & =\underbrace{\int_{0}^{\varepsilon_{F}}\dd\varepsilon d\left(\varepsilon\right)}_{=1}+\left(\mu-\varepsilon_{F}\right)d\left(\tilde{\varepsilon}\right)+\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}d'\left(\mu\right)\nonumber \\
\Rightarrow\quad\mu-\varepsilon_{F} & =-\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}\frac{d'\left(\mu\right)}{d\left(\tilde{\varepsilon}\right)}\approx-\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}\frac{d'\left(\varepsilon_{F}\right)}{d\left(\varepsilon_{F}\right)}+o\left(\left(\frac{T}{\varepsilon_{F}}\right)^{2}\right)
\end{align}
With this we get:
\begin{align}
\mu & =\varepsilon_{F}+\mathcal{O}\left(T^{2}\right)
\end{align}
For the ideal gas follows:
\begin{align*}
\mu & =\varepsilon_{F}\left(1-\frac{\pi^{2}}{12}\left(\frac{k_{B}T}{\varepsilon_{F}}\right)^{2}\right)
\end{align*}
So the expansion implies on one side $k_{B}T\ll\varepsilon_{F}$.\\
For metals holds $T_{F}=\frac{\varepsilon_{F}}{k_{B}}\approx10^{4}\,\text{K}$
and so even at room temperature $\mu\left(T\right)\approx\varepsilon_{F}$
is a very good approximation.
\item Step: Hence we can approximate:
\begin{align}
\int_{0}^{\infty}\dd\varepsilon g\left(\varepsilon\right)f\left(\varepsilon\right) & =\int_{0}^{\varepsilon_{F}}\dd\varepsilon g\left(\varepsilon\right)-\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}\left(g\left(\varepsilon_{F}\right)\frac{d'\left(\varepsilon_{F}\right)}{d\left(\varepsilon_{F}\right)}-g'\left(\varepsilon_{F}\right)\right)
\end{align}

\end{enumerate}

\subsubsection*{Application: Specific heat of metals}

The energy per particle is:

\begin{align}
\frac{E}{N} & =\int_{0}^{\infty}\dd\varepsilon\underbrace{\varepsilon d\left(\varepsilon\right)}_{=g\left(\varepsilon\right)}f\left(\varepsilon\right)\approx\nonumber \\
 & \approx\int_{0}^{\varepsilon_{F}}\dd\varepsilon\cdot\varepsilon d\left(\varepsilon\right)-\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}\left(\varepsilon_{F}d'\left(\varepsilon_{F}\right)-d\left(\varepsilon_{F}\right)-\varepsilon_{F}d'\left(\varepsilon_{F}\right)\right)=\nonumber \\
 & =\frac{E_{0}}{N}+\frac{\pi^{2}}{6}\left(k_{B}T\right)^{2}d\left(\varepsilon_{F}\right)
\end{align}
This gives the specific heat:
\begin{align*}
c_{V} & =\frac{\partial}{\partial T}\frac{E}{N}=\underbrace{\frac{\pi^{2}}{3}k_{B}^{2}d\left(\varepsilon_{F}\right)}_{=:\gamma}T=\gamma T
\end{align*}
%DATE: Di 27.11.12

For the ideal gas is the density of states per particle at the Fermi
energy is (see \ref{eq:ideal_gas-density-of-states-pp}):
\begin{align*}
d\left(\varepsilon_{F}\right) & =\frac{3}{2\varepsilon_{F}}
\end{align*}
With this the Sommerfeld formula gives:
\begin{align*}
c_{V}\left(T\right) & =\frac{\pi^{2}k_{B}^{2}}{2\varepsilon_{F}}T=\gamma T
\end{align*}
\textcolor{green}{TODO: Plot of the real $c_{V}\left(T\right)$ curve}

\emph{Note}: If one includes also the contribution of lattice vibrations
(phonons), one gets (see integrated course IIa):
\begin{align}
c_{V}\left(T\right) & =\gamma T+\alpha T^{3}
\end{align}
The $T^{3}$ term is due to the phonons, while the $T$ term comes
from the electrons.

\noindent \begin{center}
\begin{tabular}{c|c}
Metal$\vphantom{\bigg|}$ & ${\displaystyle \frac{\gamma_{\text{measured}}}{\gamma}}$\tabularnewline
\hline 
\hline 
Li$\vphantom{\Big|}$ & 2,17\tabularnewline
\hline 
Na$\vphantom{\Big|}$ & 1,21\tabularnewline
\hline 
K$\vphantom{\Big|}$ & 1,23\tabularnewline
\hline 
Rb$\vphantom{\Big|}$ & 1,22\tabularnewline
\hline 
Cs$\vphantom{\Big|}$ & 1,39\tabularnewline
\hline 
Cu$\vphantom{\Big|}$ & 1,39\tabularnewline
\hline 
Ag$\vphantom{\Big|}$ & 1,00\tabularnewline
\hline 
Au$\vphantom{\Big|}$ & 1,13\tabularnewline
\end{tabular}
\par\end{center}

For other metals, the agreement between the measured and the theoretically
predicted $\gamma$ is not that good, for example:
\begin{align*}
\text{Fe: }\frac{\gamma_{\text{measured}}}{\gamma} & =8{,}0 & \text{Bi: }\frac{\gamma_{\text{measured}}}{\gamma} & =0{,}05
\end{align*}



\subsubsection*{Fermi pressure}

For nonrelativistic free electrons hold:
\begin{align}
P\left(T,V,N\right) & =\frac{2}{3}\frac{E\left(T,V,N\right)}{V}=\frac{2}{3}\frac{E_{0}}{V}+\frac{\pi^{2}}{6}\cdot\frac{Nk_{B}T}{V}\cdot\frac{k_{B}T}{\varepsilon_{F}}
\end{align}
So at $T=0$ the pressure in a Fermi gas does not vanish! It remains
the \emph{Fermi pressure.} For the ideal gas this is (cf. \eqref{eq:E0}):
\begin{align*}
P_{\text{Fermi}} & =P\left(T=0,V,N\right)=\frac{2}{3}\cdot\frac{3}{5}\frac{N}{V}\varepsilon_{F}=\frac{2}{5}\frac{N}{V}\varepsilon_{F}
\end{align*}
So the incompressibility of solids and liquids is (partly) a consequence
of the Pauli principle.

\emph{Note}: The Fermi pressure plays an important role in some models
of stars: at equilibrium the matter pressure must compensate the gravitational
pressure.


\section{Independent Bose systems}

We discuss some consequences of the Bose-Einstein distribution:
\begin{enumerate}[label=\roman*)]
\item Bose-Einstein condensation (BEC)
\item Planck's radiation law
\end{enumerate}

\subsection{Bose-Einstein condensation}

The Bose-Einstein distribution favors a situation in which the greatest
part of the population is in the ground orbitat at sufficiently low
temperatures. The particles in the ground state are called ``condensate''.
\begin{itemize}
\item First predicted by Einstein for the ideal gas in 1924.
\item Closest experimental demonstration: BEC of an ultracold gas of alkali
atoms by E. A. Cornell, W. Ketterle and C. E. Wiemann in 1999.
\end{itemize}

\subsubsection*{Ground state occupation}

The Bose-Einstein distribution is:
\begin{align*}
n_{\text{BE}}\left(\varepsilon_{\nu}\right) & =\frac{1}{e^{\beta\left(\varepsilon_{\nu}-\mu\right)}-1}
\end{align*}
For a system of $N$-particles holds for all states $\nu$:
\begin{align*}
0 & \le n_{\text{BE}}\left(\varepsilon_{\nu}\right)\le N
\end{align*}
For the ground state with energy $\varepsilon_{1}$ we have:
\begin{align*}
n_{\text{BE}}\left(\varepsilon_{1}\right) & =\overline{n}_{g}=\frac{1}{e^{\beta\left(\varepsilon_{1}-\mu\right)}-1}
\end{align*}
In the limit of low temperatures this gives:
\begin{align*}
N=\lim_{T\to0}n_{\text{BE}}\left(\varepsilon_{1}\right) & =\lim_{T\to0}\frac{1}{e^{\beta\left(\varepsilon_{1}-\mu\right)}-1}=\lim_{T\to0}\frac{k_{B}T}{\varepsilon_{1}-\mu}
\end{align*}
Since $N$ is a large number, $\mu\lessapprox\varepsilon_{1}$ must
hold and moreover:
\begin{align*}
0 & \lessapprox\frac{\varepsilon_{1}-\mu}{k_{B}T}
\end{align*}
\emph{Note}: For the ideal gas holds:
\begin{align*}
\varepsilon_{1} & =\frac{\hbar^{2}}{2m}\frac{\pi^{2}}{L^{2}}\underbrace{\left(1+1+1\right)}_{n_{x}=n_{y}=n_{z}=1}=\frac{3}{2}\frac{\hbar^{2}}{m}\cdot\frac{\pi^{2}}{L^{2}}\xrightarrow{V\to\infty}0
\end{align*}
This implies $\mu\le0$ and $\lim_{T\to0}\mu=0$.


\subsubsection*{Critical temperature}

It seems that something special happens, when the chemical potential
approaches the largest allowed value $\varepsilon_{1}$.

At which critical temperature does it happen?

To this extend we calculate $N$:
\begin{align*}
N & =\sum_{\nu}\overline{n}_{\nu}\approx\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)n_{\text{BE}}\left(\varepsilon\right)=\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)\frac{1}{e^{\beta\left(\varepsilon-\mu\right)}-1}=\\
 & =\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)\sum_{l=1}^{\infty}e^{-\beta\left(\varepsilon-\mu\right)l}=\sum_{l=1}^{\infty}e^{\beta\mu l}\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)e^{-\beta\varepsilon l}
\end{align*}
Now we need to specify $\mathcal{D}\left(\varepsilon\right)$. We
account for a zero-point energy:
\begin{align*}
\mathcal{D}\left(\varepsilon\right) & \to\mathcal{D}_{m}\left(\varepsilon,\varepsilon_{g}\right)=A\left(\varepsilon-\varepsilon_{g}\right)^{m}\Theta\left(\varepsilon-\varepsilon_{g}\right)
\end{align*}
We thus get:
\begin{align*}
N & =\sum_{l=1}^{\infty}e^{\beta\mu l}\int_{\varepsilon_{g}}^{\infty}\dd\varepsilon A\left(\varepsilon-\varepsilon_{g}\right)^{m}e^{-\beta\varepsilon l}=\\
 & \sr ={x=l\left(\varepsilon-\varepsilon_{g}\right)}{\dd\varepsilon=\frac{1}{l}\dd\varepsilon x}\sum_{l=1}^{\infty}\frac{e^{\beta\left(\mu-\varepsilon_{g}\right)l}}{l^{m+1}}\underbrace{\int_{0}^{\infty}\dd x\cdot Ax^{m}e^{-\beta x}}_{=Z_{1}\left(T\right)}=\\
 & =Z_{1}\left(T\right)\sum_{l=1}^{\infty}\frac{e^{\beta\left(\mu-\varepsilon_{g}\right)l}}{l^{m+1}}
\end{align*}
Now we introduced the generalized Riemannian zeta function
\begin{align}
g_{\nu}\left(z\right) & =\sum_{l=1}^{\infty}\frac{z^{l}}{l^{\nu}}\label{eq:general-Riemann-zeta-function}
\end{align}
to get:
\begin{align}
N & =Z_{1}\left(T\right)g_{m+1}\left(e^{\beta\left(\mu-\varepsilon_{g}\right)}\right)
\end{align}
The critical temperature is defined by
\begin{align*}
\mu\left(T_{c}\right) & =\varepsilon_{g}
\end{align*}
or:
\begin{align}
\fbox{\ensuremath{{\displaystyle \frac{N}{Z_{1}\left(T_{c}\right)}=g_{m+1}\left(e^{\frac{\mu\left(T_{c}\right)-\varepsilon_{g}}{k_{B}T_{c}}}\right)}\stackrel{g_{m+1}\left(1\right)=\zeta\left(m+1\right)}{=}\zeta\left(m+1\right)}}\label{eq:critical_temperature}
\end{align}
Here $\zeta$ is the Riemannian zeta function.

%DATE: Fr 30.11.12

Where do the remaining particles go? We were calculating $N$ as:
\begin{align*}
N & =\sum_{\nu}\overline{n}_{\nu}\approx\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)n_{\text{BE}}\left(\varepsilon\right)
\end{align*}
Here we missed the occupation of the ground state. However, this is
only fine, when $\overline{n}_{g}\ll N$ holds. What happens for $T>T_{c}$?
In general we must include the particles of the ground state:
\begin{align*}
N & =\overline{n}_{g}+\sum_{\nu\not=g}\overline{n}_{\nu}\approx\overline{n}_{g}+\int\dd\varepsilon\mathcal{D}\left(\varepsilon\right)n_{\text{BE}}\left(\varepsilon\right)=\overline{n}_{g}+z_{1}\left(T\right)g_{m+1}\left(e^{\beta\left(\mu-\varepsilon_{g}\right)}\right)
\end{align*}
For $T\le T_{c}$ we get:
\begin{align*}
N & =\overline{n}_{g}+Z_{1}\left(T\right)\zeta\left(m+1\right)\stackrel{\eqref{eq:critical_temperature}}{=}\overline{n}_{g}+N\frac{Z_{1}\left(T\right)}{Z_{1}\left(T_{c}\right)}
\end{align*}
\begin{align}
\Rightarrow\qquad\overline{n}_{g} & =N\left(1-\frac{Z_{1}\left(T\right)}{Z_{1}\left(T_{c}\right)}\right)
\end{align}
For $T>T_{c}$ we have $\overline{n}_{g}\ll N$.

\textcolor{green}{TODO: Abb $\mu\left(T\right)$, $\overline{n}_{g}\left(T\right)$}

$\overline{n}_{g}$ is the order parameter in the Bose-Einstein condensation.


\subsubsection{Critical density}

Likewise, one can keep $T$ constant and vary $N$ (at $V=\text{const.}$).
We denote by $n_{c}=\frac{N_{c}}{V}$ the \emph{critical density}:
\begin{align}
\frac{N_{c}}{Z_{1}\left(T\right)} & =\zeta\left(m+1\right)
\end{align}



\subsubsection*{Application: ideal gas}

For the ideal gas holds $\mu_{c}=\varepsilon_{g}=0$, $Z_{1}=\frac{V}{\lambda^{3}}$,
$\mathcal{D}\left(\varepsilon\right)\sim\varepsilon^{\frac{1}{2}}$,
i.e. $m=\frac{1}{2}$, and $\lambda=\frac{h}{\sqrt{2\pi mk_{B}T}}$.
With this we obtain for $T\ge T_{c}$:
\begin{align}
N\left(T,V,\mu\right) & =\frac{V}{\lambda^{3}}\cdot g_{\frac{3}{2}}\left(e^{\beta\mu}\right)\label{eq:particle-number-ideal-gas}
\end{align}
The critical temperature is then obtained from:
\begin{align*}
\frac{N\left(T_{c},V,\mu=0\right)}{Z_{1}\left(T_{c}\right)} & =\zeta\left(\frac{3}{2}\right)
\end{align*}
So for the ideal gas we get:
\begin{align}
\fbox{\ensuremath{{\displaystyle \frac{\lambda_{c}^{3}}{v}=\zeta\left(\frac{3}{2}\right)\approx2{,}616}}}
\end{align}
The critical temperature is therefore:
\begin{align*}
k_{B}T_{c} & \approx\frac{2\pi}{\left(\zeta\left(\frac{3}{2}\right)\right)^{\frac{2}{3}}}\frac{\hbar^{2}}{mv^{\frac{2}{3}}}
\end{align*}
\emph{Example}: For the parameters of liquid $^{4}\text{He}$ with
$v=46\,\ang^{3}$ is $T_{c}=3{,}13\,\text{K}$.
\begin{itemize}
\item Temperature dependence of the ground state occupation:
\begin{align*}
\frac{Z_{1}\left(T\right)}{Z_{1}\left(T_{c}\right)} & =\left(\frac{T}{T_{c}}\right)^{\frac{3}{2}}
\end{align*}
For $T\le T_{c}$ follows:
\begin{align}
\overline{n}_{g} & =N\left(1-\left(\frac{T}{T_{c}}\right)^{\frac{3}{2}}\right)
\end{align}

\item The Energy is (cf. \noun{Fließbach}, chapter 31, page 269):
\begin{align}
E & =\sum_{\vec{p}}\varepsilon_{p}\overline{n}_{p}=\frac{3}{2}k_{B}T\frac{V}{\lambda^{3}}\cdot g_{\frac{5}{2}}\left(e^{\beta\mu}\right)\label{eq:energy-ideal-bose-gas}
\end{align}
This expression is also valid above $T_{C}$, because the ground state
energy for an ideal gas is zero.
\end{itemize}

\subsubsection*{Specific heat of the ideal gas}

\begin{align*}
\frac{c_{V}\left(T\right)}{k_{B}} & =\frac{1}{Nk_{B}}\frac{\partial E\left(T,V,N\right)}{\partial T}
\end{align*}

\begin{enumerate}[label=\roman*)]
\item For $T\le T_{c}$ we have $\mu=0$ and:
\begin{align*}
\frac{E}{N} & =\frac{3}{2}k_{B}T\frac{v}{\lambda^{3}}\zeta\left(\frac{5}{2}\right)
\end{align*}
Due to $\lambda\sim T^{-\frac{1}{2}}$ and thus
\begin{align*}
\frac{\partial}{\partial T}\left(\frac{T}{\lambda^{3}}\right) & \stackrel{\lambda^{-3}=\alpha T^{\frac{3}{2}}}{=}\alpha\frac{\partial}{\partial T}T^{\frac{5}{2}}=\frac{5}{2}\underbrace{\alpha T^{\frac{3}{2}}}_{=\lambda^{-3}}=\frac{5}{2\lambda^{3}}
\end{align*}
follows:
\begin{align}
\frac{c_{V}\left(T\right)}{k_{B}} & =\frac{15}{4}\frac{v}{\lambda^{3}}\zeta\left(\frac{5}{2}\right)\stackrel{v=\frac{\lambda_{c}^{3}}{\zeta\left(\frac{3}{2}\right)}}{=}\frac{15}{4}\frac{\lambda_{c}^{3}}{\lambda^{3}}\frac{\zeta\left(\frac{5}{2}\right)}{\zeta\left(\frac{3}{2}\right)}=\frac{15}{4}\frac{\zeta\left(\frac{5}{2}\right)}{\zeta\left(\frac{3}{2}\right)}\left(\frac{T}{T_{c}}\right)^{\frac{3}{2}}
\end{align}

\item For $T>T_{c}$ follows from \eqref{eq:energy-ideal-bose-gas}:
\begin{align*}
\frac{c_{V}\left(T\right)}{k_{B}} & =\frac{15}{4}\frac{v}{\lambda^{3}}g_{\frac{5}{2}}\left(e^{\beta\mu}\right)+\frac{3}{2}T\frac{v}{\lambda^{3}}g'_{\frac{5}{2}}\left(e^{\beta\mu}\right)\cdot\frac{\partial}{\partial T}\left(e^{\beta\mu\left(T,v\right)}\right)
\end{align*}
To proceed, let us consider \ref{eq:particle-number-ideal-gas} for
$T\ge T_{c}$:
\begin{align*}
1 & =\frac{v}{\lambda^{3}}g_{\frac{3}{2}}\left(e^{\beta\mu}\right)
\end{align*}
Upon taking $\frac{\partial}{\partial T}$ this yields and the multiplying
by $\lambda^{3}$:
\begin{align*}
0 & =\frac{3}{2T}g_{\frac{3}{2}}\left(e^{\beta\mu}\right)+g_{\frac{3}{2}}'\left(e^{\beta\mu}\right)\frac{\partial}{\partial T}e^{\beta\mu\left(T,v\right)}\\
\Rightarrow\qquad\frac{\partial}{\partial T}e^{\beta\mu\left(T,v\right)} & =-\frac{3}{2T}\frac{g_{\frac{3}{2}}\left(e^{\beta\mu}\right)}{g_{\frac{3}{2}}'\left(e^{\beta\mu}\right)}
\end{align*}
Thus we get:
\begin{align*}
\frac{c_{V}\left(T\right)}{k_{B}} & =\frac{15}{4}\frac{v}{\lambda^{3}}g_{\frac{5}{2}}\left(e^{\beta\mu}\right)+\frac{3}{2}T\frac{v}{\lambda^{3}}g'_{\frac{5}{2}}\left(e^{\beta\mu}\right)\left(-\frac{3}{2T}\frac{g_{\frac{3}{2}}\left(e^{\beta\mu}\right)}{g_{\frac{3}{2}}'\left(e^{\beta\mu}\right)}\right)=\\
 & \sr ={z:=e^{\beta\mu}}{\frac{\lambda^{3}}{v}=g_{\frac{3}{2}}\left(z\right)}\frac{15}{4}\cdot\frac{g_{\frac{5}{2}}\left(z\right)}{g_{\frac{3}{2}}\left(z\right)}-\frac{9}{4}\cdot\frac{g'_{\frac{5}{2}}\left(z\right)}{g_{\frac{3}{2}}\left(z\right)}\cdot\frac{g_{\frac{3}{2}}\left(z\right)}{g_{\frac{3}{2}}'\left(z\right)}=\\
 & =\frac{15}{4}\cdot\frac{g_{\frac{5}{2}}\left(z\right)}{g_{\frac{3}{2}}\left(z\right)}-\frac{9}{4}\cdot\frac{g'_{\frac{5}{2}}\left(z\right)}{g_{\frac{3}{2}}'\left(z\right)}=\frac{15}{4}\cdot\frac{g_{\frac{5}{2}}\left(z\right)}{g_{\frac{3}{2}}\left(z\right)}-\frac{9}{4}\cdot\frac{g{}_{\frac{3}{2}}\left(z\right)}{g_{\frac{1}{2}}\left(z\right)}
\end{align*}
In the last step we used:
\begin{align*}
zg'_{\nu}\left(z\right) & =g_{\nu-1}\left(z\right)
\end{align*}
This follows directly from the definition \eqref{eq:general-Riemann-zeta-function}.
So for $T>T_{c}$ the result is:
\begin{align}
\frac{C_{V}\left(T\right)}{k_{B}} & =\frac{15}{4}\frac{g_{\frac{5}{2}}\left(e^{\beta\mu}\right)}{g_{\frac{3}{2}}\left(e^{\beta\mu}\right)}-\frac{9}{4}\frac{g_{\frac{3}{2}}\left(e^{\beta\mu}\right)}{g_{\frac{1}{2}}\left(e^{\beta\mu}\right)}
\end{align}

\end{enumerate}
\emph{Note:} For $T\gg T_{c}$ or equivalently $\frac{\lambda^{3}}{v}\ll1$
we have $e^{\beta\mu}\ll1$ and with
\begin{align*}
g_{\nu}\left(z\right) & \approx z+\frac{z^{2}}{2^{\nu}}
\end{align*}
for $z\ll1$ we get:
\begin{align}
\frac{c_{V}\left(T\right)}{k_{B}} & \approx\frac{3}{2}\left(1+\frac{e^{\beta\mu}}{2^{\frac{7}{2}}}\right)
\end{align}
To leading order in $z\approx\frac{\lambda^{3}}{v}=\left(\frac{T_{c}}{T}\right)^{\frac{3}{2}}\zeta\left(\frac{3}{2}\right)$
follows.
\begin{align*}
\frac{c_{V}\left(T\right)}{k_{B}} & \approx\frac{3}{2}\left(1+\frac{\zeta\left(\frac{3}{2}\right)}{2^{\frac{7}{2}}}\left(\frac{T_{c}}{T}\right)^{\frac{3}{2}}\right)
\end{align*}
\emph{Note:}
\begin{align*}
\zeta\left(\frac{1}{2}\right) & =\infty
\end{align*}
\begin{align*}
g_{\frac{1}{2}}\left(z\right) & \xrightarrow{z\to0}\infty
\end{align*}
This implies for $T=T_{c}$:
\begin{align*}
\frac{c_{V}\left(T_{c}\right)}{k_{B}} & =\frac{15}{4}\frac{\zeta\left(\frac{5}{2}\right)}{\zeta\left(\frac{3}{2}\right)}\approx1.925
\end{align*}
\textcolor{green}{TODO: Abb16; Plot $\frac{c_{V}}{T}$}

So the specific heat is continuous, but not its derivative!

What is the order of the Bose-Einstein condensation phase transition?

Paul Ehrenfest introduced a ordering scheme for phase transitions:
\begin{quote}
The order of a transition is the lowest derivative of the free energy,
that is discontinuous at the critical temperature.
\end{quote}
This classification proofed not be useful and thus one introduced
the modern classification, that is named similarly to the Ehrenfest
classification:
\begin{quote}
A \emph{first order} phase transition involves latent heat, i.e. $c_{P}$
is singular, while a \emph{second order} phase transition does not
involve latent heat, i.e. $c_{P}$ is finite.
\end{quote}
The Bose-Einstein condensation involves latent heat and thus is of
first order.


\subsubsection*{Equation of state for the ideal gas}

From
\begin{align*}
P\left(T,V,N\right) & =\frac{2}{3}\frac{E\left(T,V,N\right)}{V}
\end{align*}
and the above derived expressions for $E\left(T,V,N\right)$ and $N\left(T,V,\mu\right)$
follows for $T\le T_{c}$:
\begin{align}
P\left(T,V,N\right) & =\frac{2}{3}\frac{E\left(T,V,\mu=0\right)}{V}=\frac{k_{B}T}{\lambda^{3}}\zeta\left(\frac{5}{2}\right)
\end{align}
This means:
\begin{align*}
\frac{\partial P\left(T,V,N\right)}{\partial V} & =0
\end{align*}
The system does not resist to a change in volume. In other words the
compressibility diverges:
\begin{align}
\kappa_{T} & =-\frac{1}{V}\frac{\partial V\left(P,T\right)}{\partial P}\to\infty
\end{align}
So $c_{P}$ is diverging as well. In summary:

\textcolor{green}{TODO: Abb17, abb18}


\subsubsection*{Bose-Einstein condensation of ultracold alkali atoms}

The first demonstration was in 1995 by Cornell, Wiemann and Ketterle.
(Nobel Prize 2001)
\begin{itemize}
\item Why alkali atoms? For the ideal gas holds:
\begin{align*}
T_{c} & \approx\frac{2\pi\hbar^{2}}{m}\left(\frac{n}{2{,}612}\right)^{\frac{2}{3}}
\end{align*}
For a gas in a 3D harmonic trap holds:
\begin{align*}
T_{c} & =\frac{\hbar\omega}{k_{B}}\left(\frac{N}{\zeta\left(3\right)}\right)^{\frac{1}{3}}\approx0{,}94\frac{\hbar\omega}{k_{B}}N^{\frac{1}{3}}
\end{align*}
However, the interaction is small for small densities. The condition
for the scattering length $a$ is:
\begin{align*}
n\abs a^{3} & \ll1
\end{align*}
\begin{align*}
a & =\frac{m}{4\pi\hbar}\int\dd^{3}rV\left(r\right)
\end{align*}
This is the $s$-wave scattering length. $V\left(r\right)$ is the
inter atomic potential for neutral atoms.\\
Low densities are required (good), but temperatures are then very
low (bad).\\
\emph{Example}: $^{23}\text{Na}$
\begin{align*}
N & \approx10^{6} & n & \approx10^{14}\,\text{cm}^{-3}
\end{align*}
\begin{align*}
\Rightarrow\quad T_{c} & \approx2\cdot10^{-6}\,\text{K}
\end{align*}
How do you reach this temperature?\\
Use magneto-optical traps and radio-frequency evaporative cooling.\\
\textcolor{green}{TODO: Abb19}
\end{itemize}
%DATE: Di 04.12.12


\subsection{Black body radiation}

We consider a metallic cavity at temperature $T$ and want to evaluate
the emitted radiation.
\begin{enumerate}[label=\roman*)]
\item \emph{Wave equation}: For the radiation inside the cavity, the Maxwell
equations hold. For the electric field $\vec{E}\left(\vec{r},t\right)$
this means:
\begin{align*}
\left(\Delta-\frac{1}{c^{2}}\frac{\partial^{2}}{\partial t^{2}}\right)\vec{E} & =0
\end{align*}
Using the ansatz
\begin{align*}
\vec{E}\left(\vec{r},t\right) & =\vec{E}_{0}e^{\ii\left(\vec{k}\cdot\vec{r}-\omega t\right)}
\end{align*}
yields the dispersion relation:
\begin{align*}
\omega^{2} & =c^{2}\norm{\vec{k}}^{2}
\end{align*}
\begin{align}
\Rightarrow\qquad\fbox{\ensuremath{{\displaystyle \omega=c\norm{\vec{k}}=ck}}}
\end{align}
From
\begin{align*}
\vec{\nabla}\vec{E} & =0
\end{align*}
follows:
\begin{align*}
\vec{k}\cdot\vec{E}_{0} & =0
\end{align*}
So the electric field is transverse to the direction of propagation,
i.e. two components of $\vec{E}_{0}$ are independent. This means
there are ``two kinds'' of photons.
\item \emph{Boundary condition}: Consider the cavity as a cube of volume
$V=L^{3}$. (The shape is irrelevant if $L\gg\lambda=\frac{2\pi}{k}$.)
The walls are metallic, so $\vec{E}_{\parallel}\left(\vec{r},t\right)$
and $\vec{B}_{\perp}\left(\vec{r},t\right)$ vanish at the boundaries,
i.e.:
\begin{align*}
\vec{E}_{\parallel}\left(\vec{r},t\right) & =0 & \vec{B}_{\text{\ensuremath{\perp}}}\left(\vec{r},t\right) & =0
\end{align*}
This leads to standing waves with:
\begin{align}
k & =\frac{n\pi}{L} & \vec{n} & =\left(n_{x},n_{y},n_{z}\right)\in\mathbb{N}^{3} & n & =\sqrt{n_{x}^{2}+n_{y}^{2}+n_{z}^{2}}
\end{align}
The vector $\vec{n}$ specifies the character of the harmonic mode.
\item \emph{Quantization}: Planck made the hypothesis that the amplitudes
$A_{i}\left(t\right)=E_{0,i}\left(\vec{r}\right)\sin\left(\omega t\right)$
of each mode are quantized. This in turn implies quantization of the
energy of each mode. Assuming a mode polarization index $m$ and a
vector $\vec{k}$ it holds:
\begin{align}
\fbox{\ensuremath{{\displaystyle \varepsilon_{j}=\varepsilon_{\vec{k},m}=\hbar\omega\left(k\right)\left(n_{\vec{k},m}+\frac{1}{2}\right)=\hbar\omega\left(k\right)\left(n_{j}+\frac{1}{2}\right)}}}
\end{align}
Here is $j\in\mathbb{N}_{\ge1}$ and $\varepsilon_{1}\le\varepsilon_{2}\le\ldots$.
This means that in the mode with energy $\hbar\omega\left(k\right)$
are $n_{j}$ quanta of light (photons).
\item \emph{Energy of microstate $r$}: $r=\left(n_{1},n_{2},\ldots\right)=\left(n_{\vec{k},m}\right)$
is the microstate with:
\begin{align}
E_{r} & =\sum_{j=1}^{\infty}\varepsilon_{j}=\sum_{m,\vec{k}}\hbar\omega\left(k\right)\left(n_{\vec{k},m}+\frac{1}{2}\right)=E_{0}+\sum_{\vec{k},m}\hbar\omega\left(k\right)n_{\vec{k},m}
\end{align}
Due to $n_{\vec{k},m}\in\mathbb{N}$, the associated ``particles''
are bosons. Moreover the number of particles is not fixed, yielding:
\begin{align*}
\mu & =\frac{\overline{\partial E_{r}}}{\partial N_{\text{ph}}}=0
\end{align*}

\item \emph{Statistics} is obtained from the Bose-Einstein distribution
with $\mu=0$. This gives the \emph{Planck distribution}:
\begin{align}
\overline{n}_{\vec{k},m} & =\overline{n}_{k}=\frac{1}{e^{\beta\hbar\omega\left(k\right)}-1}=\frac{1}{e^{\beta\hbar ck}-1}
\end{align}

\item \emph{Average energy}: Due to $E_{0}=\infty$, we only consider $E'=E-E_{0}$.
We find:
\begin{align*}
E' & =\sum_{\vec{k},m}\varepsilon_{k}\overline{n}_{\vec{k}}=2\sum_{n_{x},n_{y},n_{z}}\varepsilon_{k}\overline{n}_{\vec{k}}=\frac{2V}{\left(2\pi\right)^{3}}\int_{-\infty}^{\infty}\dd^{3}k\frac{\hbar ck}{e^{\beta\hbar ck}-1}=\\
 & =\frac{V}{\pi^{2}}\int_{-\infty}^{\infty}k^{2}\dd k\frac{\hbar ck}{e^{\beta\hbar ck}-1}\sr ={x=\beta\hbar ck}{\dd k=\frac{1}{\beta\hbar c}\dd x}=\frac{V}{\pi^{2}\beta^{4}\hbar^{3}c^{3}}\int_{-\infty}^{\infty}\frac{x^{3}\dd x}{e^{x}-1}=\\
 & =\frac{\pi^{2}V}{15\hbar^{3}c^{3}}\left(k_{B}T\right)^{4}
\end{align*}
With the \emph{Stefan Boltzmann constant}
\begin{align*}
\sigma & =\frac{\pi^{3}k_{B}^{4}}{60\hbar^{3}c^{2}}=\frac{2\pi^{5}k_{B}^{4}}{15h^{3}c^{2}}
\end{align*}
this gives:
\begin{align}
\fbox{\ensuremath{{\displaystyle E'=\frac{4\sigma}{c}VT^{4}}}}
\end{align}
So the heat capacity is:
\begin{align*}
C_{V} & =\frac{16}{c}\sigma VT^{3}
\end{align*}
The dependence on $T^{3}$ is typical of bosons with linear dispersion.
For example this holds also true for \emph{phonons}.
\item \emph{Planck's radiation law}: The integral in the evaluation of $E'$
can also be written as an integral over energy:
\begin{align*}
\frac{E'}{V} & =\int_{0}^{\infty}\dd\omega u\left(\omega\right)
\end{align*}
This gives Planck's radiation law, obtained in 1900:
\begin{align}
\fbox{\ensuremath{{\displaystyle u\left(\omega\right)=\frac{\hbar}{\pi^{2}c^{3}}\frac{\omega^{3}}{e^{\frac{\hbar\omega}{k_{B}T}}-1}}}}
\end{align}
\textcolor{green}{TODO: Plot $u\left(\omega\right)$}\\
For $\omega\to\infty$ holds ${\displaystyle u\left(\omega\right)\approx e^{-\frac{\hbar\omega}{k_{B}T}}\omega^{3}}$
(Wien) and for $\omega\to0$ holds $u\left(\omega\right)\approx\omega^{2}$
(Rayleigh-Jeans).\\
The importance of Planck's law is due to the fact that a pure classical
treatment would have implied:
\begin{align}
u_{\text{cl}}\left(\omega\right) & =\frac{k_{B}T\omega^{2}}{\pi^{2}c^{3}}
\end{align}
This leads to the ultraviolet catastrophe, i.e. the divergence of
$E'$ for high $\omega$.
\item \emph{Stefan-Boltzmann law}: The emitted power from a surface of area
$f$ is (cf. \noun{Fließbach}, chapter 34, page 303):
\begin{align}
\fbox{\ensuremath{{\displaystyle P_{\text{em}}=\frac{E'c}{4V}f=\sigma fT^{4}}}}
\end{align}
This is the Stefan-Boltzmann law. It enables us e.g. to estimate the
temperature of the earth, knowing the temperature of the sun.
\item \emph{Application}: Greenhouse effect
\end{enumerate}
%DATE: Fr 07.12.12


\part{Solid State Theory}


\chapter*{Motivation}

We deal with systems in the solid phase. We look in particular at
electronic and thermal properties of these systems.
\begin{itemize}
\item Because of the large number of constituents, one has to resort to
methods of statistical physics. However, the situation is complicated
due to:

\begin{enumerate}[label=\roman*)]
\item presence of a lattice
\item presence of electrostatic interactions
\end{enumerate}
\item This new complexity requires novel methods ($\to$ second quantization
formalism, $\ldots$) and novel approximations ($\to$ decoupling
of motion of ions and electrons, devise minimal model Hamiltonians
which capture the relevant low energy physics).
\item We shall primarily focus on ``bulk'' properties, i.e. properties
of large crystalline systems. However, present technologies allow
to routinely produce structure of \emph{reduced} dimensionality, e.g.
two dimensional electron gas in graphene, quantum wires, nanotubes,
quantum dots, single molecules, $\ldots$, and also to study hybrids
of those, e.g. use carbon nanotubes as a contact for a molecular junction:\\
\textcolor{green}{TODO: Abb20}
\end{itemize}

\chapter{Introduction to Solid State theory}


\section{The Hamiltonian of a solid}

We consider as a starting point a system as being composed of ions
(nuclei and closed electron shells) and valence electrons. Moreover
we assume that the ions are arranged in a regular lattice at zero
temperature.

\textcolor{green}{TODO: Abb21}

We are also in the situation that the interaction among the constituents
is known (electrostatic interaction). So the Hamiltonian of a solid
then acquires a very general form:
\begin{align}
\hat{H} & =\hat{T}_{\text{ion}}+\hat{T}_{\text{el}}+\hat{V}_{\text{ee}}+\hat{V}_{\text{ii}}+\hat{V}_{\text{ei}}
\end{align}
The $\hat{T}$ are the kinetic energies for the ions and the electrons
and the $\hat{V}$ are the potentials for electron-electron, ion-ion
and electron-ion interaction. Specifically these look like:
\begin{align}
\hat{H} & =-\sum_{\alpha=1}^{M}\frac{\hbar^{2}}{2M_{\alpha}}\nabla_{\alpha}^{2}-\sum_{j=1}^{N}\frac{\hbar^{2}}{2m}\nabla_{j}^{2}+\sum_{j<k}^{N}\frac{e^{2}}{\abs{\vec{r}_{j}-\vec{r}_{k}}}+\sum_{\alpha<\beta}^{M}\frac{Z_{\alpha}Z_{\beta}e^{2}}{\abs{\vec{R}_{\alpha}-\vec{R}_{\beta}}}-\sum_{j}\sum_{\alpha}\frac{Z_{\alpha}e^{2}}{\abs{\vec{r}_{j}-\vec{R}_{\alpha}}}\label{eq:GeneralHamiltonian}
\end{align}
Here $Z_{\alpha}$ is the effective charge number of the ions and
due to charge neutrality holds $N=MZ$.

\emph{Problem:} This Hamiltonian is too complicated to be solved exactly.
So some approximations are required.


\section{Structural reducibility \textmd{(adiabatic approximation)}}

Not all components entering entering \eqref{eq:GeneralHamiltonian}
have to be treated simultaneously. The motion of the electrons and
the motion of the ions decouple. (Born-Oppenheimer approximation)

The decoupling is based on the observation that, due to their large
mass $M_{\alpha}$, the ions move much slower than the electrons of
mass $m$, i.e. the electrons adapt instantaneously to the actual
ion configuration.
\begin{align*}
\frac{m}{M_{\alpha}} & \approx10^{-4}
\end{align*}



\subsubsection*{Qualitative proof}

Assume that the whole system is in thermal equilibrium. So the electrons
and the ions have the same average thermal energy per degree of freedom.
\begin{align*}
\left\langle \frac{mv_{i}^{2}}{2}\right\rangle  & =\left\langle \frac{M_{\alpha}v_{\alpha}^{2}}{2}\right\rangle =\frac{k_{B}T}{2}
\end{align*}
Due to $\frac{m}{M_{\alpha}}\approx10^{-4}$ the electrons move faster.


\subsubsection*{Quantitative proof}

In order to describe the solid, we should solve the Schrödinger equation:
\begin{align*}
\hat{H}\psi & =E\psi
\end{align*}
Here $\psi=\psi\left(\left(\vec{r}_{j}\right),\left(\vec{R}_{\alpha}\right)\right)=:\psi\left(\vec{r},\vec{R}\right)$
depends on the positions of the electrons and the ions.
\begin{enumerate}[label=\roman*)]
\item Let us consider the Schrödinger equation for the electrons moving
in the electrostatic potential described by the \emph{instantaneous}
configuration $\left\{ \vec{R}_{\alpha}\right\} $ of the ions.
\begin{align}
\underbrace{\left(\hat{T}_{\text{el}}+\hat{V}_{\text{ee}}+\hat{V}_{\text{ii}}+\hat{V}_{\text{ei}}\right)}_{=\hat{H}_{\text{el}}}\phi_{k} & =\varepsilon_{\text{el},k}\left(\vec{R}\right)\phi_{k}\left(\vec{r},\vec{R}\right)
\end{align}
$\varepsilon_{\text{el},k}\left(\vec{R}\right)$ is called \emph{potential
energy surface}. The $\left(\vec{R}_{\alpha}\right)$ are only parameters
of $\phi_{k}$.
\item For a given configuration $\left(\vec{R}_{\alpha}\right)$, the wave
functions $\phi_{k}$ form a complete set and can be used to expand
the total wave function:
\begin{align}
\psi\left(\vec{r},\vec{R}\right) & =\sum_{k}\phi_{k}\left(\vec{r},\vec{R}\right)\chi_{k}\left(\vec{R}\right)
\end{align}
\begin{align}
\Rightarrow\qquad\hat{H}\psi & =\sum_{k}\left(\hat{H}_{\text{el}}+\hat{T}_{\text{ion}}\right)\phi_{k}\chi_{k}=E\sum_{k}\phi_{k}\chi_{k}
\end{align}
Here we have:
\begin{align*}
\hat{T}_{\text{ion}} & =\sum_{\alpha=1}^{M}\sum_{l\in\left\{ x,y,z\right\} }\frac{\hat{p}_{\alpha,l}^{2}}{2M_{\alpha}} & \hat{p}_{\alpha,l} & =-\ii\hbar\frac{\partial}{\partial R_{\alpha,l}}
\end{align*}

\item Now use the completeness of $\left(\phi_{k}\right)$ to eliminate
the electron coordinates by multiplying with $\phi_{s}^{*}$ and integrating
over $\left(\vec{r}_{j}\right)$. We use the product formula
\begin{align*}
\frac{\partial^{2}}{\partial\vec{R}_{\alpha}^{2}}\left(\phi_{k}\left(\vec{r},\vec{R}\right)\chi_{k}\left(\vec{R}\right)\right) & =\phi_{k}\frac{\partial^{2}\chi_{k}}{\partial\vec{R}_{\alpha}^{2}}+2\frac{\partial\phi_{k}}{\partial\vec{R}_{\alpha}}\cdot\frac{\partial\chi_{k}}{\partial\vec{R}_{\alpha}}+\chi_{k}\frac{\partial^{2}\phi_{k}}{\partial\vec{R}_{\alpha}^{2}}
\end{align*}
to get:
\begin{align*}
E\sum_{k}\underbrace{\int\dd^{3N}r\cdot\phi_{s}^{*}\phi_{k}}_{=\delta_{s,k}}\chi_{k} & =\sum_{k}\underbrace{\int\dd^{3N}r\cdot\phi_{s}^{*}\phi_{k}}_{=\delta_{s,k}}\left(\varepsilon_{k}+\hat{T}_{\text{ion}}\right)\chi_{k}+\\
 & \quad+\sum_{k}\sum_{\alpha=1}^{M}\sum_{l}\int\dd^{3N}r\cdot\left(\left(\frac{\hat{p}_{\alpha,l}^{2}}{2M_{\alpha}}\phi_{k}\right)\chi_{k}+2\frac{\left(\hat{p}_{\alpha,l}\phi_{k}\right)\left(\hat{p}_{\alpha,l}\chi_{k}\right)}{2M_{\alpha}}\right)
\end{align*}
This gives:
\begin{align}
\left(\hat{T}_{\text{ion}}+\varepsilon_{s}\left(\vec{R}\right)\right)\chi_{s}+\sum_{k}\hat{A}_{sk}\left(\vec{R}\right)\chi_{k} & =E\chi_{s}
\end{align}
Here the operator $\hat{A}_{sk}$ is:
\begin{align*}
\hat{A}_{sk}\left(\vec{R}\right) & =\sum_{\alpha=1}^{M}\sum_{l\in\left\{ x,y,z\right\} }\frac{\hbar^{2}}{2M_{\alpha}}\int\dd^{3N}r\cdot\phi_{s}^{*}\left(\left(\frac{\partial^{2}}{\partial R_{\alpha l}^{2}}\phi_{k}\right)+2\left(\frac{\partial}{\partial R_{\alpha l}}\phi_{k}\right)\frac{\partial}{\partial R_{\alpha l}}\right)=\\
 & =:\hat{A}_{sk,1}+\hat{A}_{sk,2}
\end{align*}
Neglecting the contribution from $\hat{A}_{sk}$, i.e. transitions
between different quantum numbers $s$ and $k$ due to the motion
of the ions, one gets:
\begin{align}
\left(\hat{T}_{\text{ion}}+\varepsilon_{s}\left(\vec{R}\right)\right)\chi_{s}\left(\vec{R}\right) & =E\chi_{s}\left(\vec{R}\right)
\end{align}
This is a Schrödinger equation for the ions in the effective potential
$\varepsilon_{s}$.
\end{enumerate}
\emph{Note:} All effects of the chemical binding among the ions are
captured in $\varepsilon_{s}\left(\vec{R}\right)$. The equilibrium
configuration of the lattice corresponds to minima of $\varepsilon_{s}\left(\vec{R}\right)$
at positions $\left(\vec{R}_{0,\alpha}\right)$, i.e. the crystalline
structure.

\emph{Note:} Neglecting $\hat{A}_{sk}$ amounts to the Born-Oppenheimer
approximation. (see \noun{Czycholl})
\begin{align}
\hat{A}_{sk,1} & \approx\frac{m}{M_{\alpha}}\BraKet{\phi_{s}|\hat{T}_{\text{ee}}|\phi_{k}}\\
\hat{A}_{sk,2} & \approx\frac{\hbar}{M_{\alpha}}\left\langle \hat{p}_{\text{el}}\right\rangle \left\langle \hat{p}_{\text{ion}}\right\rangle \approx\left(\frac{m}{M_{\alpha}}\right)^{\frac{3}{4}}E_{\text{el}}
\end{align}
\emph{Note:} Corrections due to $\hat{A}_{sk}$ can be treated in
perturbation theory.

%DATE: Di 11.12.12

Summary:\stepcounter{equation}
\begin{align}
\left(\hat{T}_{\text{el}}+\hat{V}_{\text{el}}+\hat{V}_{\text{ei}}+\hat{V}_{\text{ii}}\right)\phi_{k}\left(\vec{R},\vec{r}\right) & =\varepsilon_{\text{el},k}\left(\vec{R}\right)\phi_{k}\left(\vec{R},\vec{r}\right) &  & \text{electrons}\tag{\arabic{chapter}.\arabic{equation}a}\label{eq:electron-equation}\\
\left(\hat{T}_{\text{ion}}\varepsilon_{\text{el},k}\left(\vec{R}\right)\right)\chi_{k}\left(\vec{R}\right) & \approx E\chi_{k}\left(\vec{R}\right) &  & \text{ions}\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}



\section{Universality}

Focus \emph{not} on the full energy profile of the system, but on
its energetically low lying dynamics, for example on the Debye theory
for the specific heat of solids.

This is because in the low temperature regime systems tend to behave
\emph{universally}, i.e. systems differing in microscopic details
(e.g. different ion species) exhibit identical \emph{collective behavior},
e.g. phonons are collective vibration modes of a solid.

As a consequence one can employ simple \emph{model Hamiltonians} without
looking at the details of microscopic interaction potentials.


\section{Symmetries and symmetry breaking}
\begin{itemize}
\item We know that to symmetries conservation laws are associated. This
can help in finding proper eigenfunctions of the underlying problem.
\item Interactions can yield a symmetry breaking, i.e. a transition to a
new state of matter, where some of the conservation laws present in
the initial Hamiltonian are violated for the system's \emph{ground}
state.\\
However, information about symmetries of the original Hamiltonian
are contained in the low energy collective excitations, called \emph{Goldstone
modes}.
\end{itemize}

\subsubsection*{Examples}
\begin{itemize}
\item A crystal has broken translational symmetry and the collective excitations
are phonons.
\item A magnet has broken spin rotational symmetries, which leads to magnons
as collective excitations.
\end{itemize}

\chapter{Independent electrons in periodic potentials}

In this chapter we shall focus on the electronic problem \eqref{eq:electron-equation}
for the special case in which $\hat{V}_{\text{ee}}=0$. Moreover we
assume the ions to sit in their equilibrium position $\vec{R}_{0,\alpha}$
attained at zero temperature and neglect any further effect of $\hat{V}_{\text{ii}}$.
We then solve the problem only described by:
\begin{align}
\hat{H} & =\hat{T}_{\text{el}}+\hat{V}_{\text{ei}}=\sum_{i=1}^{N}\frac{\hat{p}_{i}^{2}}{2m}-\sum_{i=1}^{N}\sum_{\alpha}\frac{Z_{\alpha}e^{2}}{\abs{\vec{r}_{i}-\vec{R}_{0,\alpha}}}=\nonumber \\
 & =\sum_{i=1}^{N}\underbrace{\left(\frac{\hat{p}_{i}^{2}}{2m}+v\left(\vec{r}_{i}\right)\right)}_{=:\hat{h}_{i}}
\end{align}
Here we define:
\begin{align}
v\left(\vec{r}_{i}\right) & :=-\sum_{\alpha}\frac{Z_{\alpha}e^{2}}{\abs{\vec{r}_{i}-\vec{R}_{0,\alpha}}}
\end{align}



\section{Crystal structure}


\subsubsection*{Definitions}
\begin{enumerate}
\item \emph{Point lattice}: An (infinite) \emph{periodic} lattice is characterized
by a point lattice, i.e. the set of \emph{lattice vectors}
\begin{align*}
\vec{R}_{\vec{n}} & =n_{1}\vec{a}_{1}+n_{2}\vec{a}_{2}+n_{3}\vec{a}_{3}
\end{align*}
with $\vec{n}\in\mathbb{Z}^{3}$ and independent vectors $\vec{a}_{1}$,
$\vec{a}_{2}$ and $\vec{a}_{3}$, known as \emph{primitive lattice
vectors}.\\
\textcolor{green}{TODO: Abb; Example: two-dimensional lattice; $\vec{R}=2\vec{a}_{1}+3\vec{a}_{2}$}\\
Clearly, a lattice structure is mapped onto itself under a translation
of a lattice vector.
\item \emph{Crystal structure} (cf. \noun{Ashcroft} and \noun{Mermin}, chapter
4): It is obtained by assigning an atom or group of atoms to each
lattice point.

\begin{itemize}
\item If an atom is assigned to each lattice point, a \emph{monoatomic Bravais
lattice} is obtained.\\
\emph{Examples}:

\begin{itemize}
\item simple cubic lattice spanned by:
\begin{align*}
\left(\begin{array}{c}
a\\
0\\
0
\end{array}\right),\ \left(\begin{array}{c}
0\\
a\\
0
\end{array}\right),\ \left(\begin{array}{c}
0\\
0\\
a
\end{array}\right)
\end{align*}

\item bcc lattice spanned by:
\begin{align*}
\frac{a}{2}\left(\begin{array}{c}
-1\\
1\\
1
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
-1\\
1
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
1\\
-1
\end{array}\right)
\end{align*}

\item fcc lattice spanned by:
\begin{align*}
\frac{a}{2}\left(\begin{array}{c}
0\\
1\\
1
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
0\\
1
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
1\\
0
\end{array}\right)
\end{align*}

\end{itemize}
\item If a group of atoms is assigned, one speaks of a \emph{lattice with
a basis}. The position of the atoms is then specified by $\vec{R}+\vec{\tau}$
where $\vec{\tau}$ is the position of an atom of the basis relative
to the lattice point.\\
\emph{Examples}:

\begin{itemize}
\item A bcc lattice can be seen as a simple cubic lattice with a two point
basis:
\begin{align*}
\left(\begin{array}{c}
0\\
0\\
0
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
0\\
1
\end{array}\right)
\end{align*}

\item A fcc lattice can be seen as a simple cubic lattice with a four point
basis:
\begin{align*}
\left(\begin{array}{c}
0\\
0\\
0
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
1\\
0
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
0\\
1\\
1
\end{array}\right),\ \frac{a}{2}\left(\begin{array}{c}
1\\
0\\
1
\end{array}\right)
\end{align*}

\end{itemize}
\end{itemize}
\item \emph{Unit and primitive cells}:

\begin{enumerate}[label=\alph*)]
\item A volume of space that, when translated by \emph{all} lattice vectors
just fills all space without overlapping itself or leaving voids,
is called \emph{primitive (unit) cell}.\\
A primitive cell must contain precisely one lattice point.
\item A \emph{unit cell} is a region of space that just fills space without
any overlapping when translated through some \emph{subset} of lattice
vectors. It is usually chosen to be larger than the primitive cell,
but with the symmetry of the lattice.\\
\emph{Example}: The primitive cell of the fcc lattice has $\frac{1}{4}$
of the volume of the cubic unit cell.
\item The Wigner-Seitz cell is the region of space closer to a given lattice
point than any other.
\end{enumerate}

\textcolor{green}{TODO: Abb: primitive unit cells (incl. Wigner-Seitz);
Non-primitive unit cells}

\item \emph{Reciprocal space}: Working with periodic structures, it is often
convenient to Fourier transform from the direct space to the $k$-space,
also known as the reciprocal space. The reciprocal lattice RL in reciprocal
space RS is defined by:
\begin{align*}
\text{RL} & =\left\{ \vec{G}\in\text{RS}\big|e^{\ii\vec{G}\cdot\vec{R}}=1\right\} \\
\Rightarrow\qquad\vec{G} & =m_{1}\vec{b}_{1}+m_{2}\vec{b}_{2}+m_{3}\vec{b}_{3}
\end{align*}
The $\vec{b}_{1}$, $\vec{b}_{2}$ and $\vec{b}_{3}$ are the basis
vectors defined (in three dimensions) by:
\begin{align*}
\vec{b}_{1} & =2\pi\frac{\vec{a}_{2}\times\vec{a}_{3}}{\vec{a}_{1}\cdot\left(\vec{a}_{2}\times\vec{a}_{3}\right)} & \vec{b}_{2} & =2\pi\frac{\vec{a}_{3}\times\vec{a}_{1}}{\vec{a}_{1}\cdot\left(\vec{a}_{2}\times\vec{a}_{3}\right)} & \vec{b}_{3} & =2\pi\frac{\vec{a}_{1}\times\vec{a}_{2}}{\vec{a}_{1}\cdot\left(\vec{a}_{2}\times\vec{a}_{3}\right)}
\end{align*}
\textcolor{green}{TODO: Abb: reciprocal lattice}
\item \emph{First Brillouin zone}: The first Brillouin zone (1.BZ), or Wigner-Seitz
primitive cell, is defined as all $\vec{k}$ in reciprocal space lying
closer to $\vec{G}=0$ than to any other lattice vector $\vec{G}\not=0$.
\begin{align*}
\text{1.BZ} & =\left\{ \vec{k}\in\text{RS}\big|\norm{\vec{k}}<\norm{\vec{k}+\vec{G}}\quad\fall_{\vec{G}\in\text{RL}\setminus\left\{ 0\right\} }\right\} 
\end{align*}
This means, that for all $\vec{q}\in\text{RS}$ exists a $\vec{k}\in\text{1.BZ}$
and a $\vec{G}\in\text{RL}$ such that holds:
\begin{align*}
\vec{q} & =\vec{k}+\vec{G}
\end{align*}

\item \emph{Fourier transform}: The Fourier transform of any in the lattice
periodic function
\begin{align*}
\vec{V}\left(\vec{r}\right) & =V\left(\vec{r}+\vec{R}_{\alpha}\right)
\end{align*}
is $\tilde{V}\left(\vec{G}\right)$:
\begin{align*}
V\left(\vec{r}\right) & =\sum_{\vec{G}\in\text{RL}}\tilde{V}\left(\vec{G}\right)e^{\ii\vec{G}\cdot\vec{r}}
\end{align*}

\end{enumerate}
See also the integrated course IIa and the \noun{Ashcroft} and \noun{Mermin.}


\section{Bloch theorem}

We investigate the single particle problem described by:
\begin{align}
\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+v\left(\text{\ensuremath{\vec{r}}}\right)\right)\psi\left(\vec{r}\right) & =\varepsilon\psi\left(\vec{r}\right)
\end{align}
For all lattice vectors $\vec{R}$ holds:
\begin{align*}
v\left(\vec{r}+\vec{R}\right) & =v\left(\vec{r}\right)
\end{align*}



\subsubsection*{Translation operator}

Let us introduce the translation operator $\hat{T}_{\vec{R}}$, defined
for all $\phi\in H$ by:
\begin{align}
\hat{T}_{\vec{R}}\phi\left(\vec{r}\right) & =\phi\left(\vec{r}+\vec{R}\right)
\end{align}

\begin{itemize}
\item Any $\hat{T}_{\vec{R}}$ with a lattice vector $\vec{R}$ commutes
with $\hat{h}$:
\begin{align*}
\hat{T}_{\vec{R}}\hat{h}\phi\left(\vec{r}\right) & =\hat{T}_{\vec{R}}\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+v\left(\vec{r}\right)\right)\phi\left(\vec{r}\right)=\\
 & =\left(-\frac{\hat{p}^{2}}{2m}+v\left(\text{\ensuremath{\vec{r}}}+\vec{R}\right)\right)\phi\left(\vec{r}+\vec{R}\right)=\hat{h}\hat{T}_{\vec{R}}\phi\left(\vec{R}\right)
\end{align*}

\item The translation operators commute with each other:
\begin{align}
\hat{T}_{\vec{R}}\hat{T}_{\vec{R}'} & =\hat{T}_{\vec{R}'}\hat{T}_{\vec{R}}=\hat{T}_{\vec{R}+\vec{R}'}\label{eq:TrTr'}\\
\Rightarrow\qquad\left[\hat{T}_{\vec{R}},\hat{T}_{\vec{R}'}\right] & =0\nonumber 
\end{align}

\item We thus can look for simultaneous eigenfunctions of $\hat{T}_{\vec{R}}$
and $\hat{h}$.
\begin{align*}
\hat{h}\psi\left(\vec{r}\right) & =\varepsilon\psi\left(\vec{r}\right)\\
\hat{T}_{\vec{R}}\psi\left(\vec{r}\right) & =C\left(\vec{R}\right)\psi\left(\vec{r}\right)
\end{align*}
From \eqref{eq:TrTr'} follows:
\begin{align*}
C\left(\vec{R}\right)C\left(\vec{R}'\right) & =C\left(\vec{R}+\vec{R}'\right)
\end{align*}

\item The normalization condition
\begin{align*}
1 & =\int\dd^{3}r\abs{\psi\left(\vec{r}\right)}^{2}\sr ={\text{variable}}{\text{transformation}}\int\dd^{3}r\abs{\psi\left(\vec{r}+\vec{R}\right)}^{2}=\int\dd^{3}r\abs{C\left(\vec{R}\right)}^{2}\abs{\psi\left(\vec{r}\right)}^{2}
\end{align*}
gives:
\begin{align*}
\abs{C\left(\vec{R}\right)}^{2} & =1\\
\Rightarrow\qquad C\left(\vec{R}\right) & =e^{\ii\vec{k}\cdot\vec{R}}
\end{align*}

\end{itemize}

\subsubsection*{First form of the Bloch theorem}

The form of the eigenfunctions $\psi$ of $\hat{T}_{\vec{R}}$ is
such that:
\begin{align}
\fbox{\ensuremath{{\displaystyle \psi\left(\vec{r}+\vec{R}\right)=e^{\ii\vec{k}\cdot\vec{R}}\psi\left(\vec{r}\right)}}}
\end{align}
\emph{Bloch functions} are functions of this form, which are also
eigenfunctions of $\hat{h}$. 


\subsubsection*{Periodic boundary conditions}

Now we write $\vec{R}=N_{i}\vec{a}_{i}$ to get:
\begin{align*}
\psi\left(\vec{r}+N_{i}\vec{a}_{i}\right) & =\psi\left(\vec{r}\right)
\end{align*}
$N_{i}$ is chosen such that $L_{i}=N_{i}\norm{\vec{a}_{i}}$ is the
length of the system in the $i$-direction. The periodic boundary
condition yields:
\begin{align}
e^{\ii\vec{k}\cdot N_{i}\vec{a}_{i}} & =1
\end{align}
With $\vec{b}_{i}\cdot\vec{a}_{j}=2\pi\delta_{ij}$ follows for $n_{i}\in\mathbb{Z}$:
\begin{align}
\vec{k} & =\sum_{i}\frac{n_{i}}{N_{i}}\vec{b}_{i}
\end{align}
The $k$-space per allowed value of $\vec{k}$ is:
\begin{align*}
V_{\vec{k}} & =\frac{\vec{b}_{1}}{N_{1}}\cdot\left(\frac{\vec{b}_{2}}{N_{2}}\times\frac{\vec{b}_{3}}{N_{3}}\right)=\frac{V_{\text{pc}}}{N_{1}N_{2}N_{3}}=\frac{V_{\text{pc}}}{N_{\text{cell}}}
\end{align*}
$N_{\text{cell}}$ is the number of allowed values of $k$ per primitive
cell with volume $V_{\text{pc}}$. Moreover holds:
\begin{align*}
\vec{b}_{1} & =2\pi\frac{\vec{a}_{2}\times\vec{a}_{3}}{\vec{a}_{1}\cdot\left(\vec{a}_{2}\times\vec{a}_{3}\right)} & \vec{b}_{2} & =2\pi\frac{\vec{a}_{3}\times\vec{a}_{1}}{\vec{a}_{1}\cdot\left(\vec{a}_{2}\times\vec{a}_{3}\right)} & \vec{b}_{3} & =2\pi\frac{\vec{a}_{1}\times\vec{a}_{2}}{\vec{a}_{1}\cdot\left(\vec{a}_{2}\times\vec{a}_{3}\right)}
\end{align*}
\begin{align*}
\Rightarrow\quad V_{\text{pc}} & =\frac{\left(2\pi\right)^{3}}{v}=\frac{\left(2\pi\right)^{3}}{V}N_{\text{cell}}\\
\Rightarrow\quad V_{\vec{k}} & =\frac{\left(2\pi\right)^{3}}{V}
\end{align*}



\subsubsection*{Second form of the Bloch theorem}

Define for a Bloch function $\psi_{\vec{k}}\left(\vec{r}\right)$
the \emph{Bloch factor}:\stepcounter{equation}
\begin{align}
u_{\vec{k}}\left(\vec{r}\right) & =ae^{-\ii\vec{k}\cdot\vec{r}}\psi_{\vec{k}}\left(\vec{r}\right)\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}
With the first form of the Bloch theorem follows:
\begin{align*}
u_{\vec{k}}\left(\vec{r}+\vec{R}\right) & =\vec{u}_{\vec{k}}\left(\vec{r}\right)\tag{\arabic{chapter}.\arabic{equation}b}
\end{align*}
The \emph{normalized Bloch function} is:
\begin{align}
\fbox{\ensuremath{{\displaystyle \psi_{\vec{k}}\left(\vec{r}\right)=\frac{1}{\sqrt{V}}e^{\ii\vec{k}\cdot\vec{r}}u_{\vec{k}}\left(\vec{r}\right)}}}
\end{align}
Hence, as the plane waves, Bloch waves are delocalized.

The differential equation for $u_{\vec{k}}\left(\vec{r}\right)$ follows
from the Schrödinger equation for $\psi$:
\begin{align*}
\hat{h}\sqrt{V}\psi_{\vec{k}}\left(\vec{r}\right) & =\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+v\left(\vec{r}\right)\right)e^{\ii\vec{k}\vec{r}}u_{\vec{k}}\left(\vec{r}\right)=\varepsilon e^{\ii\vec{k}\cdot\vec{r}}u_{\vec{k}}\left(\vec{r}\right)
\end{align*}
This gives:
\begin{align}
\left(\frac{\hbar^{2}}{2m}\left(\frac{\nabla}{\ii}+\vec{k}\right)^{2}+v\left(\vec{r}\right)\right)u_{\vec{k}}\left(\vec{r}\right) & =\varepsilon\left(\vec{k}\right)u_{\vec{k}}\left(\vec{r}\right)\label{eq:differential-equation-uk}
\end{align}
In equation \eqref{eq:differential-equation-uk} the wave vector $\vec{k}$
is only a parameter. Because of the periodicity of $u_{\vec{k}}\left(\vec{r}\right)$
this problem is equivalent to a boundary problem at the boundary of
the unit cell. Therefore, at fixed $\vec{k}$ one expects discrete
eigenvalues $\varepsilon_{n}\left(\vec{k}\right)$ associated to eigenfunctions
$u_{n,\vec{k}}\left(\vec{r}\right)$.\\
So as a function of $\vec{k}$ one obtains the $n$-th band $\varepsilon_{n}\left(\vec{k}\right)$.\\
In general, in Dirac notation, the Schrödinger equation reads:
\begin{align}
\hat{h}\KET{n,\vec{k}} & =\varepsilon_{n}\left(\vec{k}\right)\KET{n,\vec{k}}
\end{align}
\emph{Note}: The eigenfunctions $u_{n,\vec{k}}$ can be normalized
on the unit cell:
\begin{align}
\frac{1}{V_{\text{cell}}}\int_{V_{\text{cell}}}\dd^{3}ru_{n,\vec{k}}^{*}\left(\vec{r}\right)u_{n',\vec{k}}\left(\vec{r}\right) & =\delta_{nn'}
\end{align}
Then the Bloch functions are also normalized over the full space,
i.e. we get:
\begin{align}
\int_{V}\dd^{3}r\psi_{n,\vec{k}}^{*}\left(\vec{r}\right)\psi_{n',\vec{k}'}\left(\vec{r}\right) & =\delta_{\vec{k},\vec{k}'}\delta_{nn'}
\end{align}
The completeness relation is:
\begin{align}
\sum_{n}u_{n,k}^{*}\left(\vec{r}\right)u_{n,\vec{k}}\left(\vec{r}'\right) & =V_{\text{cell}}\delta\left(\vec{r}-\vec{r}'\right)
\end{align}
%DATE: Fr 14.12.12


\subsubsection*{Wannier functions}

One can build a complete set of orthonormal functions, which, in contrast
to the Bloch waves, are localized. These states, known as \emph{Wannier
states}, are defined as:
\begin{align}
w_{\alpha,n}\left(\vec{r}-\vec{R}_{\alpha}\right) & :=\frac{1}{\sqrt{N_{\text{cell}}}}\sum_{\vec{k}\in\text{1.BZ}}e^{-\ii\vec{k}\cdot\vec{R}_{\alpha}}\psi_{n,\vec{k}}\left(\vec{r}\right)
\end{align}
It holds:
\begin{align}
 & \int\dd^{3}rw_{\alpha,n}^{*}\left(\vec{r}-\vec{R}_{\alpha}\right)w_{\beta,l}\left(\vec{r}-\vec{R}_{\beta}\right)\nonumber \\
 & \qquad\qquad\qquad=\frac{1}{N_{\text{cell}}}\sum_{\vec{k},\vec{k}'\in\text{1.BZ}}e^{\ii\left(\vec{k}\cdot\vec{R}_{\alpha}-\vec{k}'\cdot\vec{R}_{\beta}\right)}\underbrace{\int\dd^{3}r\psi_{n,\vec{k}}^{*}\left(\vec{r}\right)\psi_{l,\vec{k}'}\left(\vec{r}\right)}_{=\delta_{nl}\delta_{\vec{k},\vec{k}'}}=\nonumber \\
 & \qquad\qquad\qquad=\frac{1}{N_{\text{cell}}}\sum_{\vec{k}\in\text{BZ}}e^{\ii\vec{k}\cdot\left(\vec{R}_{\alpha}-\vec{R}_{\beta}\right)}\delta_{n,l}=\delta_{\alpha,\beta}\delta_{n,l}
\end{align}
Vice versa one can express Bloch functions in terms of Wannier functions:
\begin{align}
\fbox{\ensuremath{{\displaystyle \psi_{n,\vec{k}}\left(\vec{r}\right)=\frac{1}{\sqrt{N_{\text{cell}}}}\sum_{\alpha}e^{\ii\vec{k}\cdot\vec{R}_{\alpha}}w_{\alpha,n}\left(\vec{r}-\vec{R}_{\alpha}\right)}}}
\end{align}



\subsubsection*{Energy dispersion}

\begin{align*}
\varepsilon_{n,\vec{k}} & =\BraKet{n,\vec{k}|\hat{h}|n,\vec{k}}=\int\dd^{3}r\psi_{n,\vec{k}}^{*}\left(\vec{r}\right)h\left(\vec{r}\right)\psi_{n,\vec{k}}\left(\vec{r}\right)
\end{align*}
This means:
\begin{align*}
\varepsilon_{n,\vec{k}} & =\frac{1}{N_{\text{cell}}}\sum_{\alpha,\beta}e^{-\ii\vec{k}\cdot\vec{R}_{\alpha}}\cdot e^{\ii\vec{k}\cdot\vec{R}_{\beta}}\int\dd^{3}rw_{n}^{*}\left(\vec{r}-\vec{R}_{\alpha}\right)\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)\right)w\left(\vec{r}-\vec{R}_{\beta}\right)=\\
 & \sr ={\vec{r}-\vec{R}_{\beta}=:\vec{r}'}{\vec{r}'\leadsto\vec{r}}\frac{1}{N_{\text{cell}}}\sum_{\alpha,\beta}e^{-\ii\vec{k}\cdot\left(\vec{R}_{\alpha}-\vec{R}_{\beta}\right)}\int\dd^{3}rw_{n}^{*}\left(\vec{r}-\vec{R}_{\alpha}+\vec{R}_{\beta}\right)\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)\right)w_{n}\left(\vec{r}\right)=\\
 & \sr ={\vec{R}_{\gamma}:=\vec{R}_{\alpha}-\vec{R}_{\beta}}{}\frac{1}{N_{\text{cell}}}\sum_{\alpha,\gamma}e^{-\ii\vec{k}\cdot\vec{R}_{\gamma}}\int\dd^{3}rw_{n}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)\right)w_{n}\left(\vec{r}\right)=\\
 & \sr ={\sum_{\alpha}=N_{\text{cell}}}{}\sum_{\gamma}e^{-\ii\vec{k}\cdot\vec{R}_{\gamma}}\int\dd^{3}rw_{n}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)\right)w_{n}\left(\vec{r}\right)=\\
 & =\underbrace{\int\dd^{3}rw_{n}^{*}\left(\vec{r}\right)\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)\right)w_{n}\left(\vec{r}\right)}_{=:E_{n}}+\\
 & \qquad+\sum_{\gamma;\vec{R}_{\gamma}\not=0}e^{-\ii\vec{k}\cdot\vec{R}_{\gamma}}\underbrace{\int\dd^{3}rw_{n}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)\right)w_{n}\left(\vec{r}\right)}_{=:\gamma_{nn}\left(\vec{R}_{\gamma}\right)=\gamma_{nn}\left(-\vec{R}_{\gamma}\right)}
\end{align*}
$\gamma_{nn}\left(\vec{R}\right)$ is called the hopping matrix. One
can show that the kinetic part $\frac{\hat{p}^{2}}{2m}$ does not
contribute to $\gamma_{nn}$ and due to $v<0$ we get $\gamma_{nn}<0$.
So we found:
\begin{align}
\fbox{\ensuremath{{\displaystyle \varepsilon_{n,\vec{k}}=E_{n}+\sum_{\alpha;\vec{R}_{\alpha}\not=0}e^{-\ii\vec{k}\cdot\vec{R}_{\alpha}}\gamma_{nn}\left(\vec{R}_{\alpha}\right)}}}
\end{align}
This is still exact.


\subsubsection*{Approximation}
\begin{itemize}
\item Restrict the sum to nearest neighbors only.
\item In the calculation of $\gamma_{nn}\left(\vec{R}_{\alpha}\right)$
neglect ``three center'' integrals:
\begin{align*}
v\left(\vec{r}\right) & =\sum_{\beta}v_{\text{atom}}\left(\vec{r}-\vec{R}_{\beta}\right)\approx v_{\text{atom}}\left(\vec{r}\right)+v_{\text{atom}}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align*}

\item \emph{Example}: one-dimensional chain\textcolor{green}{}\\
\textcolor{green}{TODO: Abb22}
\begin{align*}
\varepsilon\left(k\right) & =E+e^{-\ii ka}\gamma\left(a\right)+e^{\ii ka}\gamma\left(-a\right)=E+2\gamma\left(a\right)\cos\left(ka\right)
\end{align*}
With ${\displaystyle -\frac{N_{\text{cell}}}{2}\le m<\frac{N_{\text{cell}}}{2}}$
we have:
\begin{align*}
k_{m} & =\frac{2\pi}{a}\cdot\frac{m}{N_{\text{cell}}}
\end{align*}
\textcolor{green}{TODO: Abb23}\\
The dispersion is parabolic near $k=0$.
\item \emph{Example}: simple cubic lattice\textcolor{green}{}\\
\textcolor{green}{TODO: Abb24}\\
There are 6 nearest neighbors and define $\gamma:=\gamma\left(a\right)$
to get:
\begin{align*}
\varepsilon\left(k\right) & =E+2\gamma\left(\cos\left(k_{x}a\right)+\cos\left(k_{y}a\right)+\cos\left(k_{z}a\right)\right)
\end{align*}
Again the dispersion is parabolic around $\vec{k}=0$.
\item \emph{Note:} Hamilton operator in Wannier basis
\begin{align*}
\hat{h} & =\sum_{\alpha,\alpha',n,n'}C_{\alpha,\beta,n,n'}\KET{n,\alpha}\BRA{n',\alpha'}
\end{align*}
Here we use:
\begin{align*}
C_{\alpha,\alpha',n,n'} & =\BraKet{n,\alpha|\hat{h}|n',\alpha'}=\begin{cases}
E_{n} & \text{for }\alpha=\alpha'\text{ and }n=n'\\
\gamma_{nn'}\left(\vec{R}_{\alpha}-\vec{R}_{\alpha'}\right) & \text{for }\alpha\not=\alpha'\text{ and/or }n\not=n'
\end{cases}
\end{align*}
Now neglect $n\not=n'$ and include only nearest neighbors. So for
a given band $n$ we get:
\begin{align*}
\hat{h}_{n} & =\left(\begin{array}{ccccc}
\ddots\\
 & E_{n} & \gamma_{nn}\\
 & \gamma_{nn} & E_{n} & \gamma_{nn}\\
 &  & \gamma_{nn} & E_{n}\\
 &  &  &  & \ddots
\end{array}\right)
\end{align*}
Diagonalizing this operator yields again $\varepsilon_{n,\vec{k}}$.
\end{itemize}

\subsubsection*{How to evaluate the electronic band structure?}

One can envisage, besides numerical ``ab initio'' methods, two semi-analytical
approaches:

\noindent \begin{center}
\begin{longtable}{c|cc}
method$\vphantom{\big|}$ & LCAO & almost free electron\tabularnewline
\hline 
\hline 
based on$\vphantom{\Big|}$ & localized states & plane waves\tabularnewline
\hline 
improvement$\vphantom{\Big|}$ & next nearest atoms & other waves\tabularnewline
\hline 
good for$\vphantom{\Big|}$ & covalent solids%
\footnote{insulators (C, N, P) or semiconductors (Si, Ge, As)%
}, transition metals%
\footnote{partially filled $d$-shells%
} & simple metals\tabularnewline
\end{longtable}
\par\end{center}


\section{Linear combination of atomic orbitals (LCAO) method}

\emph{Underlying idea}: View the solid as a collection of weakly interacting
atoms.

\emph{Advantage}: The eigenfunctions and eigenvalues of isolated atoms
are known.
\begin{itemize}
\item \emph{Example}: Na\\
electronic structure: $1s^{2}2s^{2}2p^{6}3s^{1}=\left[\text{Ne}\right]3s^{1}$\\
The energy diagram of Na as a function of the inter-atomic distance
is:\\
\textcolor{green}{TODO: Abb25}
\item \emph{Example}: Si\\
electronic structure: $\left[\text{Ne}\right]3s^{2}3p^{2}$\\
\textcolor{green}{TODO: Abb26}
\end{itemize}
%DATE: Di 18.12.12


\subsubsection*{LCAO construction}
\begin{itemize}
\item Step 1: Schrödinger equation

\begin{enumerate}[label=\roman*)]
\item \emph{Isolated atom}: The Schrödinger equation yields:

\begin{itemize}
\item atomic energies $\varepsilon_{\nu}$
\item atomic orbitals $\varphi_{\nu}$
\end{itemize}

\begin{align}
\hat{h}_{\text{at}}\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right) & =\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+v_{\text{at}}\left(\vec{r}-\vec{R}_{\alpha}\right)\right)\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)=\varepsilon_{\nu}\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align}


\item \emph{Electrons in the crystal}:
\begin{align}
\hat{h} & =\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}\right)=\frac{\hat{p}^{2}}{2m}+\sum_{\alpha}v_{\text{at}}\left(\vec{r}-\vec{R}_{\alpha}\right)=\hat{h}_{\text{at}}+\underbrace{\sum_{\beta\not=\alpha}v_{\text{at}}\left(\vec{r}-\vec{R}_{\beta}\right)}_{=\Delta v\left(\vec{r}\right)}
\end{align}
\emph{Note}: The potential $\Delta v$ yields the effects of the neighboring
atoms on the atomic energies and wave functions.
\end{enumerate}
\item Step 2: Construct extended wave functions satisfying the Bloch theorem
using the $\varphi_{\nu}$.
\begin{align}
\psi_{\nu,\vec{k}}\left(\vec{r}\right) & =\frac{1}{\sqrt{N_{\text{cell}}}}\sum_{\alpha}e^{\ii\vec{k}\cdot\vec{R}_{\alpha}}\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align}
The values of $\vec{k}$ are set by imposing periodic boundary conditions.
The Bloch theorem states:
\begin{align*}
\psi_{\nu,\vec{k}}\left(\vec{r}+\vec{R}_{\alpha}\right) & =e^{\ii\vec{k}\cdot\vec{R}_{\alpha}}\psi_{\nu,\vec{k}}\left(\vec{r}\right)
\end{align*}

\item Step 3: Use the functions $\psi_{\nu,\vec{k}}\left(\vec{r}\right)$
as a complete set for the expansion of the eigenfunctions of $\hat{h}$:
\begin{align}
\psi_{n,\vec{k}}\left(\vec{r}\right) & =\sum_{\nu}c_{n\nu}\psi_{\nu,\vec{k}}\left(\vec{r}\right)
\end{align}
These solve the Schrödinger equation:
\begin{align*}
\hat{h}\psi_{n,\vec{k}}\left(\vec{r}\right) & =\varepsilon_{n}\left(\vec{k}\right)\psi_{n,\vec{k}}\left(\vec{r}\right)
\end{align*}

\item Step 4: Obtain the coefficients $c_{n\nu}$.

\begin{enumerate}
\item Observe:
\begin{align*}
\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\hat{h}\psi_{n,\vec{k}}\left(\vec{r}\right) & =\frac{1}{\sqrt{N_{\text{cell}}}}\sum_{\nu}\sum_{\alpha}c_{n\nu}\left(-\frac{\hbar^{2}}{2m}\nabla^{2}+\sum_{\beta}v_{\text{at}}\left(\vec{r}-\vec{R}_{\beta}\right)\right)e^{\ii\vec{k}\vec{R}_{\alpha}}\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)=\\
 & =\frac{1}{\sqrt{N_{\text{cell}}}}\sum_{\nu}c_{n\nu}\sum_{\alpha}\left(\varepsilon_{\nu}+\sum_{\beta\not=\alpha}v_{\text{at}}\left(\vec{r}-\vec{R}_{\beta}\right)\right)e^{\ii\vec{k}\vec{R}_{\alpha}}\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align*}

\item Multiply from the left with $\psi_{\nu',\vec{k}}^{*}\left(\vec{r}\right)$
and integrate in $\dd^{3}r$:
\begin{align*}
\int\dd^{3}r\psi_{\nu',\vec{k}}^{*}\left(\vec{r}\right)\hat{h}\psi_{n,\vec{k}}\left(\vec{r}\right) & =\frac{1}{N_{\text{cell}}}\int\dd^{3}r\sum_{\nu}c_{n\nu}\sum_{\gamma}e^{-\ii\vec{k}\vec{R}_{\gamma}}\varphi_{\nu'}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)\cdot\\
 & \qquad\cdot\sum_{\alpha}\left(\varepsilon_{\nu}+\sum_{\beta\not=\alpha}v_{\text{at}}\left(\vec{r}-\vec{R}_{\beta}\right)\right)e^{\ii\vec{k}\vec{R}_{\alpha}}\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align*}

\item Use the orthonormality of the atomic wave functions at the \emph{same
site}
\begin{align*}
\int\dd^{3}r\varphi_{\nu'}^{*}\left(\vec{r}\right)\varphi_{\nu}\left(\vec{r}\right) & =\delta_{\nu\nu'}
\end{align*}
to get:
\begin{align*}
\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace0 & =\int\dd^{3}r\psi_{\nu',\vec{k}}^{*}\left(\hat{h}-\varepsilon_{n}\left(\vec{k}\right)\right)\psi_{n,\vec{k}}\left(\vec{r}\right)=\\
\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace & =\sum_{\nu}c_{n\nu}\left(\varepsilon_{\nu}-\varepsilon_{n}\left(\vec{k}\right)\right)\underbrace{\left(\delta_{\nu\nu'}+\frac{1}{N_{\text{at}}}\sum_{\alpha,\gamma\not=\alpha}e^{-\ii\vec{k}\cdot\vec{R}_{\gamma}}e^{\ii\vec{k}\vec{R}_{\alpha}}\int\dd^{3}r\varphi_{\nu'}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)\varphi_{\nu}\left(\vec{r}-\vec{R}\right)\right)}_{=S_{\nu'\nu}}+\\
\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace & \qquad+\sum_{\nu}c_{n\nu}\underbrace{\frac{1}{N_{\text{cell}}}\sum_{\gamma,\alpha}e^{-\ii\vec{k}\vec{R}_{\gamma}}e^{\ii\vec{k}\vec{R}_{\alpha}}\int\dd^{3}r\varphi_{\nu'}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)\left(\sum_{\beta\not=\alpha}v_{\text{at}}\left(\vec{r}-\vec{R}_{\beta}\right)\right)\varphi_{\nu}\left(\vec{r}-\vec{R}\right)}_{=:K_{\nu'\nu}}=\\
\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace & =\sum_{\nu}c_{n\nu}\left(\left(\varepsilon_{\nu}-\varepsilon_{n}\left(\vec{k}\right)\right)S_{\nu'\nu}+K_{\nu'\nu}\right)
\end{align*}

\end{enumerate}

So the eigenvalues $\varepsilon_{n,\vec{k}}=\varepsilon_{n}\left(\vec{k}\right)$
are obtained from the secular equation:
\begin{align}
\det\left(\varepsilon_{\nu}S_{\nu'\nu}+K_{\nu'\nu}-\varepsilon_{n}\left(\vec{k}\right)S_{\nu'\nu}\right) & =0
\end{align}
The $S_{\nu'\nu}$ and $K_{\nu'\nu}$ are the so called overlap integrals
and are defined as:
\begin{align}
S_{\nu'\nu} & :=\delta_{\nu'\nu}+\frac{1}{N_{\text{at}}}\sum_{\alpha,\beta\not=\alpha}e^{-\ii\vec{k}\vec{R}_{\beta}}e^{\ii\vec{k}\vec{R}_{\alpha}}\int\dd^{3}r\cdot\varphi_{\nu'}^{*}\left(\vec{r}-\vec{R}_{\beta}\right)\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)\\
K_{\nu'\nu} & :=\frac{1}{N_{\text{cell}}}\sum_{\gamma,\alpha,\beta\not=\alpha}e^{-\ii\vec{k}\vec{R}_{\gamma}}e^{\ii\vec{k}\vec{R}_{\alpha}}\int\dd^{3}r\varphi_{\nu'}^{*}\left(\vec{r}-\vec{R}_{\gamma}\right)v_{\text{at}}\left(\vec{r}-\vec{R}_{\beta}\right)\varphi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align}
Note that the atomic orbitals $\varphi_{\nu}$ are in general not
orthogonal on different lattice sites.

\end{itemize}

\subsubsection*{Tight binding approximation}
\begin{itemize}
\item $S_{\nu'\nu}\approx\delta_{\nu'\nu}$
\item Neglect three center integrals and retain the nearest neighbors (n.n.)
in the sum over $\alpha$ in $K_{\nu'\nu}$.
\begin{align*}
K_{\nu'\nu} & \approx\underbrace{\sum_{\alpha,\vec{R}_{\alpha}\not=0}\int\dd^{3}r\varphi_{\nu'}^{*}\left(\vec{r}\right)v_{\text{at}}\left(\vec{r}-\vec{R}_{\alpha}\right)\varphi_{\nu}\left(\vec{r}\right)}_{=:c_{\nu'\nu}\ \text{crystal field}}+\\
 & \qquad+\sum_{\alpha\,\text{n.n.}}e^{-\ii\vec{k}\vec{R}_{\alpha}}\underbrace{\int\dd^{3}r\varphi_{\nu'}^{*}\left(\vec{r}-\vec{R}_{\alpha}\right)v_{\text{at}}\left(\vec{r}-\vec{R}_{\alpha}\right)\varphi_{\nu}\left(\vec{r}\right)}_{\gamma_{\nu'\nu}\left(\vec{R}_{\alpha}\right)\ \text{overlap term}}
\end{align*}
The secular equation becomes:
\begin{align}
\det\bigg(\underbrace{\varepsilon_{\nu}\delta_{\nu\nu'}+c_{\nu\nu'}+\sum_{\alpha\,\text{n.n.}}e^{-\ii\vec{k}\cdot\vec{R}_{\alpha}}\gamma_{\nu\nu'}\left(\vec{R}_{\alpha}\right)}_{=:\mathcal{H}_{\nu\nu'}\left(\vec{k}\right)}-\varepsilon_{n}\left(\vec{k}\right)\delta_{\nu\nu'}\bigg) & =0\label{eq:secular-equation}
\end{align}

\item \emph{Note}: In some way, we are approximating Wannier functions
\begin{align*}
w_{\alpha,n}^{\text{LCAO}}\left(\vec{r}-\vec{R}_{\alpha}\right) & =\sum_{\nu}c_{n,\nu}\psi_{\nu}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align*}
with the additional assumption $S_{\nu'\nu}\approx\delta_{\nu'\nu}$.
\item \emph{Note}: The LCAO method is very convenient for problems, where
only a few atomic orbitals $\nu$ are required.
\item \emph{Example}: With one orbital $\nu$ only, the secular equation
yields (in this case $n\to\nu$):
\begin{align*}
\varepsilon\left(\vec{k}\right) & =\varepsilon_{\nu}+c_{\nu\nu}+\sum_{\alpha\,\text{n.n.}}e^{-\ii\vec{k}\cdot\vec{R}_{\alpha}}\gamma_{\nu\nu}\left(\vec{R}_{\alpha}\right)
\end{align*}
Let us e.g. consider an $s$-band on a cubic lattice (e.g. $3s$ electron
of Na on a cubic lattice).
\begin{align*}
\gamma_{ss} & =V_{ss\sigma}
\end{align*}
\textcolor{green}{TODO: Abb overlap between $s$-orbitals}
\begin{align*}
\varepsilon\left(\vec{k}\right) & =\varepsilon_{s}+c_{ss}+\sum_{\alpha\,\text{n.n.}}e^{-\ii\vec{k}\cdot\vec{R}}V_{ss\sigma}
\end{align*}
\textcolor{green}{TODO: Abb direct lattice $a$; spanned by $a\vec{e}_{x},a\vec{e}_{y},a\vec{e}_{z}$,
reciprocal lattice $\frac{2\pi}{a}$, spanned by $\frac{2\pi}{a}\vec{e}_{x},\frac{2\pi}{a}\vec{e}_{y},\frac{2\pi}{a}\vec{e}_{z}$}\\
\textcolor{green}{TODO: Abb 1. Brillouin zone with $\Gamma,M,X,R$}
\begin{align*}
\Gamma & =\left(\begin{array}{c}
0\\
0\\
0
\end{array}\right) & X & =\frac{\pi}{a}\left(\begin{array}{c}
1\\
0\\
0
\end{array}\right) & M & =\frac{\pi}{a}\left(\begin{array}{c}
1\\
1\\
0
\end{array}\right) & R & =\frac{\pi}{a}\left(\begin{array}{c}
1\\
1\\
1
\end{array}\right)
\end{align*}
In general, accounting for the symmetry of the cubic lattice and with
$V_{ss\sigma}=:\gamma$ follows:
\begin{align*}
\varepsilon\left(\vec{k}\right) & =\underbrace{\varepsilon_{s}+c_{ss}}_{=:\tilde{\varepsilon}_{s}}+2\gamma\left(\cos\left(k_{x}a\right)+\cos\left(k_{y}a\right)+\cos\left(k_{z}a\right)\right)
\end{align*}
Hence we get:
\begin{align*}
\varepsilon\left(\Gamma\right) & =\tilde{\varepsilon}_{s}+6\gamma & \varepsilon\left(X\right) & =\tilde{\varepsilon}_{s}+2\gamma & \varepsilon\left(M\right) & =\tilde{\varepsilon}_{s}-2\gamma & \varepsilon\left(R\right) & =\tilde{\varepsilon}_{s}-6\gamma
\end{align*}
\textcolor{green}{TODO: Abb Plot $\varepsilon\left(\vec{k}\right)$
path $\Gamma\to X\to M\to R$}
\item \emph{Note}: The particle dispersion around the $\Gamma$-point can
be considered as for free electrons with effective electron mass:
\begin{align*}
m^{*} & :=-\frac{\hbar^{2}}{2a^{2}\gamma}
\end{align*}

\item \emph{Example}: Consider a one-dimensional chain with two orbitals.\\
\textcolor{green}{TODO: Abb chain with $s$- and $p$-orbitals}\\
The secular approximation requires to evaluate the matrix $\mathcal{H}_{\nu'\nu}$.
In this case we have:
\begin{align*}
\mathcal{H} & =\left(\begin{array}{cc}
\tilde{\varepsilon}_{s}+V_{ss\sigma}\left(e^{-\ii ka}+e^{\ii ka}\right) & c_{sp}+V_{sp\sigma}\left(e^{-\ii ka}-e^{\ii ka}\right)\\
c_{ps}+V_{sp\sigma}^{*}\left(e^{-\ii ka}-e^{\ii ka}\right) & \tilde{\varepsilon}_{p}+V_{pp\sigma}\left(e^{-\ii ka}+e^{\ii ka}\right)
\end{array}\right)
\end{align*}
The two orbitals give two bonds. $\tilde{\varepsilon}_{p}-\tilde{\varepsilon}_{s}\gg\abs{V_{ss\sigma}},\abs{V_{sp\sigma}},\abs{V_{pp\sigma}}$\\
\textcolor{green}{TODO: Abb $s$-band, $p$-band; $V_{ss\sigma}<0$,
$V_{pp\sigma}>0$}%DATE: Fr 21.12.12
\item \emph{Example}: Consider a two-dimensional square lattice with four
orbitals.\\
\textcolor{green}{TODO: Abb27}\\
For simplicity assume $c_{\nu\nu'}=c_{\nu\nu}\delta_{\nu\nu'}$ and
set $\tilde{\varepsilon}_{\nu}=\varepsilon_{\nu}+c_{\nu\nu}$:
\begin{align*}
\negthickspace\negthickspace\negthickspace\negthickspace\negthickspace\left(\mathcal{H}_{\nu\nu'}\right) & =\begin{array}{c}
\BRA s\\
\BRA{p_{x}}\\
\BRA{p_{y}}\\
\BRA{p_{z}}
\end{array}\stackrel{\begin{array}{cccc}
\KET s\quad & \qquad\qquad\KET{p_{x}}\qquad\qquad & \qquad\qquad\KET{p_{y}}\qquad\qquad & \quad\KET{p_{z}}\end{array}}{\left(\begin{array}{cccc}
\tilde{\varepsilon}_{s}+V_{ss\sigma}g_{0} & V_{sp\sigma}g_{1} & V_{sp\sigma}g_{2}^{*} & 0\\
V_{sp\sigma}g_{1}^{*} & \tilde{\varepsilon}_{p}+V_{pp\sigma}g_{4}+V_{pp\pi}g_{3} & 0 & 0\\
V_{sp\sigma}g_{2} & 0 & \tilde{\varepsilon}_{p}+V_{pp\sigma}g_{3}+V_{pp\pi}g_{4} & 0\\
0 & 0 & 0 & \tilde{\varepsilon}_{p}+V_{pp\pi}g_{0}
\end{array}\right)}
\end{align*}
Here we used the abbreviations:
\begin{align*}
g_{0} & :=e^{-\ii k_{x}a}+e^{\ii k_{x}a}+e^{-\ii k_{y}a}+e^{\ii k_{y}a} & g_{1} & :=e^{\ii k_{x}a}-e^{\ii k_{x}a}\\
g_{2} & :=-e^{-\ii k_{y}a}+e^{\ii k_{y}a} & g_{3} & :=e^{-\ii k_{y}a}+e^{\ii k_{y}a}\\
g_{4} & :=e^{\ii k_{x}a}+e^{-\ii k_{x}a}
\end{align*}
\textcolor{green}{TODO: Abb28}\\
\emph{Main features:}

\begin{enumerate}
\item The four orbitals induce four bands.
\item There are degeneracies at the symmetry points.\\
\textcolor{green}{TODO: Abb29 (neglecting $V_{sp\sigma}$)}
\end{enumerate}
\item \emph{Orbital overlaps for three-dimensional crystals}:

\begin{enumerate}[label=\roman*)]
\item $_{1}\BraKet{s|\hat{v}_{\text{atom}}|s}_{2}=V_{ss\sigma}$\\
\textcolor{green}{TODO: Abb30}
\item $_{1}\left\langle s|\hat{v}_{\text{atom}}|p\right\rangle _{2}$\\
\textcolor{green}{TODO: Abb31, abb32}
\item $_{1}\BraKet{p|\hat{v}_{\text{atom}}|p}_{2}=\left(\hat{d}\cdot\hat{b}_{1}\right)\left(\hat{d}\cdot\hat{b}_{2}\right)V_{pp\sigma}+\left(\hat{b}_{1}-\hat{d}\left(\hat{b}_{1}\cdot\hat{d}\right)\right)\left(\hat{b}_{2}-\hat{d}\left(\hat{b}_{2}\cdot\hat{d}\right)\right)V_{pp\pi}$\\
\textcolor{green}{TODO: Abb33}
\end{enumerate}
\end{itemize}

\subsubsection*{Example}

The diamond/zincblend structure consist of two interpenetrating fcc
lattices. This can be viewed as an fcc with a two-point basis $\left\{ 0,\frac{a}{4}\left(\vec{e}_{x}+\vec{e}_{y}+\vec{e}_{z}\right)\right\} $.\\
For the diamond structure both atoms are the same, e.g. for C, Ge
or Si, but for the zincblend structure these are different as in $A_{\text{III}}B_{\text{V}}$,
e.g. for GaAs or ZnS.\\
\textcolor{green}{TODO: Abb unit cube of zincblend structure}\\
Consider now the specific example GaAs:
\begin{itemize}
\item Ga: $\left[\text{Ar}\right]3d^{10}4s^{2}4p^{1}$ has two $s$ and
one $p$ electrons.
\item As: $\left[\text{Ar}\right]3d^{10}4s^{2}4p^{3}$ has two $s$ and
three $p$ electrons.
\item Together this are eight electrons.
\item The elementary cell consists of one Ga (cation) and one As (anion)
\item Basis: $s^{c},s^{a},p_{x}^{c},p_{x}^{a},p_{y}^{c},p_{y}^{a},p_{z}^{c},p_{z}^{a}$\\
\textcolor{green}{TODO: Abb orbitals}
\item Nearest neighbors: Remember the secular equation \eqref{eq:secular-equation}.\\
\textcolor{green}{TODO: Abb nearest neighbors}
\item Overlap:
\begin{align*}
s^{c}s^{a} & \to\gamma_{ss}\\
s^{c}p_{x}^{a} & \to\gamma_{sp}\\
p_{x}^{c}p_{x}^{a} & \to\gamma_{xx}\\
p_{x}^{c}p_{y}^{a} & \to\gamma_{xy}
\end{align*}

\item Phase factors:
\begin{align*}
e^{\ii\vec{q}\vec{d}_{1}}+e^{\ii\vec{q}\vec{d}_{2}}+e^{\ii\vec{q}\vec{d}_{3}}+e^{\ii\vec{q}\vec{d}_{4}} & =g_{0} & \vec{d}_{1} & =\frac{a}{4}\left(\begin{array}{c}
1\\
1\\
1
\end{array}\right)\\
e^{\ii\vec{q}\vec{d}_{1}}+e^{\ii\vec{q}\vec{d}_{2}}-e^{\ii\vec{q}\vec{d}_{3}}-e^{\ii\vec{q}\vec{d}_{4}} & =g_{1} & \vec{d}_{2} & =\frac{a}{4}\left(\begin{array}{c}
1\\
-1\\
-1
\end{array}\right)\\
e^{\ii\vec{q}\vec{d}_{1}}-e^{\ii\vec{q}\vec{d}_{2}}+e^{\ii\vec{q}\vec{d}_{3}}-e^{\ii\vec{q}\vec{d}_{4}} & =g_{2} & \vec{d}_{3} & =\frac{a}{4}\left(\begin{array}{c}
-1\\
1\\
-1
\end{array}\right)\\
e^{\ii\vec{q}\vec{d}_{1}}-e^{\ii\vec{q}\vec{d}_{2}}-e^{\ii\vec{q}\vec{d}_{3}}+e^{\ii\vec{q}\vec{d}_{4}} & =g_{3} & \vec{d}_{4} & =\frac{a}{4}\left(\begin{array}{c}
-1\\
-1\\
1
\end{array}\right)
\end{align*}
With the shorthand notation
\begin{align*}
_{1}\BraKet{s|\hat{v}_{\text{atom}}|s}_{2} & =V_{ss\sigma}=:\gamma_{ss}\\
_{1}\BraKet{s|\hat{v}_{\text{atom}}|p}_{2} & =\frac{V_{sp\sigma}}{\sqrt{3}}=:-\gamma_{sp}\\
_{1}\BraKet{p_{y}|\hat{v}_{\text{atom}}|p_{y}}_{2} & =\frac{V_{pp\sigma}}{3}+\frac{2V_{pp\pi}}{3}=:\gamma_{pp}\\
_{1}\BraKet{p_{x}|\hat{v}_{\text{atom}}|p_{y}}_{2} & =V_{pp\sigma}\cos^{2}\Theta-V_{pp\pi}\cos^{2}\Theta=\frac{V_{pp\sigma}}{3}-\frac{V_{pp\pi}}{3}=:\gamma_{xy}
\end{align*}
we get the LCAO matrix:\vspace{-7mm}
\begin{align*}
\mathcal{H} & =\begin{array}{c}
s^{c}\\
s^{a}\\
p_{x}^{c}\\
p_{x}^{a}\\
p_{y}^{c}\\
p_{y}^{a}\\
p_{z}^{c}\\
p_{z}^{a}
\end{array}\overset{\begin{array}{cccccccc}
\hphantom{\gamma_{ss}g_{0}^{*}} & \hphantom{-\gamma_{ss}g_{0}} & \hphantom{-\gamma_{sp}g_{1}^{*}} & \hphantom{-\gamma_{sp}g_{2}^{*}} & \hphantom{-\gamma_{sp}g_{3}^{*}} & \hphantom{\gamma_{sp}g_{1}} & \hphantom{\gamma_{sp}g_{2}} & \hphantom{\gamma_{sp}g_{3}}\\
s^{c} & s^{a} & p_{x}^{c} & p_{y}^{c} & p_{z}^{c} & p_{x}^{a} & p_{y}^{a} & p_{z}^{a}
\end{array}}{\left(\begin{array}{cccccccc}
\varepsilon_{s}^{c} & \gamma_{ss}g_{0} & 0 & 0 & 0 & \gamma_{sp}g_{1} & \gamma_{sp}g_{2} & \gamma_{sp}g_{3}\\
\gamma_{ss}g_{0}^{*} & \varepsilon_{s}^{a} & -\gamma_{sp}g_{1}^{*} & -\gamma_{sp}g_{2}^{*} & -\gamma_{sp}g_{3}^{*} & 0 & 0 & 0\\
0 & -\gamma_{sp}g_{1} & \varepsilon_{p}^{c} & -0 & 0 & \gamma_{xx}g_{0} & \gamma_{xy}g_{3} & \gamma_{xy}g_{2}\\
0 & -\gamma_{sp}g_{2} & 0 & \varepsilon_{p}^{c} & 0 & \gamma_{xy}g_{3} & \gamma_{xx}g_{0} & \gamma_{xy}g_{1}\\
0 & -\gamma_{sp}g_{3} & 0 & 0 & \varepsilon_{p}^{c} & \gamma_{xy}g_{2} & \gamma_{xy}g_{1} & \gamma_{xx}g_{0}\\
\gamma_{sp}g_{1}^{*} & 0 & \gamma_{xx}g_{0}^{*} & \gamma_{xy}g_{3}^{*} & \gamma_{xy}g_{2}^{*} & \varepsilon_{p}^{a} & 0 & 0\\
\gamma_{sp}g_{2}^{*} & 0 & \gamma_{xy}g_{3}^{*} & \gamma_{xx}g_{0}^{*} & \gamma_{xy}g_{1}^{*} & 0 & \varepsilon_{p}^{a} & 0\\
\gamma_{sp}g_{3}^{*} & 0 & \gamma_{xy}g_{2}^{*} & \gamma_{xy}g_{1}^{*} & \gamma_{xx}g_{0}^{*} & 0 & 0 & \varepsilon_{p}^{a}
\end{array}\right)}
\end{align*}

\item No general analytic solution is know. Only at some high symmetry points,
e.g. the $\Gamma$ point, an analytic solution can be constructed,
because some $g_{i}$ are zero.\\
At the $\Gamma$ point, we have $g_{1}=g_{2}=g_{3}=0$ and $g_{0}=4$,
thus we get:
\begin{align*}
E & =\frac{\varepsilon_{s}^{c}+\varepsilon_{s}^{a}}{2}\pm\sqrt{\left(\frac{\varepsilon_{s}^{c}-\varepsilon_{s}^{a}}{2}\right)^{2}+\left(4\gamma_{ss}\right)^{2}} &  & \text{two }s\text{ states}\\
E & =\frac{\varepsilon_{p}^{c}+\varepsilon_{p}^{a}}{2}\pm\sqrt{\left(\frac{\varepsilon_{p}^{c}-\varepsilon_{p}^{a}}{2}\right)^{2}+\left(4\gamma_{xx}\right)^{2}} &  & \text{two threefold degenerate }p\text{ states}
\end{align*}

\item For Ge ($\left[\text{Ar}\right]3d^{10}4s^{2}4p^{2}$) there are eight
orbitals, so there are eight energy bands.
\item The zincblende bands at the $\Gamma$-point are highly degenerate.\textcolor{green}{}\\
\textcolor{green}{TODO: Abb Ge-band structure}
\end{itemize}

\section{Almost free electrons}

See integrated course IIa.

The point of view complimentary to the LCAO one, is to consider the
periodic potential as a weak perturbation. In this situation it is
convenient to express the Bloch waves as linear combinations of \emph{(delocalized)
plane waves}, rather than of localized atomic orbitals.

Let us expand the wave function in the plane wave basis $\KET{\vec{k},\sigma}$.
(In the following $\chi_{\sigma}$ is the spin part, $\chi_{\uparrow}=\left(1,0\right)$
and $\chi_{\downarrow}=\left(0,1\right)$, and $\varepsilon_{\vec{k}'}^{0}$
the free energy of the free electron.)
\begin{align*}
\psi_{\sigma}\left(\vec{r}\right) & =\sum_{\vec{k}'}c_{\vec{k}'}\BraKet{\vec{r}|\vec{k}'\sigma}=\sum_{\vec{k}'}c_{\vec{k}'}\psi_{\vec{k}',\sigma}^{0}\left(\vec{r}\right)=\frac{1}{\sqrt{V}}\sum_{\vec{k}'}c_{\vec{k}'}e^{\ii\vec{k}'\cdot\vec{r}}\chi_{\sigma}
\end{align*}
\begin{align*}
\Rightarrow\qquad\BraKet{\vec{k},\sigma|\hat{h}|\psi_{\sigma}} & =\sum_{\vec{k}'}c_{\vec{k}'}\BraKet{\vec{k},\sigma|-\frac{\hbar^{2}}{2m}\nabla^{2}+v\left(\vec{r}\right)|\vec{k}'\sigma'}=\\
 & =\sum_{\vec{k}'}c_{\vec{k}'}\left(\varepsilon_{\vec{k}'}^{0}\delta_{\vec{k}\vec{k}'}+\sum_{\vec{G}\in\text{RL}}\tilde{v}\left(\vec{G}\right)\delta_{\vec{k},\vec{k}'+\vec{G}}\right)\delta_{\sigma\sigma'}
\end{align*}
Here we used the Fourier transform of the potential:
\begin{align*}
v\left(\vec{r}\right) & =\sum_{\vec{G}\in\text{RL}}\tilde{v}\left(\vec{G}\right)e^{\ii\vec{G}\cdot\vec{r}}\\
\tilde{v}\left(\vec{k}\right) & =\frac{1}{V_{\text{cell}}}\int\dd^{3}re^{-\ii\vec{G}\cdot\vec{r}}v\left(\vec{r}\right)
\end{align*}


Now we construct the eigenvalue equation:\stepcounter{equation}
\begin{align}
c_{\vec{k}}\varepsilon_{\vec{k}}^{0}+\sum_{\vec{G}\in\text{RL}}\tilde{v}\left(\vec{G}\right)c_{\vec{k}-\vec{G}} & =\varepsilon_{n}\left(\vec{k}\right)c_{\vec{k}}\tag{\arabic{chapter}.\arabic{equation}a}\\
c_{\vec{k}-\vec{G}'}\varepsilon_{\vec{k}-\vec{G}'}^{0}+\sum_{\vec{G}''=\vec{G}+\vec{G}'\in\text{RL}}\tilde{v}\left(\vec{G}-\vec{G}'\right)c_{\vec{k}-\vec{G}''} & =\varepsilon_{n}\left(\vec{k}\right)c_{\vec{k}-\vec{G}'}\nonumber \\
\sum_{\vec{G}\in\text{RL}}c_{\vec{k}-\vec{G}}\left(\left(\varepsilon_{\vec{k}-\vec{G}'}^{0}-\varepsilon_{n}\left(\vec{k}\right)\right)\delta_{\vec{G},\vec{G}'}+\tilde{v}\left(\vec{G}-\vec{G}'\right)\right) & =0\nonumber 
\end{align}
This gives the eigenvalue equation:
\begin{align}
\det\left(\left(\varepsilon_{\vec{k}-\vec{G}'}^{0}-\varepsilon_{n}\left(\vec{k}\right)\right)\delta_{\vec{G},\vec{G}'}+\tilde{v}\left(\vec{G}-\vec{G}'\right)\right) & =0\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
This is exact. However, the efficiency of this approach crucially
depends on the convergence of the plane wave expansion of on the strength
of the periodic potential. In other words, the kinetic term should
dominate over the non-diagonal potential term.

Let us consider the case in which the free electron picture is only
slightly perturbed. Consider for simplicity the one dimensional case:
\begin{enumerate}
\item Draw the free electron parabola and identify the Brillouin zones.\\
\textcolor{green}{TODO: Abb parabola with zone scheme}
\item Take into account the periodicity $\alpha$ of the dispersion relation
to obtain a reduced zone scheme.\\
\textcolor{green}{TODO: Abb parabola with reduced zone scheme}
\item The degeneracy
\begin{align*}
\tilde{\varepsilon}_{\vec{q}=\frac{\vec{G}}{2}}^{0} & =\tilde{\varepsilon}_{\vec{q}=\frac{\vec{G}}{2}-\vec{G}}^{0}
\end{align*}
at Bragg planes is removed:
\begin{align*}
\varepsilon\left(\vec{q}=\frac{\vec{G}}{2}\right) & =\varepsilon_{\frac{\vec{G}}{2}}^{0}\pm\abs{\tilde{v}\left(\vec{G}\right)}
\end{align*}
The energy gaps (energy bands) are formed.
\item At the zone boundary holds:
\begin{align*}
\frac{\partial}{\partial\vec{q}}\varepsilon\left(\vec{q}\right) & =\frac{\hbar^{2}}{2m}\left(\vec{q}-\frac{\vec{G}}{2}\right)\\
\Rightarrow\qquad v\left(\vec{q}\right) & =\frac{\partial}{\hbar\partial\vec{q}}\varepsilon\left(\vec{q}\right)\big|_{\vec{q}=\frac{\vec{G}}{2}}=0
\end{align*}
So the group velocity vanishes in this case and standing waves are
formed.
\end{enumerate}
In one dimension holds:
\begin{itemize}
\item The most it can occur is twofold degeneracy.
\item To leading order in the potential, the free electron description remains
correct except at Bragg planes.
\item Within an extended-zone scheme one finds:\\
\textcolor{green}{TODO: Abb extended zone scheme with the first two
bands}
\end{itemize}
The main outcome is:
\begin{itemize}
\item The periodic potential is treated as a perturbation.
\item Main effect: It (often) removes degeneracies at high symmetry points
(at Bragg planes).
\end{itemize}
\emph{Example in one dimension}: repeated zone scheme

\textcolor{green}{TODO: Abb34}

\begin{align*}
\frac{\partial\varepsilon}{\partial k}\bigg|_{\frac{\vec{G}}{2}} & =0
\end{align*}



\section{Ground state of Bloch electrons}

The ground state of $N_{e}$ Bloch electrons is constructed by increasingly
filling one-electron levels.
\begin{itemize}
\item For each band $\varepsilon_{n}\left(\vec{k}\right)$, including spin,
$2N_{\text{cell}}$ electrons are allowed.
\item The Bravais lattice has $n$ atoms per primitive cell, and thus we
have:
\begin{align*}
N_{\text{at}} & =nN_{\text{cell}}
\end{align*}

\item Moreover, there are $N_{e}=N_{\text{at}}Z_{e}$ valence electrons
in total, where $Z_{e}$ is the number of valence electrons per atom.
\end{itemize}
Two situations may occur:
\begin{enumerate}
\item Some bands are completely filled. All others remain empty.

\begin{itemize}
\item The energy difference between the lowest unoccupied level and the
highest occupied one is called \emph{band gap}.
\item A band gap might occur only if the number of electrons per primitive
cell is even.
\item Filled bands are inert (cf. \noun{Ashcroft}, chapter 12). So at $T=0$
these are insulators. If the band gap is rather small, one speaks
of semi conductors.
\end{itemize}
\item A number of bands is partially filled.

\begin{itemize}
\item The energy of the highest occupied level is called \emph{Fermi energy}.
It lies within the energy range of one or more bands.
\item The \emph{Fermi surface} separates filled from unfilled levels.
\begin{align*}
\varepsilon_{n}\left(\vec{k}\right) & =\varepsilon_{F}
\end{align*}
Because $\varepsilon_{n}\left(\vec{k}\right)$ has the periodicity
of the reciprocal lattice, also $\varepsilon_{F}$ is a $k$-space
surface with such periodicity.
\end{itemize}
\end{enumerate}
\emph{Note}: In insulators, the Fermi energy is by definition (as
$\varepsilon_{F}=\lim_{T\to0}\mu$) in the middle of the band gap.
\begin{itemize}
\item If $nZ_{e}$ is odd the system is a metal (some bands are partly filled).
\item If $nZ_{e}$ is even, the system is a metal or an insulator depending
on the band overlap and on interaction defects. (Example: divalent
metals)\\
\textcolor{green}{TODO: Abb even-odd rule for narrow bands and wide
bands}
\end{itemize}
For weak potentials, the Fermi surface can be evaluated starting from
the free electron sphere centered at $\vec{k}=0$, noticing that this
will be modified near the Bragg planes.
\begin{align*}
\frac{\partial}{\partial\vec{q}}\varepsilon\left(\vec{q}\right)\big|_{\vec{q}=\frac{\vec{G}}{2}} & =0
\end{align*}
So the surface of constant energy is orthogonal to a Bragg plane.

\textcolor{green}{TODO: Abb fermi sphere of free electron and modified
by Bragg plane}


\subsubsection*{Example: Square lattice}
\begin{itemize}
\item Bragg planes are the planes intersecting the lines joining the origin
and reciprocal lattice points.
\item The $n$-th Brillouin zone is the set of points that can be reached
from the first Brillouin zone by crossing $n-1$ Bragg planes, but
no fewer.
\end{itemize}
\textcolor{green}{TODO: Abb The Nearest through Fifth nearest Neighbors
for a point in a square lattice and their Bragg lines}

For example consider the first three Brillouin zones and the Fermi
surface of this lattice.

\textcolor{green}{TODO: Abb first three BZs; Blue circle: free electron
Fermi surface for some electron concentration}

The first Brillouin zone is entirely occupied, while the second, third
and fourth are only partially occupied.


\section{Alkali and noble metals}


\subsubsection*{Monovalent metals}

\noindent \begin{center}
\begin{tabular}{c|c}
Alkali metals & Noble metals\tabularnewline
(body-centered cubic)$\vphantom{\Big|}$ & (face-centered cubic)\tabularnewline
\hline 
\hline 
Li: $\left[\text{He}\right]2s^{1}$$\vphantom{\Big|}$ & \tabularnewline
\hline 
Na: $\left[\text{Ne}\right]3s^{1}$$\vphantom{\Big|}$ & \tabularnewline
\hline 
K: $\left[\text{Ar}\right]4s^{1}$$\vphantom{\Big|}$ & Cu: $\left[\text{Ar}\right]3d^{10}4s^{1}$\tabularnewline
\hline 
Rb: $\left[\text{Kr}\right]5s^{1}$$\vphantom{\Big|}$ & Ag: $\left[\text{Kr}\right]4d^{10}5s^{1}$\tabularnewline
\hline 
Cs: $\left[\text{Xe}\right]6s^{1}$$\vphantom{\Big|}$ & Au: $\left[\text{Xe}\right]5d^{10}6s^{1}$\tabularnewline
\end{tabular}
\par\end{center}


\subsubsection*{Alkali metals}

They have one valence electron and form a bcc lattice in direct space.
It holds:
\begin{align*}
\frac{k_{F}^{3}}{3\pi^{2}} & =n_{e}=\frac{N_{e}}{V}=\frac{2}{a^{3}}
\end{align*}
The factor 2 is due to the fact that the bcc lattice has two atoms
per conventional cubic cell. This gives:
\begin{align*}
k_{F} & \approx0{,}620\cdot\frac{2\pi}{a}
\end{align*}


\textcolor{green}{TODO: Abb 1. Brillouin zone: rhombic dodecahedron}

The shortest distance from the center $\Gamma$ of the first Brillouin
zone to the zone face is in the direction $\left[110\right]$ to the
point $N$:
\begin{align*}
\overline{\Gamma N} & =\frac{2\pi}{a}\sqrt{\left(\frac{1}{2}\right)^{2}+\left(\frac{1}{2}\right)^{2}+0}\approx0{,}707\cdot\frac{2\pi}{a}>k_{F}
\end{align*}
The prefactor is due to the fact, that $\frac{4\pi}{a}$ is the side
of the conventional cubic cell for the fcc lattice.

\textcolor{green}{TODO: Abb Fermi surface; almost no distortion from
the sphere}


\subsubsection*{Noble metals}

Neglecting the $d$-electrons%
\footnote{The $d$-electrons are only relevant for optical properties.%
}, the noble metals have one valence electron. The direct space lattice
is fcc.
\begin{align*}
\frac{k_{F}^{3}}{3\pi^{2}} & =n_{e}=\frac{N_{e}}{V}=\frac{4}{a^{3}}
\end{align*}
The factor 4 is due to the fact that the fcc lattice has four atoms
per conventional cubic cell. This gives:
\begin{align*}
k_{F} & \approx0{,}782\cdot\frac{2\pi}{a}
\end{align*}
The shortest distance from the center $\Gamma$ of the first Brillouin
zone to the zone face is in the direction $\left[111\right]$ to the
point $L$:
\begin{align*}
\overline{\Gamma L} & =\frac{2\pi}{a}\sqrt{\left(\frac{1}{2}\right)^{2}+\left(\frac{1}{2}\right)^{2}+\left(\frac{1}{2}\right)^{2}}\approx0{,}866\cdot\frac{2\pi}{a}\approx1{,}108\cdot k_{F}
\end{align*}
The prefactor is due to the fact, that $\frac{4\pi}{a}$ is the side
of the conventional cubic cell for the bcc lattice.

\textcolor{green}{TODO: Abb Fermi surface for noble metal}

Here the Fermi surface lies nearly within the first Brillouin zone,
but touches the zone face near~$L$.

\textcolor{green}{TODO: Abb Periodic table of Fermi surfaces; IA:
bcc, IIA: Be, Mg: hcp, Ca, Sr: Bcc, Ba: fcc, IB: fcc, IIB: Zn, Cd:
hcp, Hg: rhombohedral}


\subsubsection*{Conclusion}

For simple metals (alkali and noble metals), one can usually forget
the band structure and reduce the problem to that of \emph{free particles}.


\section{Semiconductors}

See integrated course IIa.


\subsubsection*{Typical situation:}

\textcolor{green}{TODO: Abb35}


\subsubsection*{Conclusion}

Since all relevant properties of semiconductors are due to excited
electrons around the minima of the conduction band or to holes around
the maxima of the valence band, one can treat electrons and holes
as free particles possessing an effective mass, which can even be
negative, defined by:
\begin{align*}
\left(\frac{1}{m^{*}\left(n\right)}\right)_{\alpha\alpha'} & :=\frac{1}{\hbar^{2}}\frac{\partial^{2}\varepsilon_{n}\left(\vec{k}\right)}{\partial k_{\alpha}\partial k_{\alpha'}}
\end{align*}


%DATE: Di 08.01.13


\chapter{Second quantization}

Why the need for second quantization?
\begin{itemize}
\item The indistinguishability of particles requires that the wave functions
must be symmetrized or antisymmetrized. This becomes cumbersome if
$N$ is large.
\item The first quantization approach is tailored to problems with fixed
$N$.
\end{itemize}
Refresh the first quantization approach to $N$-particles systems
(cf. section \ref{sec:Indistinguishability-of-particles}):
\begin{enumerate}[label=\roman*)]
\item Consider a set of eigenfunctions $\KET{\lambda}=\KET{\psi_{\lambda}}$
of a single particle Hamiltonian $\hat{h}_{\text{sp}}$:
\begin{align*}
\hat{h}_{\text{sp}}\KET{\psi_{\lambda}} & =\varepsilon_{\lambda}\KET{\psi_{\lambda}}
\end{align*}
Or consider equivalently the set:
\begin{align*}
\left\{ \psi_{\lambda}\left(\vec{r}\right)=\left\langle \vec{r}\big|\psi_{\lambda}\right\rangle =\left\langle \vec{r}\big|\lambda\right\rangle \right\} 
\end{align*}

\item Any $N$-particles wave function can be built from the complete orthonormal
basis $\left\{ \psi_{\lambda}\left(\vec{r}\right)\right\} $. The
$N$-particles wave function reads:
\begin{align*}
\KET{\lambda_{\nu_{1}},\lambda_{\nu_{2}},\ldots,\lambda_{\nu_{N}}} & =\frac{1}{\sqrt{N!}}\cdot\frac{1}{\sqrt{\prod_{\lambda=0}^{\infty}n_{\lambda}!}}\sum_{p\in\mathfrak{S}\left(N\right)}\left(-\xi\right)^{\frac{1-\text{sign}\left(p\right)}{2}}\KET{\lambda_{p_{1}}}\otimes\ldots\otimes\KET{\lambda_{p_{N}}}
\end{align*}
\begin{align*}
\xi & =\begin{cases}
+1 & \text{for fermions}\\
-1 & \text{for bosons}
\end{cases}
\end{align*}

\item \emph{Occupation number representation}: The basis states for an $N$-particle
system are obtained by listing the occupation number of each basis
state.
\begin{align*}
\left\{ \KET{n_{\lambda_{1}},n_{\lambda_{2}},\ldots}\bigg|\sum_{j}n_{\lambda_{j}}=N\right\} 
\end{align*}
\emph{Note}: The sum over $j$ is determined by the dimension of the
single particle Hilbert space.\\
It holds:
\begin{align}
\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}} & =\KET{n_{\lambda_{1}},n_{\lambda_{2}},\ldots,}\label{eq:Number-KET}
\end{align}
For example this means:
\begin{align*}
\KET{\lambda_{\nu_{1}}=1,\lambda_{\nu_{2}}=3,\lambda_{\nu_{3}}=1,\lambda_{\nu_{4}}=0,\lambda_{\nu_{5}}=5} & =\KET{1,2,0,1,0,1,0,0,\ldots}
\end{align*}

\end{enumerate}

\section{The formalism of second quantization}
\begin{itemize}
\item The so-called second quantization formalism is based on the occupation
number representation.
\item The \emph{basis states} as well as each (many-body) \emph{operator}
are uniquely determined by specifying \emph{annihilation/creation}
operators, which fulfill \emph{bosonic (fermionic) commutation relations}.
\end{itemize}
We begin with some abstract definitions:
\begin{enumerate}[label=\roman*)]
\item Introduce a reference state $\KET 0:=\KET{0,0,\ldots}$ called \emph{the
vacuum state}.
\item Introduce a set of operators $\hat{a}_{\lambda}$ and their adjoints
$\hat{a}_{\lambda}^{\dagger}$ such that holds:
\begin{align*}
\hat{a}_{\lambda}\KET 0 & =0\\
\mathcal{N}\prod_{i=1}^{N}\hat{a}_{\lambda_{\nu_{i}}}^{\dagger}\KET 0 & =\mathcal{N}\hat{a}_{\lambda_{\nu_{1}}}^{\dagger}\cdot\ldots\cdot\hat{a}_{\lambda_{\nu_{N}}}^{\dagger}\KET 0:=\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{n}}}
\end{align*}
$\mathcal{N}$ is a normalization factor with
\begin{align*}
\mathcal{N}^{-1} & =\sqrt{\prod_{\lambda}n_{\lambda}}
\end{align*}
and $n_{\lambda}$ is the number of times the state $\KET{\lambda}$
appears in the family $\left(\KET{\lambda_{\nu_{1}}},\ldots,\KET{\lambda_{\nu_{N}}}\right)$.
It holds $n_{\lambda}\in\mathbb{N}$ for bosons and $n_{\lambda}\in\left\{ 0,1\right\} $
for fermions. As we shall proof holds
\begin{align}
\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}} & =\KET{n_{\lambda_{1}},n_{\lambda_{2}},\ldots}\label{eq:occupation-number-representation}
\end{align}
as in \eqref{eq:Number-KET}.
\item In order to care for the symmetry of the so constructed states, $\hat{a}_{\lambda}$
and $\hat{a}_{\lambda}^{\dagger}$ have to fulfill the following commutation
relations:
\begin{align}
\left[\hat{a}_{\lambda},\hat{a}_{\mu}^{\dagger}\right]_{\xi} & :=\hat{a}_{\lambda}\hat{a}_{\mu}^{\dagger}+\xi\hat{a}_{\mu}^{\dagger}\hat{a}_{\lambda}=\delta_{\mu\nu}\label{eq:commutation-relation1}\\
\left[\hat{a}_{\lambda},\hat{a}_{\mu}\right]_{\xi} & =\left[\hat{a}_{\lambda}^{\dagger},\hat{a}_{\mu}^{\dagger}\right]_{\xi}=0\label{eq:commutation-relation2}
\end{align}
To understand \eqref{eq:commutation-relation2} observe:
\begin{align*}
\KET{\lambda,\mu} & =\mathcal{N}\hat{a}_{\lambda}^{\dagger}\hat{a}_{\mu}^{\dagger}\KET 0\\
\KET{\mu,\lambda} & =\mathcal{N}\hat{a}_{\mu}^{\dagger}\hat{a}_{\lambda}^{\dagger}\KET 0\stackrel{\eqref{eq:commutation-relation2}}{=}-\xi\KET{\lambda,\mu}
\end{align*}
These are the proper symmetry relations.\\
On the other hand \eqref{eq:commutation-relation1} ensures orthonormality:
\begin{align*}
\delta_{\lambda\mu} & =\BraKet{0|\hat{a}_{\lambda}\hat{a}_{\mu}^{\dagger}|0}=\BraKet{0|\left(-\xi\right)\hat{a}_{\mu}^{\dagger}\hat{a}_{\lambda}+\left[\hat{a}_{\lambda},\hat{a}_{\mu}^{\dagger}\right]_{\xi}|0}=\\
 & =\underbrace{\BraKet{0|\left(-\xi\right)\hat{a}_{\mu}^{\dagger}\hat{a}_{\lambda}|0}}_{=0}+\BraKet{0|\left[\hat{a}_{\lambda},\hat{a}_{\mu}^{\dagger}\right]_{\xi}|0}=\BraKet{0|\left[\hat{a}_{\lambda},\hat{a}_{\mu}^{\dagger}\right]_{\xi}|0}
\end{align*}
Under the prescriptions i) - iii), \emph{any} $N$-body state can
be generated by the application of a set of $N$ independent creation
operators $\hat{a}_{\lambda}^{\dagger}$ to a vacuum state. This is
the completeness of the second quantization approach.
\item Define now $\mathcal{F}_{N}$ as the Hilbert space of states with
fixed particle number $N$, i.e. the linear span of all basis states
with $\KET{\lambda_{\nu_{1}},\lambda_{\nu_{2}},\ldots,\lambda_{\nu_{N}}}$.
The space
\begin{align*}
\mathcal{F} & =\bigoplus_{N=0}^{\infty}\mathcal{F}_{N}
\end{align*}
containing \emph{all} many-body states is called \emph{Fock space}.
While the operator algebra of $\hat{a}_{\lambda}$ and $\hat{a}_{\lambda}^{\dagger}$
does not close in $\mathcal{F}_{N}$, it does in $\mathcal{F}$.\\
\textcolor{green}{TODO: Abb36}\\
For fermions holds:
\begin{align*}
\left(\hat{a}_{\lambda}^{\dagger}\right)^{2} & =0=\left(\hat{a}_{\lambda}\right)^{2}
\end{align*}

\item Define the occupation number operator:
\begin{align*}
\hat{n}_{\lambda} & =\hat{a}_{\lambda}^{\dagger}\hat{a}_{\lambda}
\end{align*}
For it holds:
\begin{align*}
\hat{n}_{\lambda}\left(\hat{a}_{\lambda}^{\dagger}\right)^{n_{\lambda}}\KET 0 & =n_{\lambda}\left(\hat{a}_{\lambda}^{\dagger}\right)^{n_{\lambda}}\KET 0
\end{align*}
This means that $\left(\hat{a}_{\lambda}^{\dagger}\right)^{n_{\lambda}}\KET 0$
is an eigenstate of $\hat{n}_{\lambda}$ with eigenvalue $n_{\lambda}$.
Moreover we have:
\begin{align*}
\hat{n}_{\lambda}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}} & =\mathcal{N}\hat{a}_{\lambda}^{\dagger}\hat{a}_{\lambda}\prod_{i=1}^{N}\hat{a}_{\lambda_{\nu_{i}}}^{\dagger}\KET 0=\sum_{i=1}^{N}\delta_{\lambda\lambda_{\nu_{i}}}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}
\end{align*}
So $\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}$ is an eigenstate
of $\hat{n}_{\lambda}$ with eigenvalue $n_{\lambda}$, which proofs
the equality \eqref{eq:occupation-number-representation}.
\item To change the basis, observe:
\begin{align*}
\hat{I} & =\sum_{\lambda}\KET{\lambda}\BRA{\lambda}\\
\Rightarrow\qquad\hat{a}_{\tilde{\lambda}}^{\dagger}\KET 0=\KET{\tilde{\lambda}} & =\sum_{\lambda}\KET{\lambda}\BraKet{\lambda|\tilde{\lambda}}=\left(\sum_{\lambda}\hat{a}_{\lambda}^{\dagger}\BraKet{\lambda|\tilde{\lambda}}\right)\KET 0
\end{align*}
This gives:
\begin{align}
\fbox{\ensuremath{{\displaystyle \hat{a}_{\tilde{\lambda}}^{\dagger}=\sum_{\lambda}\hat{a}_{\lambda}^{\dagger}\BraKet{\lambda|\tilde{\lambda}}}}} &  & \fbox{\ensuremath{{\displaystyle \hat{a}_{\lambda}=\sum_{\lambda}\hat{a}_{\lambda}\BraKet{\tilde{\lambda}|\lambda}}}}
\end{align}
\emph{Example}: Transformation from the coordinate to momentum representation
in one dimension for a system of length $L$ goes as follows:
\begin{align*}
\hat{a}_{\tilde{\lambda}} & =\hat{a}\left(x\right) & \hat{a}_{\lambda} & =\hat{a}_{k}
\end{align*}
\begin{align*}
\Rightarrow\quad\hat{a}\left(x\right) & =\sum_{k}\hat{a}_{k}\BraKet{x|k}=\frac{1}{\sqrt{L}}\sum_{k}\hat{a}_{k}e^{\ii kx}\\
\hat{a}_{k} & =\int_{0}^{L}\dd x\left\langle k|x\right\rangle \hat{a}\left(x\right)=\frac{1}{\sqrt{L}}\int_{0}^{L}\dd xe^{-\ii kx}\hat{a}\left(x\right)
\end{align*}
\emph{Note}:
\begin{align*}
\left[\hat{a}\left(\vec{r}_{1}\right),\hat{a}^{\dagger}\left(\vec{r}_{2}\right)\right]_{\xi} & =\delta\left(\vec{r}_{1}-\vec{r}_{2}\right)
\end{align*}

\item In second quantization, every operator can be written in terms of
the creation and annihilation operators.
\end{enumerate}

\section{Representation of one-body and two-body operators in second quantization}

One-body operators $\hat{O}_{1}$ acting in the $N$-particle Hilbert
space $\mathcal{F}_{N}$ are defined as:
\begin{align*}
\hat{O}_{1} & =\sum_{i=1}^{N}\hat{o}_{i}
\end{align*}
Here $\hat{o}_{i}$ is an operator acting on particle $i$.


\subsubsection*{Examples}
\begin{itemize}
\item Kinetic operator:
\begin{align*}
\hat{T} & =\sum_{i=1}^{N}\hat{t}_{i}=\sum_{i=1}^{N}\frac{\hat{p}^{2}}{2m}=-\frac{\hbar^{2}}{2m}\sum_{i=1}^{N}\nabla_{i}^{2}
\end{align*}

\item One particle potential operator:
\begin{align*}
\hat{V} & =\sum_{i=1}^{N}v\left(\vec{r}_{i}\right)=\sum_{i=1}^{N}\hat{v}_{i}
\end{align*}

\end{itemize}
%DATE: Di 15.01.12


\subsection{One-body operators in second quantization}

In general in first quantization holds:
\begin{align*}
\hat{o} & =\sum_{\lambda_{1}\lambda_{2}}o_{\lambda_{1}\lambda_{2}}\KET{\lambda_{1}}\BRA{\lambda_{1}} & o_{\lambda_{1}\lambda_{2}} & =\left\langle \lambda_{1}|\hat{o}|\lambda_{2}\right\rangle 
\end{align*}


Consider a one-body operator that is \emph{diagonal} in the basis
$\left(\KET{\lambda}\right)$, i.e.:
\begin{align*}
\hat{O}_{1} & =\sum_{i=1}^{N}\hat{o}_{i} & \hat{o} & =\sum_{\lambda}o_{\lambda}\KET{\lambda}\BRA{\lambda} & o_{\lambda} & =\BraKet{\lambda|\hat{o}|\lambda}
\end{align*}
Now we calculate:
\begin{align*}
 & \BraKet{\lambda_{\nu_{1}'},\lambda_{\nu_{2}'},\ldots,\lambda_{\nu_{N}'}|\hat{O}_{1}|\lambda_{\nu_{1}},\lambda_{\nu_{2}},\ldots,\lambda_{\nu_{N}}}\\
 & \qquad\qquad=\BraKet{\lambda_{\nu_{1}'},\lambda_{\nu_{2}'},\ldots,\lambda_{\nu_{N}'}|\sum_{i=1}^{N}\sum_{\lambda}o_{\lambda}\KET{\lambda}_{i\ i}\!\BRA{\lambda}|\lambda_{\nu_{1}},\lambda_{\nu_{2}},\ldots,\lambda_{\nu_{N}}}=\\
 & \qquad\qquad=\BraKet{\lambda_{\nu_{1}'},\lambda_{\nu_{2}'},\ldots,\lambda_{\nu_{N}'}|\sum_{i=1}^{N}\sum_{\lambda}o_{\lambda}\delta_{\lambda\lambda_{\nu_{i}}}|\lambda_{\nu_{1}},\lambda_{\nu_{2}},\ldots,\lambda_{\nu_{N}}}
\end{align*}
Here we wrote short $\KET{\lambda}_{i\ i}\!\BRA{\lambda}$ for the
fact that the operator acts on the $i$-th component of $\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}$.
Using
\begin{align*}
\hat{n}_{\lambda}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}} & =\sum_{i=1}^{N}\delta_{\lambda\lambda_{\nu_{i}}}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}
\end{align*}
we get:
\begin{align*}
\BraKet{\lambda_{\nu_{1}'},\ldots,\lambda_{\nu_{N}'}|\hat{O}_{1}|\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}} & =\BraKet{\lambda_{\nu_{1}'},\ldots,\lambda_{\nu_{N}'}|\sum_{\lambda}o_{\lambda}\hat{n}_{\lambda}|\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}
\end{align*}
This gives:
\begin{align}
\fbox{\ensuremath{{\displaystyle \hat{O}_{1}=\sum_{\lambda}o_{\lambda}\hat{n}_{\lambda}=\sum_{\lambda}o_{\lambda}\hat{a}_{\lambda}^{\dagger}\hat{a}_{\lambda}}}}
\end{align}
For a generic basis $\KET{\tilde{\lambda}}$ we know:
\begin{align*}
\hat{a}_{\tilde{\lambda}} & =\sum_{\lambda}\hat{a}_{\lambda}\left\langle \tilde{\lambda}|\lambda\right\rangle  & \hat{a}_{\tilde{\lambda}}^{\dagger} & =\sum_{\lambda}\hat{a}_{\lambda}^{\dagger}\left\langle \tilde{\lambda}|\lambda\right\rangle \\
\hat{a}_{\lambda} & =\sum_{\tilde{\eta}}\hat{a}_{\tilde{\eta}}\left\langle \lambda|\tilde{\eta}\right\rangle  & \hat{a}_{\lambda}^{\dagger} & =\sum_{\tilde{\nu}}\hat{a}_{\tilde{v}}^{\dagger}\left\langle \tilde{\nu}|\lambda\right\rangle 
\end{align*}
With $o_{\tilde{\nu},\tilde{\eta}}:=\left\langle \tilde{\nu},\lambda\right\rangle \left\langle \lambda,\tilde{\eta}\right\rangle $
follows:
\begin{align}
\fbox{\ensuremath{{\displaystyle \hat{O}_{1}=\sum_{\tilde{\eta},\tilde{\nu}}o_{\tilde{\nu},\tilde{\eta}}\hat{a}_{\tilde{\nu}}^{\dagger}\hat{a}_{\tilde{\eta}}}}}
\end{align}



\subsubsection*{Example: Kinetic operator}

\begin{align*}
\hat{T} & =\sum_{i=1}^{N}\hat{t}_{i}=\sum_{\mu\nu}t_{\mu\nu}\hat{a}_{\mu}^{\dagger}\hat{a}_{\nu}
\end{align*}

\begin{enumerate}[label=\roman*)]
\item Position representation:
\begin{align*}
t_{\mu\nu} & =\BraKet{\mu|\hat{t}|\nu}=\int\dd^{3}r\int\dd^{3}r'\BraKet{\mu|\vec{r}}\BraKet{\vec{r}|\hat{t}|\vec{r}'}\left\langle \vec{r}'|\nu\right\rangle =\\
 & =\int\dd^{3}r\int\dd^{3}r'\psi_{\mu}^{*}\left(\vec{r}\right)\BraKet{\vec{r}|\hat{t}|\vec{r}'}\psi_{\nu}\left(\vec{r}'\right)=\\
 & =\int\dd^{3}r\psi_{\mu}^{*}\left(\vec{r}\right)\left(-\frac{\hbar^{2}}{2m}\nabla_{r}^{2}\right)\psi_{\nu}\left(\vec{r}\right)
\end{align*}
\begin{align*}
\Rightarrow\qquad\hat{T} & =\sum_{\mu,\nu}t_{\mu\nu}\hat{a}_{\mu}^{\dagger}\hat{a}_{\nu}=\int\dd^{3}r\underbrace{\left(\sum_{\mu}\psi_{\mu}^{*}\left(\vec{r}\right)\hat{a}_{\mu}^{\dagger}\right)}_{=:\hat{a}^{\dagger}\left(\vec{r}\right)}\left(-\frac{\hbar^{2}}{2m}\nabla_{r}^{2}\right)\underbrace{\left(\sum_{\nu}\psi_{\nu}\left(\vec{r}\right)\hat{a}_{\nu}\right)}_{=\hat{a}\left(\vec{r}\right)}=\\
 & =\int\dd^{3}r\hat{a}^{\dagger}\left(\vec{r}\right)\left(-\frac{\hbar^{2}}{2m}\nabla_{r}^{2}\right)\hat{a}\left(\vec{r}\right)
\end{align*}

\item Momentum representation:
\begin{align*}
\hat{a}^{\dagger}\left(\vec{r}\right) & =\sum_{\vec{k}}\BraKet{\vec{r}|\vec{k}}^{*}\hat{a}_{\vec{k}}^{\dagger}=\frac{1}{\sqrt{V}}\sum_{\vec{k}}e^{-\ii\vec{k}\cdot\vec{r}}\hat{a}_{\vec{k}}^{\dagger}
\end{align*}
\begin{align*}
\Rightarrow\qquad\hat{T} & =-\frac{1}{V}\sum_{\vec{k},\vec{k}'}\int\dd^{3}re^{-\ii\vec{k}\cdot\vec{r}}\hat{a}_{\vec{k}}^{\dagger}\frac{\hbar^{2}}{2m}\nabla_{r}^{2}e^{\ii\vec{k}'\cdot\vec{r}}\hat{a}_{\vec{k}'}=\\
 & \stackrel{\frac{1}{V}\int\dd^{3}re^{\ii\vec{k}\cdot\vec{r}}=\delta_{\vec{k},\vec{0}}}{=}\sum_{\vec{k}}\frac{\hbar^{2}k^{2}}{2m}\hat{a}_{\vec{k}}^{\dagger}\hat{a}_{\vec{k}}
\end{align*}
\emph{Note:} For particles with spin holds:
\begin{align*}
\hat{T} & =\sum_{\vec{k},\sigma}\frac{\hbar^{2}k^{2}}{2m}\hat{a}_{\vec{k}\sigma}^{\dagger}\hat{a}_{\vec{k}\sigma}=\sum_{\sigma}\int\dd^{3}r\hat{a}_{\sigma}^{\dagger}\left(\vec{r}\right)\left(-\frac{\hbar^{2}}{2m}\nabla_{\vec{r}}^{2}\right)\hat{a}_{\sigma}\left(\vec{r}\right)
\end{align*}

\end{enumerate}

\subsubsection*{Example: Density operator}

\begin{align*}
\hat{\varrho}_{\text{tot}} & :=\sum_{i=1}^{N}\delta\left(\vec{r}-\vec{r}_{i}\right)
\end{align*}
In the position representation we get:
\begin{align*}
\hat{\varrho}_{\text{tot}}\left(\vec{r}\right) & =\hat{a}^{\dagger}\left(\vec{r}\right)\hat{a}\left(\vec{r}\right)
\end{align*}
In the momentum representation this gives:
\begin{align*}
\hat{\varrho}_{\text{tot}}\left(\vec{k}\right) & =\frac{1}{V}\sum_{\vec{k},\vec{q}}e^{\ii\vec{q}\cdot\vec{r}}\hat{a}_{\vec{k}}^{\dagger}\hat{a}_{\vec{k}+\vec{q}}
\end{align*}



\subsubsection*{Example: Number operator}

Position representation:
\begin{align*}
\hat{N} & =\int\dd^{3}r\hat{\varrho}_{\text{tot}}\left(\vec{r}\right)=\int\dd^{3}r\hat{a}^{\dagger}\left(\vec{r}\right)\hat{a}\left(\vec{r}\right)
\end{align*}
Momentum representation:
\begin{align}
\hat{N} & =\frac{1}{V}\int\dd^{3}r\sum_{\vec{q},\vec{k}}e^{\ii\vec{q}\cdot\vec{r}}\hat{a}_{\vec{k}}^{\dagger}\hat{a}_{\vec{k}+\vec{q}}=\sum_{\vec{k}}\hat{a}_{\vec{k}}^{\dagger}\hat{a}_{\vec{k}}=\sum_{\vec{k}}\hat{n}_{\vec{k}}
\end{align}
\begin{align*}
\hat{N}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}} & =\sum_{\lambda_{i}}\hat{n}_{\lambda_{i}}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}=\underbrace{\sum_{\lambda_{i}}n_{\lambda_{i}}}_{=N}\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}=N\KET{\lambda_{\nu_{1}},\ldots,\lambda_{\nu_{N}}}
\end{align*}



\subsubsection*{Example: One-particle Hamiltonian}

\begin{align*}
\hat{H} & =\sum_{i=1}^{N}\hat{h}_{i}=\sum_{i=1}^{N}\left(\frac{\hat{p}^{2}}{2m}+v\left(\vec{r}_{i}\right)\right) & v\left(\vec{r}_{i}+\vec{R}\right) & =v\left(\vec{r}_{i}\right)
\end{align*}
This is a problem for $N$ electrons in a \emph{periodic} potential.
The eigenvector basis vectors are the Bloch states:
\begin{align*}
\hat{h}\KET{\vec{k},n} & =\varepsilon_{\vec{k},n}\KET{\vec{k},n}
\end{align*}
\begin{align*}
\hat{H} & =\sum_{\vec{k},n}\varepsilon_{\vec{k},n}\hat{a}_{\vec{k},n}^{\dagger}\hat{a}_{\vec{k},n}
\end{align*}



\subsection{Two-body operators}

A two-body operator in an $N$-particles system is defined in first
quantization as:
\begin{align*}
\hat{O}_{2} & =\frac{1}{2}\sum_{i,i\not=j}\hat{o}_{ij}
\end{align*}
It follows that these operators are fully characterized by their action
on two particles.

Consider the matrix element (primed indices are for particle two):
\begin{align*}
o_{\mu\mu'\lambda\lambda'} & =\BraKet{\mu\mu'|\hat{o}|\lambda\lambda'}\stackrel{\text{not symmetrized}}{:=}\BRA{\mu}\otimes\BRA{\mu'}\hat{o}\KET{\lambda}\otimes\KET{\lambda'}
\end{align*}
Computing
\begin{align*}
\BraKet{\mu_{1}\mu_{2}\ldots\mu_{N}|\hat{O}_{2}|\lambda_{1}\lambda_{2}\ldots\lambda_{N}}
\end{align*}
with the symmetrized states, we get:
\begin{align}
\hat{O}_{2} & =\frac{1}{2}\sum_{\lambda\lambda'\mu\mu'}o_{\mu\mu'\lambda\lambda'}\hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}^{\dagger}\hat{a}_{{\color{red}\lambda'}}\hat{a}_{{\color{red}\lambda}}
\end{align}
\textcolor{green}{TODO: abb37 Feynman-diagram; interpretation of $o_{\mu\mu'\lambda\lambda'}$}


\subsubsection*{Example: Coulomb interaction}

\begin{align*}
\hat{V}_{ee} & =\frac{1}{2}\sum_{i,j,i\not=j}\frac{e^{2}}{\norm{\vec{r}_{i}-\vec{r}_{j}}}=\frac{1}{2}\sum_{i,j,i\not=j}v_{ee}\left(\vec{r}_{i}-\vec{r}_{j}\right)
\end{align*}


In the position representation holds:
\begin{align*}
\hat{V}_{ee} & =\frac{1}{2}\sum_{\mu,\mu',\lambda,\lambda'}\left(\int\dd^{3}r\int\dd^{3}r'\psi_{\mu}^{*}\left(\vec{r}\right)\psi_{\mu'}^{*}\left(\vec{r}'\right)v_{ee}\left(\vec{r}-\vec{r}'\right)\psi_{\lambda'}\left(\vec{r}'\right)\psi_{\lambda}\left(\vec{r}\right)\right)\hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}^{\dagger}\hat{a}_{\lambda'}\hat{a}_{\lambda}=\\
 & =\frac{1}{2}\int\dd^{3}r\int\dd^{3}r'\hat{a}^{\dagger}\left(\vec{r}\right)\hat{a}^{\dagger}\left(\vec{r}'\right)v_{ee}\left(\vec{r}-\vec{r}'\right)\hat{a}\left(\vec{r}'\right)\hat{a}\left(\vec{r}\right)
\end{align*}
Including the spin we get:
\begin{align*}
\hat{V}_{ee} & =\frac{1}{2}\sum_{\sigma\sigma'}\int\dd^{3}r\int\dd^{3}r'\hat{a}_{\sigma}^{\dagger}\left(\vec{r}\right)\hat{a}_{\sigma'}^{\dagger}\left(\vec{r}'\right)v\left(\vec{r}-\vec{r}'\right)\hat{a}_{\sigma'}\left(\vec{r}'\right)\hat{a}_{\sigma}\left(\vec{r}\right)
\end{align*}
In the momentum representation, the Coulomb interaction can be seen
as a scattering process with momentum transfer $\vec{q}$.
\begin{align}
\hat{V}_{ee} & =\frac{1}{2V}\sum_{\sigma,\sigma'}\sum_{\vec{q}}\sum_{\vec{k},\vec{k}'}\tilde{v}_{ee}\left(\vec{q}\right)\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}'-\vec{q},\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}
\end{align}
Here $\tilde{v}_{ee}$ is the Fourier transformation:
\begin{align}
\tilde{v}_{ee}\left(\vec{q}\right) & :=\int\dd^{3}re^{\ii\vec{q}\cdot\vec{r}}\frac{e^{2}}{r}=\lim_{\eta\to0}\int\dd^{3}re^{\ii\vec{q}\cdot\vec{r}}e^{-\eta r}\frac{e^{2}}{r}=\frac{4\pi e^{2}}{q^{2}}
\end{align}
\textcolor{green}{TODO: Abb38}

%DATE: Do 17.01.13


\chapter{Interacting electron gas}

Let us remember the Hamiltonian of a solid in the adiabatic approximation:
\begin{align*}
\underbrace{\left(\hat{T}_{ee}+\hat{V}_{ee}+\hat{V}_{ei}+\hat{V}_{ii}\right)}_{=\hat{H}_{\text{el}}}\phi_{k} & =\varepsilon_{\text{el}}\left(k\right)\phi_{k} &  & \text{electrons}\\
\left(\hat{T}_{\text{ion}}+\varepsilon_{\text{el}}\left(k\right)\right)\chi_{k} & =E\chi_{k} &  & \text{ions}
\end{align*}
We now remember
\begin{align*}
\hat{H}_{\text{el}} & =\hat{T}_{ee}+\hat{V}_{ee}+\hat{V}_{ei}+\hat{V}_{ii}
\end{align*}
and in a first approximation \emph{fully} neglect the ion:
\begin{align*}
\hat{H}_{\text{el}} & \approx\hat{T}_{ee}+\hat{V}_{ee}\\
\hat{V}_{ee} & =\frac{1}{2V}\sum_{\vec{k},\vec{k}',\vec{q}}\sum_{\sigma,\sigma'}\tilde{v}_{ee}\left(q\right)\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}'-\vec{q},\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}\\
\tilde{v}_{ee}\left(q\right) & =\frac{4\pi e^{2}}{q^{2}}
\end{align*}
\emph{Problem:} We have a divergence at $q=0$.


\section{Jellium model}

To remove the divergence, we observe that the positively charged ions
do not only provide a periodic potential for the electrons, but also
ensure charge neutrality. To this extend we introduced the local charge
density:
\begin{align*}
e\tilde{\varrho}\left(\vec{r}\right) & =e\left(\varrho\left(\vec{r}\right)-z\varrho_{\text{ion}}\left(\vec{r}\right)\right)
\end{align*}
The jellium approximation is:
\begin{align*}
z\varrho_{\text{ion}}\left(\vec{r}\right) & \approx z\varrho_{\text{ion}}^{\text{jellium}}:=n_{e}=\frac{N_{e}}{V}
\end{align*}
Within this approximation holds:
\begin{align*}
\hat{V}_{ee}+\hat{V}_{ei}+\hat{V}_{ii} & \approx\hat{V}_{ee}+\hat{V}_{ei}^{\text{jellium}}+\hat{V}_{ii}^{\text{jellium}}=:\hat{V}_{ee}^{\text{jellium}}
\end{align*}
Now the very nice thing is that this turns out to cancel the divergence:
\begin{align}
\hat{V}_{ee}^{\text{jellium}} & =\frac{1}{2V}\sum_{\vec{k},\vec{k}',\vec{q}\not=0}\sum_{\sigma,\sigma'}\tilde{v}_{ee}\left(q\right)\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}-\vec{q},\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}
\end{align}
To see this, let us consider the second quantization expressions for
$\hat{V}_{ei}$ and $\hat{V}_{ii}$:
\begin{align*}
\hat{V}_{ei} & =\int\dd^{3}r\dd^{3}r'\hat{\psi}_{\text{el}}^{\dagger}\left(\vec{r}\right)\hat{\psi}_{\text{ion}}^{\dagger}\left(\vec{r}'\right)v_{ei}\left(\vec{r}-\vec{r}'\right)\hat{\psi}_{\text{ion}}\left(\vec{r}'\right)\hat{\psi}_{\text{el}}\left(\vec{r}\right)\\
\hat{V}_{ii} & =\frac{1}{2}\int\dd^{3}r\dd^{3}r'\hat{\psi}_{\text{ion}}^{\dagger}\left(\vec{r}\right)\hat{\psi}_{\text{ion}}^{\dagger}\left(\vec{r}'\right)v_{ii}\left(\vec{r}-\vec{r}'\right)\hat{\psi}_{\text{ion}}\left(\vec{r}'\right)\hat{\psi}_{\text{ion}}\left(\vec{r}\right)
\end{align*}
Within the jellium approximation we get:
\begin{align*}
\hat{V}_{ei} & \approx\hat{V}_{ei}^{\text{jellium}}=-\frac{\hat{N}_{e}}{V}\int\dd^{3}r\int\dd^{3}r'\hat{\varrho}_{\text{el}}\left(\vec{r}\right)\frac{e^{2}}{\abs{\vec{r}-\vec{r}'}}+\frac{\hat{N}_{e}^{2}}{V^{2}}\cdot\frac{1}{2}\int\dd^{3}r\int\dd^{3}r'\frac{e^{2}}{\abs{\vec{r}-\vec{r}'}}=\\
 & =-\frac{\hat{N}_{e}^{2}}{V}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)+\frac{1}{2}\frac{\hat{N}_{e}^{2}}{V}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)=-\frac{1}{2}\frac{\hat{N}_{e}^{2}}{V}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)
\end{align*}
On the other hand, the $q=0$ contribution from $\hat{V}_{ee}$ is:
\begin{align*}
 & \frac{1}{2V}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)\sum_{\vec{k},\vec{k}'}\sum_{\sigma,\sigma'}\hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}=\\
 & \qquad\qquad\sr ={\text{Pauli}}{\text{principle}}\frac{1}{2V}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)\sum_{\vec{k},\sigma}\sum_{\left(\vec{k}',\sigma'\right)\not=\left(\vec{k},\sigma\right)}\hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}=\\
 & \qquad\qquad=\frac{1}{2V}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)\underbrace{\sum_{\vec{k},\sigma}\hat{n}_{\vec{k},\sigma}}_{\to N_{e}}\underbrace{\sum_{\left(\vec{k}',\sigma'\right)\not=\left(\vec{k},\sigma\right)}\hat{n}_{\vec{k}',\sigma'}}_{\to N_{e}-1}\approx\\
 & \qquad\qquad\stackrel{N_{e}\gg1}{\approx}\frac{1}{2}\lim_{q\to0}\tilde{v}_{ee}\left(q\right)\frac{\hat{N}_{e}^{2}}{V}
\end{align*}
This compensates $\hat{V}_{ei}^{\text{jellium}}+\hat{V}_{ii}^{\text{jellium}}$.


\section{Energy scales}

We have the interplay between kinetic energy of the electrons and
Coulomb repulsion. Which energy scale wins for a normal metal?
\begin{itemize}
\item It holds:
\begin{align*}
\frac{1}{n_{e}} & =\frac{V}{N_{e}}\approx\frac{4}{3}\pi r_{0}^{3}
\end{align*}
So the potential energy per particle is:
\begin{align*}
\varepsilon_{\text{pot}} & \approx\frac{e^{2}}{r_{0}}\sim n_{e}^{\frac{1}{3}}
\end{align*}

\item The kinetic energy per particle is the ground state energy per particle
of the noninteracting (ideal) Fermi gas (see equation \eqref{eq:E0}
and \eqref{eq:Fermi-momentum}):
\begin{align*}
\varepsilon_{\text{kin}} & =\frac{E_{\text{ground state}}}{N_{\text{el}}}=\frac{3}{5}\varepsilon_{F}=\frac{3}{5}\frac{\hbar^{2}k_{F}^{2}}{2m}=\frac{3}{5}\frac{\hbar^{2}}{2m}\left(3\pi^{2}n_{e}\right)^{\frac{2}{3}}\sim n_{e}^{\frac{2}{3}}
\end{align*}

\item It follows:
\begin{align*}
\frac{\varepsilon_{\text{pot}}}{\varepsilon_{\text{kin}}} & \sim\frac{n_{e}^{\frac{1}{3}}}{n_{e}^{\frac{1}{3}}}=n_{e}^{-\frac{1}{3}}\xrightarrow{n_{e}\to\infty}0
\end{align*}
The importance of the Coulomb interaction diminishes with density
as a consequence of the \emph{Pauli principle}.
\item A parameter to quantify the ratio of the two energy scales is the
dimensionless quantity $r_{s}$ (cf. \noun{Ashcroft} and \noun{Mermin},
Table 1.1):
\begin{align*}
r_{s} & :=\frac{r_{0}}{a_{0}}=\frac{r_{0}}{\hbar^{2}m^{-1}e^{-2}}=\frac{e^{2}}{r_{0}}\cdot\frac{mr_{0}^{2}}{\hbar^{2}}\approx\frac{\varepsilon_{\text{pot}}}{\varepsilon_{\text{kin}}}
\end{align*}
(With $\Delta p\Delta x\ge\hbar$ follows $\Delta p\approx\frac{\hbar}{r_{0}}$.)
\end{itemize}
\noindent \begin{center}
\begin{tabular}{c|c}
Metal$\vphantom{\Big|}$ & $r_{s}$\tabularnewline
\hline 
\hline 
Li$\vphantom{\Big|}$ & 3,3\tabularnewline
\hline 
Na$\vphantom{\Big|}$ & 3,9\tabularnewline
\hline 
K$\vphantom{\Big|}$ & 4,9\tabularnewline
\hline 
Cu$\vphantom{\Big|}$ & 2,7\tabularnewline
\hline 
Be$\vphantom{\Big|}$ & 1,9\tabularnewline
\end{tabular}
\par\end{center}

So simple and noble metals have intermediate values of $r_{s}$!


\section{Electron interaction effects in perturbation theory}

We consider
\begin{align}
\hat{H}_{e}^{\text{jellium}} & =\hat{T}_{ee}+\hat{V}_{ee}^{\text{jellium}}
\end{align}
and look at $\hat{V}_{ee}^{\text{jellium}}$ as a perturbation. We
calculate the ground state energy.


\subsubsection*{Zeroth order}

\begin{align*}
E^{\left(0\right)} & =\BraKet{\text{FS}|\hat{T}_{ee}|\text{FS}}
\end{align*}
Here $\KET{\text{FS}}$ (Fermi sea) is the ground state for $N_{e}$
noninteracting fermions:
\begin{align*}
\KET{\text{FS}} & =\prod_{\vec{k}_{i},\norm{\vec{k}_{i}}\le k_{F}}\prod_{\sigma}\hat{a}_{\vec{k}_{i},\sigma}^{\dagger}\KET 0\\
\varepsilon_{k_{1}} & \le\varepsilon_{k_{2}}\le\ldots\le\varepsilon_{k_{F}}
\end{align*}
Hence we get:
\begin{align*}
E^{\left(0\right)} & =\BraKet{\text{FS}|\sum_{\vec{k},\sigma}\frac{\hbar^{2}}{2m}k^{2}\hat{n}_{\vec{k},\sigma}|\text{FS}}
\end{align*}
\begin{align*}
\hat{n}_{\vec{k},\sigma}\KET{\text{FS}} & =\hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\KET{\text{FS}}=\begin{cases}
1 & k\le k_{F}\\
0 & k>k_{F}
\end{cases}
\end{align*}
With this follows:
\begin{align*}
\frac{E^{\left(0\right)}}{N} & =\varepsilon^{\left(0\right)}=\sum_{\vec{k},\sigma}\frac{\hbar^{2}k^{2}}{2m}\BraKet{\text{FS}|\hat{n}_{\vec{k},\sigma}|\text{FS}}=\sum_{\norm{\vec{k}}\le k_{F},\sigma}\frac{\hbar^{2}k^{2}}{2m}\stackrel{\eqref{eq:E0}}{=}\frac{3}{5}N\varepsilon_{F}\approx\frac{2,21}{r_{s}^{2}}E_{\text{Ry}}
\end{align*}
The last approximation is a comparison with the Rydberg energy:
\begin{align*}
E_{\text{Ry}} & =\frac{e^{2}}{2a_{0}}\approx13{,}6\,\text{eV}
\end{align*}



\subsubsection*{First order}

\begin{align*}
E^{\left(1\right)} & =\BraKet{\text{FS}|\hat{V}_{ee}^{\text{jellium}}|\text{FS}}=\\
 & =\frac{1}{2V}\sum_{\vec{q}\not=0}\sum_{\vec{k},\vec{k}',\sigma,\sigma'}\tilde{v}_{ee}\left(\vec{q}\right)\cdot\BraKet{\text{FS}|\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}'-\vec{q},\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}|\text{FS}}\stackrel{k,k'<k_{F}}{\not=}0
\end{align*}
We also need $\vec{k}'=\vec{k}+\vec{q}$ and $\sigma=\sigma'$ for
this not to vanish.

%DATE: Fr 18.01.13

Now follows:
\begin{align*}
\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}'-\vec{q},\sigma'}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma} & =\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma'}^{\dagger}\hat{a}_{\vec{k}+\vec{q},\sigma'}\hat{a}_{\vec{k},\sigma}=-\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}+\vec{q},\sigma'}\hat{a}_{\vec{k},\sigma'}^{\dagger}\hat{a}_{\vec{k},\sigma}
\end{align*}


Hence we get:
\begin{align*}
E^{\left(1\right)} & =-\frac{1}{2V}\sum_{\vec{q}\not=0}\sum_{\vec{k},\vec{k}',\sigma,\sigma'}\tilde{v}_{ee}\left(q\right)\delta_{\sigma\sigma'}\delta_{\vec{k}+\vec{q},\vec{k}'}\Theta\left(k_{F}-\norm{\vec{k}+\vec{q}}\right)\Theta\left(k_{F}-\norm{\vec{k}}\right)=\\
 & =-\frac{1}{V}\frac{V^{2}}{\left(2\pi\right)^{6}}\int\dd\vec{q}\tilde{v}_{ee}\left(q\right)\left(1-\delta_{\vec{q},0}\right)\int\dd\vec{k}\Theta\left(k_{F}-\norm{\vec{k}+\vec{q}}\right)\Theta\left(k_{F}-\norm{\vec{k}}\right)
\end{align*}
For the integration limits consider:

\textcolor{green}{TODO: Abb39}
\begin{align*}
0 & \le q\le2k_{F}\\
\frac{q}{2k_{F}} & \le\cos\left(\theta_{k}\right)\le1\\
\frac{q}{2\cos\left(\theta_{k}\right)} & <k<k_{F}
\end{align*}
(see \noun{Bruus} and \noun{Flensberg}, section 2.2.1)

This yields:
\begin{align*}
E^{\left(1\right)} & =-\frac{4\pi e^{2}}{2V}\underbrace{2\cdot}_{\text{spin}}\underbrace{\left(4\pi\right)}_{q\text{-solid angle}}\frac{V}{\left(2\pi\right)^{3}}\int_{0^{+}}^{2k_{F}}\dd q\frac{q^{2}}{q^{2}}\underbrace{2\cdot}_{\text{symmetry}}\underbrace{\left(2\pi\right)}_{\text{integration over }\varphi_{k}}\cdot\\
 & \qquad\cdot\int_{\frac{a}{2k_{F}}}^{1}\dd\left(\cos\theta_{k}\right)\frac{V}{\left(2\pi\right)^{3}}\int_{\frac{q}{2\cos\left(\theta_{k}\right)}}^{k_{F}}\dd k\cdot k^{2}=-\frac{e^{2}}{2}V\frac{k_{F}^{4}}{2\pi^{3}}
\end{align*}
From this we find:
\begin{align*}
\varepsilon^{\left(0\right)}+\varepsilon^{\left(1\right)} & \approx\left(\frac{2{,}21}{r_{s}^{2}}-\frac{0{,}916}{r_{s}}\right)E_{\text{Ry}}
\end{align*}
\textcolor{green}{TODO: Abb40}

\begin{align*}
r_{s}^{*} & =4{,}83\\
\varepsilon^{*} & =-0{,}095\cdot E_{\text{Ry}}=-1{,}29\,\text{eV}
\end{align*}
For comparison look at:
\begin{align*}
r_{s}^{\text{Na}} & =3{,}96 & \varepsilon^{\text{Na}} & =-0{,}08\,\text{Ry}=-1{,}13\,\text{eV}
\end{align*}



\subsubsection{Second order perturbation theory}

One could try to improve the result for the ground state energy by
going to second order.

\emph{Problem:} The contribution diverges!

So summation of all orders in the perturbation theory is needed. (To
achieve this, one approximates every summand and only takes the most
divergent part. To improve the result one can try to also include
the next less divergent part, and so on.)
\begin{align*}
E^{\left(2\right)} & =\sum_{\KET{\nu}\not=\KET{\text{FS}}}\frac{\BraKet{\text{FS}|\hat{V}_{ee}^{\text{jellium}}|\nu}\BraKet{\nu|\hat{V}_{ee}^{\text{jellium}}|\text{FS}}}{E^{\left(0\right)}-E_{\nu}}=E_{\text{dir}}^{\left(2\right)}+E_{\text{exchange}}^{\left(2\right)}
\end{align*}
\textcolor{green}{TODO: Abb41}

For non-vanishing contributions must hold:
\begin{enumerate}[label=\roman*)]
\item The intermediate states $\KET{\nu}$ are outside of the Fermi sphere.
\item Excited electrons must be put back in the holes left behind.
\end{enumerate}
Then holds e.g. for direct contribution:
\begin{align*}
E_{\text{dir}}^{\left(2\right)} & =\frac{1}{4V^{2}}\sum_{\KET{\nu}\not=\KET{\text{FS}}}\sum_{\vec{q}\not=0}\sum_{\vec{k},\vec{k}',\sigma,\sigma'}\frac{\tilde{v}_{ee}^{2}\left(q\right)}{E^{\left(0\right)}-E_{\nu}}\cdot\\
 & \qquad\cdot\Theta\left(\norm{\vec{k}+\vec{q}}-k_{F}\right)\Theta\left(\norm{\vec{k}'-\vec{q}}-k_{F}\right)\Theta\left(k_{F}-\norm{\vec{k}}\right)\Theta\left(k_{F}-\norm{\vec{k}'}\right)\sim\\
 & \sim\int_{0^{+}}\dd q\cdot q^{2}\frac{1}{q^{4}}\cdot\frac{1}{q}\cdot q\cdot q=\int_{0^{+}}\dd q\frac{1}{q}\approx\lim_{\varepsilon\searrow0}\ln\left(q\right)
\end{align*}
So we have logarithmic divergence, which is very bad $\ldots$


\section{Mean field approximation}

The Idea is:

\textcolor{green}{TODO: Abb42}

The individual particle interacts with an average background, depending
usually on the density. So we get an \emph{effective} single particle
theory.


\subsubsection*{Basic concepts of mean field theory}

Consider two kinds of particles described by the operators $\hat{a}_{\mu}$
and $\hat{b}_{\nu}$ respectively.
\begin{enumerate}[label=\roman*)]
\item Assume the interacting Hamiltonian as
\begin{align*}
\hat{H} & =\hat{H}_{0}+\hat{V}_{\text{int}}
\end{align*}
with:
\begin{align*}
\hat{H}_{0} & =\sum_{\mu}\varepsilon_{\mu}\hat{a}_{\mu}^{\dagger}\hat{a}_{\mu}+\sum_{\nu}\varepsilon_{\nu}\hat{b}_{\nu}^{\dagger}\hat{b}_{\nu}\\
\hat{V}_{\text{int}} & =\sum_{\nu,\nu',\mu,\mu'}v_{\nu\mu\nu'\mu'}\hat{a}_{\nu}^{\dagger}\hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\hat{a}_{\nu'}
\end{align*}

\item Define now with the average $\left\langle .\right\rangle $:
\begin{align*}
\hat{d}_{\nu\nu'} & =\hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}-\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \\
\hat{e}_{\nu\nu'} & =\hat{b}_{\nu}^{\dagger}\hat{b}_{\nu'}-\left\langle \hat{b}_{\nu}^{\dagger}\hat{b}_{\nu'}\right\rangle 
\end{align*}
This gives:
\begin{align*}
\hat{V}_{\text{int}} & =\sum_{\nu,\nu',\mu,\mu'}v_{\nu\mu\nu'\mu'}\left(\left(\hat{d}_{\nu\nu'}+\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \right)\left(\hat{e}_{\mu\mu'}+\left\langle \hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\right\rangle \right)\right)=\\
 & =\sum_{\nu,\nu',\mu,\mu'}v_{\nu\mu\nu'\mu'}\Bigg(\underbrace{\hat{d}_{\nu\nu'}\hat{e}_{\mu\mu'}}_{\text{interaction part}}+\underbrace{\hat{d}_{\nu\nu'}\left\langle \hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\right\rangle +\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \hat{e}_{\mu\mu'}+\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \left\langle \hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\right\rangle }_{\text{only single-particle operators}}\Bigg)
\end{align*}
The mean field approximation amounts to neglecting the interaction
part.
\begin{align}
\hat{V}_{\text{int}} & \approx\hat{V}_{\text{MF}}=\sum_{\nu,\nu',\mu,\mu'}v_{\nu\mu\nu'\mu'}\left(\hat{d}_{\nu\nu'}\left\langle \hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\right\rangle +\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \hat{e}_{\mu\mu'}+\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \left\langle \hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\right\rangle \right)
\end{align}
Looking at $\hat{V}_{\text{MF}}$, we can formulate the mean field
procedure in a simple way. If the interaction is the product of two
operators $\hat{A}$ and $\hat{B}$, then follows:
\begin{align*}
\hat{H}_{AB} & =\hat{A}\hat{B}\\
\Rightarrow\qquad\hat{H}_{\text{MF},AB} & =\hat{A}\left\langle \hat{B}\right\rangle +\left\langle \hat{A}\right\rangle \hat{B}-\left\langle \hat{A}\right\rangle \left\langle \hat{B}\right\rangle 
\end{align*}
The subtraction ensures the correct average:
\begin{align*}
\left\langle \hat{H}_{\text{MF},AB}\right\rangle  & =\left\langle \hat{A}\right\rangle \left\langle \hat{B}\right\rangle 
\end{align*}
\emph{Note}: 
\begin{align*}
\left\langle \hat{V}_{\text{MF}}\right\rangle  & =\sum_{\nu,\nu',\mu,\mu'}v_{\nu\mu\nu'\mu'}\left\langle \hat{a}_{\mu}^{\dagger}\hat{a}_{\nu'}\right\rangle \left\langle \hat{b}_{\mu}^{\dagger}\hat{b}_{\mu'}\right\rangle 
\end{align*}
This would be the exact form, if the two systems would not be interacting.\end{enumerate}
\begin{itemize}
\item How to find the averages?\\
In general we should understand $\left\langle .\right\rangle $ as
being related to the mean field Hamiltonian itself $\hat{H}_{\text{MF}}=\hat{H}_{0}+\hat{V}_{\text{MF}}$,
i.e. for a system in thermal equilibrium:
\begin{align*}
\left\langle \hat{A}\right\rangle  & =\frac{1}{Z_{\text{MF}}}\text{tr}\left(e^{-\hat{\beta}\hat{H}_{\text{MF}}}\hat{A}\right)
\end{align*}
One has to solve a \emph{self-consistent problem}. In other words
to evaluate $\overline{n}_{\nu\nu'}^{a}:=\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle $
we need a self-consistency loop:
\begin{align*}
\overline{n}_{\nu\nu'}^{a} & \to\hat{H}_{\text{MF}}\to\overline{n}_{\nu\nu'}^{a}\to\ldots
\end{align*}

\item The problem is that the self-consistent procedure might still be intractable
for a large number of particles.\\
In practice one has to \emph{assume} something about the averages
$\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle $.\\
\emph{Example}: Use symmetry arguments or look at zero temperature
properties or do something else $\ldots$
\item \emph{Hartree-Fock approximation} (alike particles):
\begin{align*}
\hat{H} & =\hat{H}_{0}+\hat{V}_{\text{int}}\\
\hat{H}_{0} & =\sum_{\mu}\varepsilon_{\mu}\hat{a}_{\mu}^{\dagger}\hat{a}_{\mu}\\
\hat{V}_{\text{int}} & =\sum_{\mu,\nu,\mu',\nu'}\hat{a}_{\nu}^{\dagger}\hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}\hat{a}_{\nu'}
\end{align*}

\item \emph{Mean field approximation}:
\begin{align}
\hat{a}_{\nu}^{\dagger}\hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}\hat{a}_{\nu'} & \approx\hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\left\langle \hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}\right\rangle +\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}-\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\nu'}\right\rangle \left\langle \hat{a}_{\mu}^{\dagger}\hat{a}_{\mu'}\right\rangle \pm\nonumber \\
 & \underbrace{\pm}_{\text{bosons/fermions}}\left(\hat{a}_{\nu}^{\dagger}\hat{a}_{\mu'}\left\langle \hat{a}_{\mu}^{\dagger}\hat{a}_{\nu'}\right\rangle +\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\mu'}\right\rangle \hat{a}_{\mu}^{\dagger}\hat{a}_{\nu'}-\left\langle \hat{a}_{\nu}^{\dagger}\hat{a}_{\mu'}\right\rangle \left\langle \hat{a}_{\mu}^{\dagger}\hat{a}_{\nu'}\right\rangle \right)=\\
 & =:\text{Hartree}\pm\underbrace{\text{Fock}}_{\text{exchange part for alike particles}}\nonumber 
\end{align}

\item \emph{Hartree-Fock for the interacting electron gas}:
\begin{align*}
\hat{T}+\hat{V}_{ee}^{\text{jellium}} & =\sum_{\vec{k},\sigma}\varepsilon_{\vec{k}}\hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}+\frac{1}{2V}\sum_{\vec{q}\not=0}\sum_{\vec{k},\vec{k}',\sigma,\sigma'}\tilde{v}_{ee}\left(q\right)\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\hat{a}_{\vec{k},\sigma}
\end{align*}
%DATE: Di 22.01.13\\
In the Hartree-Fock approximation holds:
\begin{align*}
 & \hat{V}_{ee}^{\text{jellium}}\approx\hat{V}_{ee,\text{MF}}^{\text{jellium}}=\\
 & =\frac{1}{2V}\sum_{\vec{q}\not=0}\sum_{\vec{k},\vec{k}',\sigma,\sigma'}\tilde{v}_{ee}\left(q\right)\Bigg(\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle \hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}+\\
 & \qquad-\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\left\langle \hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\right\rangle -\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle \left\langle \hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\right\rangle -\\
 & \qquad-\bigg(\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\right\rangle \hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}+\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\right\rangle \hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}-\\
 & \qquad-\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}',\sigma'}\right\rangle \left\langle \hat{a}_{\vec{k}'-\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle \bigg)\Bigg)
\end{align*}


\begin{itemize}
\item Translational invariance yields:
\begin{align*}
\left\langle \hat{a}_{\vec{k}}^{\dagger}\hat{a}_{\vec{k}'}\right\rangle  & =\frac{1}{V}\int\dd^{3}r\int\dd^{3}r'e^{\ii\vec{k}\cdot\vec{r}}e^{-\ii\vec{k}'\cdot\vec{r}'}\underbrace{\left\langle \hat{a}_{\vec{k}}^{\dagger}\left(\vec{r}\right)\hat{a}_{\vec{k}'}\left(\vec{r}'\right)\right\rangle }_{=f\left(\vec{r}-\vec{r}'\right)}=\\
 & \stackrel{\vec{R}=\vec{r}+\vec{r}'}{=}\frac{1}{V}\int\dd^{3}R\int\dd^{3}r'e^{\ii\left(\vec{k}-\vec{k}'\right)\cdot\vec{R}}e^{\ii\left(\vec{k}'\vec{r}-\vec{k}\cdot\vec{r}'\right)}f\left(\vec{R}-2\vec{r}'\right)=\\
 & =\frac{1}{V}\int\dd^{3}r'\delta_{\vec{k},\vec{k}'}e^{\ii\left(\vec{k}'\vec{r}-\vec{k}\cdot\vec{r}'\right)}f\left(\vec{R}-2\vec{r}'\right)=\\
 & =\stackrel{\vec{r}''=\vec{R}-2\vec{r'}}{=}\delta_{\vec{k},\vec{k}'}\frac{1}{V}\int\dd^{3}r''f\left(\vec{r}''\right)=\left\langle \hat{n}_{\vec{k}}\right\rangle \delta_{\vec{k},\vec{k}'}
\end{align*}

\item Assume spin-independence of the interaction (otherwise ferromagnetic
solutions are possible):
\begin{align*}
\left\langle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle  & =\left\langle \hat{a}_{\vec{k},-\sigma}\hat{a}_{\vec{k},-\sigma}^{\dagger}\right\rangle 
\end{align*}

\item The Coulomb interaction only depends on the distance:
\begin{align*}
v_{ee}\left(\vec{r}\right) & =v_{ee}\left(r\right)\\
\Rightarrow\qquad\tilde{v}_{ee}\left(\vec{q}\right) & =\tilde{v}_{ee}\left(q\right)=\tilde{v}_{ee}\left(-q\right)
\end{align*}

\end{itemize}

Due to the $\delta_{\vec{k},\vec{k}'}$ and $\vec{q}\not=0$ the Hartree
term vanishes and we get:
\begin{align*}
\hat{V}_{ee,\text{MF}}^{\text{jellium}} & =-\frac{1}{2V}\sum_{\vec{q}\not=0}\sum_{\vec{k},\sigma}\tilde{v}_{ee}\left(q\right)\bigg(\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}+\vec{q},\sigma}\right\rangle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}+\\
 & \qquad+\hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}+\vec{q},\sigma}\left\langle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle -\left\langle \hat{a}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{k}+\vec{q},\sigma}\right\rangle \left\langle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle \bigg)
\end{align*}
Now substitute $\vec{k}+\vec{q}=\vec{q}'$ and write again $\vec{q}$
for $\vec{q}'$.
\begin{align*}
\hat{V}_{ee,\text{MF}}^{\text{jellium}} & =-\frac{1}{2V}\sum_{\vec{q}\not=0}\sum_{\vec{k},\sigma}\tilde{v}_{ee}\left(\vec{q}-\vec{k}\right)\bigg(\left\langle \hat{a}_{\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{q},\sigma}\right\rangle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}+\\
 & \qquad+\hat{a}_{\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{q},\sigma}\left\langle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle -\left\langle \hat{a}_{\vec{q},\sigma}^{\dagger}\hat{a}_{\vec{q},\sigma}\right\rangle \left\langle \hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}\right\rangle \bigg)
\end{align*}
From $\tilde{v}_{ee}\left(\vec{q}\right)=\tilde{v}_{ee}\left(-\vec{q}\right)$
we get:\stepcounter{equation}
\begin{align}
\fbox{\ensuremath{{\displaystyle \hat{V}_{ee,\text{MF}}^{\text{jellium}}=\sum_{\vec{k},\sigma}v_{\text{HF}}\left(\vec{k}\right)\hat{a}_{\vec{k},\sigma}^{\dagger}\hat{a}_{\vec{k},\sigma}-2\sum_{\vec{k},\sigma}v_{\text{HF}}\left(\vec{k}\right)n\left(\vec{k}\right)n_{\vec{k},\sigma}}}}\tag{\arabic{chapter}.\arabic{equation}a}
\end{align}
\begin{align}
v_{\text{HF}}\left(\vec{k}\right) & =-\frac{1}{V}\sum_{\vec{q}\not=\vec{k}}\tilde{v}_{ee}\left(\vec{q}-\vec{k}\right)n_{\vec{q},\sigma}
\end{align}
All together gives:\addtocounter{equation}{-1}
\begin{align}
\hat{T}_{e}+\hat{V}_{ee,\text{MF}}^{\text{jellium}} & =\sum_{\vec{k},\sigma}\left(\varepsilon_{\vec{k}}+v_{\text{HF}}\left(\vec{k}\right)\right)\hat{n}_{\vec{k},\sigma}+\text{const.}\tag{\arabic{chapter}.\arabic{equation}b}
\end{align}
\stepcounter{equation}Consider the Hartree-Fock contribution at $T=0$
and assume.
\begin{align*}
n_{\vec{k},\sigma} & =\Theta\left(k_{F}-k\right)
\end{align*}
This is appropriate for fermions if $v_{\text{HF}}\left(k\right)$
is a monotonously increasing function of $k$. Then follows:
\begin{align*}
v_{\text{HF}}\left(\vec{k}\right) & =-\frac{1}{V}\sum_{\vec{q}\not=\vec{k}}\tilde{v}_{ee}\left(\vec{q}-\vec{k}\right)\Theta\left(k_{F}-q\right)=\\
 & =-\frac{4\pi e^{2}}{\left(2\pi\right)^{3}}2\pi\int_{0}^{k_{F}}\dd q\cdot q^{2}\int_{-1}^{1}\frac{\dd\left(\cos\theta_{q}\right)}{k^{2}+q^{2}-2qk\cos\theta_{q}}
\end{align*}
With
\begin{align*}
\int_{-1}^{1}\frac{\dd\mu}{1+a\mu} & =\frac{1}{a}\ln\abs{\frac{1+a}{1-a}}
\end{align*}
this gives the exchange energy of an electron with $\vec{k},\sigma$:
\begin{align}
v_{\text{HF}}\left(\vec{k}\right) & =-e^{2}\frac{k_{F}}{\pi}\left(1+\frac{k_{F}^{2}-k^{2}}{2k_{F}k}\ln\abs{\frac{k+k_{F}}{k-k_{F}}}\right)
\end{align}
It can be rewritten as:
\begin{align*}
v_{\text{HF}}\left(\vec{k}\right) & =\frac{e^{2}k_{F}}{\pi}S\left(\frac{k}{k_{F}}\right)
\end{align*}
\begin{align*}
S\left(y\right) & =-\left(1+\frac{1-y^{2}}{2y}\ln\abs{\frac{1+y}{1-y}}\right)
\end{align*}
\textcolor{green}{TODO: Abb43 ,Plot $S\left(y\right)$}
\begin{align*}
S\left(1\right) & =-1 & \frac{\dd S\left(y\right)}{\dd y}\bigg|_{y=1} & \to\infty
\end{align*}


\end{itemize}

\subsubsection{Consequences}
\begin{enumerate}
\item We can calculate the ground state energy within the Hartree-Fock approximation.
The exchange contribution is:
\begin{align*}
E_{\text{G},\text{HF}} & =\frac{V}{\left(2\pi\right)^{3}}\sum_{\sigma}\int\dd\vec{k}v_{\text{HF}}\left(k\right)n_{\vec{k},\sigma}=N\cdot\left(-\frac{3}{4}\frac{e^{2}k_{F}}{\pi}\right)
\end{align*}
This is precisely the same correction as from the first order perturbation
theory.
\begin{align*}
\varepsilon_{\text{G,HF}} & =\frac{E_{\text{G,HF}}}{N}=-\frac{0,916}{r_{s}}\, E_{\text{Ry}}
\end{align*}

\item The fact that $\frac{\dd S\left(y\right)}{\dd y}$ diverges for $y=1$
(i.e. at the Fermi level), implies that the density of states vanishes
at $\varepsilon_{F}$, which is unphysical. In fact holds:
\begin{align*}
\mathcal{D}\left(\varepsilon\right) & =\sum_{\vec{k},\sigma}\delta\bigg(\varepsilon-\underbrace{\left(\varepsilon_{\vec{k}}+v_{\text{HF}}\left(\vec{k}\right)\right)}_{=\varepsilon_{\text{tot}}\left(\vec{k}\right)}\bigg)=\frac{V}{\pi^{2}}\int_{0}^{\infty}\dd k\cdot k^{2}\delta\left(\varepsilon-\varepsilon_{\text{tot}}\left(k\right)\right)=\\
 & =\frac{V}{\pi^{2}}k^{2}\left(\varepsilon\right)\left(\frac{\dd\varepsilon_{\text{tot}}\left(k\right)}{\dd k}\right)^{-1}
\end{align*}
We had already shown for free electron gas:
\begin{align*}
C_{V} & \sim\mathcal{D}_{0}\left(\varepsilon_{F}\right)
\end{align*}
This can be measured not to vanish.\\
The reason for this problem is the divergence of the $\frac{1}{r}$-Coulomb
repulsion of the electrons.
\end{enumerate}

\subsubsection{Conclusion}

We need theories that go beyond first order perturbation theory or
Hartree-Fock. Such theories should at least account for screening
effects in the interacting gas. With screening, the Coulomb interaction
gets renormalized and no divergence at $q=0$ anymore.


\section{Dielectric properties and screening}

Let us consider the effect of an external electromagnetic potential
$\varphi_{\text{ext}}$ on the interacting electron gas. One consequence
is that a charge density is induced in the system:
\begin{align}
\varrho_{e,\text{ind}}\left(\vec{r},t\right) & =e\varrho\left(\vec{r},t\right)=\int\dd^{3}r'\int_{t_{0}}^{\infty}\dd t'\chi^{R}\left(\vec{r},t;\vec{r}',t'\right)\varphi_{\text{ext}}\left(\vec{r}',t'\right)
\end{align}
$\chi^{R}\left(\vec{r},t;\vec{r}',t'\right)$ is the polarizability
function also called response function. $t_{0}$ is the time, at which
the perturbation started.\\
Once the induced charge is know, the induced potential follows:
\begin{align*}
\varphi_{\text{ind}}\left(\vec{r},t\right) & =\int\dd^{3}r'u_{ee}\left(\vec{r}-\vec{r}'\right)\varrho_{e,\text{ind}}\left(\vec{r}',t\right)\\
u_{ee}\left(\vec{r},t\right) & =\frac{v_{ee}\left(\vec{r}\right)}{e^{2}}\stackrel{\text{SI units}}{=}\frac{1}{4\pi\varepsilon_{0}\norm{\vec{r}}}
\end{align*}
Hence the total potential is:
\begin{align*}
\varphi_{\text{tot}}\left(\vec{r},t\right) & =\varphi_{\text{ext}}\left(\vec{r},t\right)+\varphi_{\text{ind}}\left(\vec{r},t\right)=\\
 & =\varphi_{\text{ext}}\left(\vec{r},t\right)+\int\dd^{3}r'\int\dd^{3}r''\int\dd t'u_{ee}\left(\vec{r}-\vec{r}'\right)\chi^{R}\left(\vec{r}',t;\vec{r}'',t'\right)\varphi_{\text{ext}}\left(\vec{r}'',t'\right)=\\
 & =\int\dd^{3}r''\int\dd t'\varepsilon^{-1}\left(\vec{r},t;\vec{r}'',t'\right)\varphi_{\text{ext}}\left(\vec{r}'',t'\right)
\end{align*}
Here $\varepsilon$ is the dielectric function and it follows:
\begin{align*}
\varepsilon^{-1}\left(\vec{r},t;\vec{r'},t'\right) & =\delta\left(\vec{r}-\vec{r}'\right)\delta\left(t-t'\right)+\int\dd^{3}r''u_{ee}\left(\vec{r}-\vec{r}''\right)\chi^{R}\left(\vec{r}'',t;\vec{r}',t'\right)
\end{align*}
\begin{align}
\Rightarrow\qquad\fbox{\ensuremath{{\displaystyle \widetilde{\varepsilon^{-1}}\left(\vec{q},\omega\right)=1+\tilde{u}_{ee}\left(q\right)\tilde{\chi}^{R}\left(\vec{q},\omega\right)}}}
\end{align}
\begin{align*}
\tilde{u}_{ee}\left(q\right) & =\frac{1}{\varepsilon_{0}q^{2}}
\end{align*}
This holds for system which are homogeneous in space and time.\\
$\varepsilon^{-1}$ is experimentally and $\tilde{\chi}^{R}$ is theoretically
accessible.

In total we get:
\begin{align*}
\tilde{\varphi}_{\text{tot}} & =\widetilde{\varepsilon^{-1}}\tilde{\varphi}_{\text{ext}}
\end{align*}


%DATE: Fr 25.01.13


\subsection{Linear response theory}

The linear response theory is based on the idea that the response
of a system to a weak perturbation, proportional to the perturbation
itself, can be calculated to the \emph{lowest} order in the perturbation.


\subsubsection*{Example}

The conductivity tensor $\sigma$ is independent of $\tilde{\vec{E}}$.
\begin{align*}
\tilde{\vec{j}} & =\tilde{\sigma}\tilde{\vec{E}}
\end{align*}
So we have:
\begin{align*}
\tilde{\varrho}_{e,\text{ind}} & =\tilde{\chi}^{R}\tilde{\varphi}_{\text{ext}}
\end{align*}
The susceptibility $\tilde{\chi}^{R}$ is independent of $\tilde{\varphi}_{\text{ext}}$.
This allows to evaluate non-equilibrium quantities $\left(\tilde{\vec{j}},\tilde{\varrho}_{e,\text{ind}}\right)$
by looking at equilibrium functions $\left(\tilde{\sigma},\tilde{\chi}^{R},\ldots\right)$.


\subsubsection*{Formally}

Given an external perturbation $\hat{H}_{\text{ext}}$, what is the
expectation value $\left\langle \hat{A}\right\rangle $ of a given
operator $\hat{A}$ to \emph{linear order} in $\hat{H}_{\text{ext}}$?

Suppose that at time $t_{0}$ the external perturbation is applied
to the system, driving it out of equilibrium.
\begin{align*}
\hat{H}\left(t\right) & =\hat{H}_{0}+\hat{H}_{\text{ext}}\left(t\right)\Theta\left(t-t_{0}\right)
\end{align*}


\textcolor{green}{TODO: Abb44}

For $t<t_{0}$ we have thermal equilibrium and therefore:
\begin{align*}
\left\langle \hat{A}\right\rangle _{0} & =\text{tr}\left(\hat{A}\hat{\varrho}_{0}\right)=\text{tr}\left(\frac{\hat{A}}{Z}e^{-\beta\hat{H}_{0}}\right)
\end{align*}
For $t>t_{0}$ we have:
\begin{align*}
\left\langle \hat{A}\left(t\right)\right\rangle  & =\text{tr}\left(\hat{A}\hat{\varrho}\left(t\right)\right)=?
\end{align*}
We consider $\hat{H}_{\text{ext}}$ as a weak perturbation, so that
it is convenient to work in deviations from equilibrum. We solve the
Liouville-von Neumann equation for $\hat{\varrho}\left(t\right)=\hat{\varrho}_{0}+\Delta\hat{\varrho}\left(t\right)$.
\begin{align*}
\dot{\hat{\varrho}}\left(t\right) & =-\frac{\ii}{\hbar}\left[\hat{H}\left(t\right),\hat{\varrho}\left(t\right)\right]=-\frac{\ii}{\hbar}\left[\hat{H}_{0},\Delta\varrho\left(t\right)\right]+\frac{\ii}{\hbar}\left[\hat{\varrho}_{0},\hat{H}_{\text{ext}}\left(t\right)\right]+o_{0}\left(\hat{H}\right)
\end{align*}
This gives:
\begin{align*}
\ii\Delta\dot{\hat{\varrho}}\left(t\right)-\frac{1}{\hbar}\left[\hat{H}_{0},\Delta\varrho\left(t\right)\right] & \approx-\frac{1}{\hbar}\left[\hat{\varrho}_{0},\hat{H}_{\text{ext}}\left(t\right)\right]
\end{align*}
The differential equation is solved by expressing the left hand side
as:
\begin{align*}
e^{-\frac{\ii}{\hbar}\hat{H}_{0}t}\left(\ii\frac{\dd}{\dd t}\left(e^{\frac{\ii}{\hbar}\hat{H}_{0}t}\Delta\hat{\varrho}\left(t\right)e^{-\frac{\ii}{\hbar}\hat{H}_{0}t}\right)\right)e^{\frac{\ii}{\hbar}\hat{H}_{0}t} & =-\frac{1}{\hbar}\left[\hat{\varrho}_{0},\hat{H}_{\text{ext}}\left(t\right)\right]\\
\ii\frac{\dd}{\dd t}\left(e^{\frac{\ii}{\hbar}\hat{H}_{0}t}\Delta\hat{\varrho}\left(t\right)e^{-\frac{\ii}{\hbar}\hat{H}_{0}t}\right) & =-e^{\frac{\ii}{\hbar}\hat{H}_{0}t}\frac{1}{\hbar}\left[\hat{\varrho}_{0},\hat{H}_{\text{ext}}\left(t\right)\right]e^{-\frac{\ii}{\hbar}\hat{H}_{0}t}=-\frac{1}{\hbar}\left[\hat{\varrho}_{0},\hat{H}_{\text{ext},I}\left(t\right)\right]\\
\Delta\hat{\varrho}_{I}\left(t\right)-\Delta\hat{\varrho}_{I}\left(t_{0}\right) & =-\frac{\ii}{\hbar}\int_{t_{0}}^{t}\dd t'\left[\hat{H}_{\text{ext},I}\left(t'\right),\hat{\varrho}_{0}\right]
\end{align*}
Using the cyclic invariance of the trace we get the \emph{Kubo formula}:
\begin{align}
\delta\left\langle \hat{A}\left(t\right)\right\rangle  & =\left\langle \hat{A}\left(t\right)\right\rangle -\left\langle \hat{A}\right\rangle _{0}=\int_{t_{0}}^{\infty}\dd t'C_{\hat{A},\hat{H}_{\text{ext}}}^{R}\left(t,t'\right)\\
C_{\hat{A},\hat{H}_{\text{ext}}}^{R}\left(t,t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\left\langle \left[\hat{A}_{I}\left(t\right),\hat{H}_{\text{ext},I}\left(t'\right)\right]\right\rangle _{0}
\end{align}
The correlation function $C_{\hat{A},\hat{H}_{\text{ext}}}^{R}\left(t,t'\right)$
is called \emph{response function}.

$\left\langle .\right\rangle _{0}$ means that we take the zeroth
order expectation value. The $^{R}$ means, that it is a \emph{retarded}
correlation function, which ensures causality. The $_{I}$ stands
for the interaction representation.
\begin{itemize}
\item The inherent non-equilibrium quantity $\delta\left\langle \hat{A}\left(t\right)\right\rangle $
is expressed as a \emph{retarded} correlation function of the system
in equilibrium.
\item $\Theta\left(t-t'\right)$ expresses the causality of the solution,
which is why we call it retarded correlation function.
\end{itemize}

\subsubsection*{Kubo formula in the frequency domain}

Consider the case in which the external Hamiltonian is
\begin{align*}
\hat{H}_{\text{ext}}\left(t\right) & =\hat{B}\cdot f\left(t\right)
\end{align*}
with a constant operator $\hat{B}$ and a time-dependent element $f\left(t\right)\in\mathbb{C}$.
Then follows:
\begin{align*}
\delta\left\langle \hat{A}\left(t\right)\right\rangle  & =\left\langle \hat{A}\left(t\right)\right\rangle -\left\langle \hat{A}\right\rangle _{0}=-\frac{\ii}{\hbar}\int_{t_{0}}^{\infty}\dd t'\left\langle \left[\hat{A}_{I}\left(t\right),\hat{B}_{I}\left(t'\right)\right]\right\rangle _{0}f\left(t'\right)\Theta\left(t-t'\right)\\
\end{align*}
With
\begin{align*}
C_{\hat{A},\hat{B}}^{R}\left(t,t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\left\langle \left[\hat{A}_{I}\left(t\right),\hat{B}_{I}\left(t'\right)\right]\right\rangle _{0}\sr ={\text{cyclic invariance}}{\text{of the trace}}C_{\hat{A},\hat{B}}^{R}\left(t-t'\right)
\end{align*}
then follows for $t_{0}=-\infty$:
\begin{align*}
\delta\left\langle \tilde{\hat{A}}\left(\omega\right)\right\rangle  & =\int_{-\infty}^{\infty}\dd te^{\ii\omega t}\delta\left\langle \hat{A}\left(t\right)\right\rangle =\tilde{C}_{\hat{A},\hat{B}}^{R}\left(\omega\right)\tilde{f}\left(\omega\right)
\end{align*}
We note that the usual definition of the Fourier transform is:
\begin{align*}
\tilde{C}_{\hat{A},\hat{B}}^{R}\left(\omega\right) & =\int_{-\infty}^{\infty}\dd te^{\ii\omega t}C_{\hat{A},\hat{B}}^{R}\left(t\right)
\end{align*}
In order for the Fourier transform to be well defined, the integrand
must decay for both plus and minus infinity. For retarded functions
as
\begin{align*}
C_{\hat{A},\hat{B}}^{R}\left(t-t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\left\langle \left[\hat{A}_{I}\left(t\right),\hat{B}_{I}\left(t'\right)\right]\right\rangle _{0}
\end{align*}
that are zero at negative times, only $+\infty$ can cause a problem.
It is then usual to define the Fourier transform as:
\begin{align*}
\tilde{C}_{\hat{A},\hat{B}}^{R}\left(\omega\right) & =\lim_{\eta\searrow0}\int_{-\infty}^{\infty}\dd te^{\ii\omega t}e^{-\eta t}C_{\hat{A},\hat{B}}^{R}\left(t\right)
\end{align*}
Consider a position dependent external perturbation given by:
\begin{align*}
\hat{H}_{\text{ext}}\left(t\right) & =\int\dd^{3}r\hat{B}\left(\vec{r}\right)f\left(\vec{r},t\right)
\end{align*}
In this case one finds:
\begin{align*}
\delta\left\langle \tilde{\hat{A}}\left(\omega\right)\right\rangle  & =\int\dd^{3}r\tilde{C}_{\hat{A},\hat{B}\left(\vec{r}\right)}^{R}\tilde{f}\left(\vec{r},\omega\right)
\end{align*}



\subsubsection*{Example \textmd{(Kubo formula for the dielectric function)}}

The external perturbation is:
\begin{align*}
\hat{H}_{\text{ext}} & =\int\dd^{3}r\hat{\varrho}_{e}\left(\vec{r}\right)\varphi_{\text{ext}}\left(\vec{r},t\right)
\end{align*}
The induced charge is:
\begin{align*}
\left\langle \hat{\varrho}_{e,\text{ind}}\right\rangle  & =\left\langle \hat{\varrho}_{e}\right\rangle -\left\langle \hat{\varrho}_{e}\right\rangle _{0}
\end{align*}
This gives:
\begin{align*}
\left\langle \hat{\varrho}_{e,\text{ind}}\right\rangle  & =\varrho_{e,\text{ind}}=\int\dd^{3}r'\int_{t_{0}}^{\infty}\dd t'C_{\varrho_{e}\left(\vec{r}\right),\varrho_{e}\left(\vec{r}'\right)}^{R}\left(t,t'\right)\varphi_{\text{ext}}\left(\vec{r}',t'\right)\\
C_{\varrho_{e}\left(\vec{r}\right),\varrho_{e}\left(\vec{r}'\right)}^{R}\left(t,t'\right) & =\chi^{R}\left(\vec{r},t,\vec{r}',t'\right)=-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\left\langle \left[\hat{\varrho}_{e,I}\left(\vec{r},t\right),\hat{\varrho}_{e,I}\left(\vec{r}',t'\right)\right]\right\rangle _{0}
\end{align*}
$\chi^{R}$ is the \emph{density-density correlation function}.

\emph{Note}: For the electron gas holds:
\begin{align}
\chi^{R}\left(\vec{r},t,\vec{r}',t'\right) & =\chi^{R}\left(\vec{r}-\vec{r}',t-t'\right)\nonumber \\
\Rightarrow\qquad\tilde{\chi}^{R}\left(\vec{q},\omega\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\frac{1}{V}\left\langle \left[\tilde{\hat{\varrho}}_{e,I}\left(\vec{q},t\right),\tilde{\hat{\varrho}}_{e,I}\left(-\vec{q},t'\right)\right]\right\rangle _{0}
\end{align}
\noun{(}cf. \noun{Bruus} and \noun{Flensberg}, chapter 8.5)

To proceed, we need to know how to evaluate the time evolution of
operators in second quantization!


\subsection{Time dependence of operators in second quantization}

In second quantization one deals with operators. Hence also the time
evolution is as given in the Heisenberg representation, where the
Heisenberg equations hold. Specifically, for a time independent Hamiltonian
$\hat{H}$, a given operator $\hat{A}\left(t\right)$ has to obey:
\begin{align}
\dot{\hat{A}}\left(t\right) & =\frac{\ii}{\hbar}\left[\hat{H},\hat{A}\left(t\right)\right]+\left(\partial_{t}\hat{A}\right)\left(t\right)
\end{align}
Here $\dot{\hat{A}}$ is the time derivative in the Heisenberg picture
and $\partial_{t}A$ is the time derivative in the Schrödinger picture.


\subsubsection*{Example}

\begin{align*}
\hat{H} & =\sum_{\nu}\varepsilon_{\nu}\hat{a}_{\nu}^{\dagger}\hat{a}_{\nu}
\end{align*}
The equation of motion is:
\begin{align*}
\hat{a}_{\nu}\left(t\right) & :=e^{\ii\hat{H}\frac{t}{\hbar}}\hat{a}_{\nu}e^{-\hat{H}\frac{t}{\hbar}}\\
\hat{a}_{\nu}^{\dagger}\left(t\right) & :=e^{\ii\hat{H}\frac{t}{\hbar}}\hat{a}_{\nu}^{\dagger}e^{-\hat{H}\frac{t}{\hbar}}
\end{align*}
We simply have to use these equations and the form of the Hamiltonian
to get:
\begin{align*}
\dot{\hat{a}}_{\nu}\left(t\right) & =\frac{\ii}{\hbar}\left[\hat{H},\hat{a}_{\nu}\left(t\right)\right]=\frac{\ii}{\hbar}e^{\ii\hat{H}\frac{t}{\hbar}}\left[\hat{H},\hat{a}_{\nu}\right]e^{-\ii\hat{H}\frac{t}{\hbar}}=\\
 & =\frac{\ii}{\hbar}e^{\ii\hat{H}\frac{t}{\hbar}}\sum_{\nu'}\varepsilon_{\nu'}\underbrace{\left[\hat{a}_{\nu'}^{\dagger}\hat{a}_{\nu},\hat{a}_{\nu}\right]}_{=-\delta_{\nu\nu'}\hat{a}_{\nu'}}e^{-\ii\hat{H}\frac{t}{\hbar}}=-\frac{\ii}{\hbar}\varepsilon_{\nu}\hat{a}_{\nu}\left(t\right)
\end{align*}
This yields:

\begin{framed}
\begin{align}
\hat{a}_{\nu}\left(t\right) & =e^{-\frac{\ii}{\hbar}\varepsilon_{\nu}t}\hat{a}_{\nu}\\
\left[\hat{a}_{\nu_{1}}\left(t_{1}\right),\hat{a}_{\nu_{2}}^{\dagger}\left(t_{2}\right)\right] & =e^{-\frac{\ii}{\hbar}\varepsilon_{\nu_{1}}\left(t_{1}-t_{2}\right)}\delta_{\nu_{1}\nu_{2}}
\end{align}
\end{framed}


\subsection{Susceptibility of non-interacting electron gas}

To start with, we evaluate the susceptibility $\tilde{\chi}^{R}$
for the non-interacting electron gas. We denote it by $\tilde{\chi}_{0}^{R}$.
\begin{align*}
\tilde{\chi}^{R}\left(\vec{q},t-t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\left\langle \left[\tilde{\hat{\varrho}}_{e,I}\left(\vec{q},t\right),\tilde{\hat{\varrho}}_{e,I}\left(-\vec{q},t\right)\right]\right\rangle _{0}\\
\hat{H}_{0} & =\sum_{\vec{k},\sigma}\varepsilon_{\vec{k}}\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k},\sigma}
\end{align*}
\begin{align*}
\Rightarrow\qquad\tilde{\hat{\varrho}}_{e}\left(\vec{q},t\right) & =-e\sum_{\vec{k},\sigma}\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}e^{-\frac{\ii}{\hbar}\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)t}
\end{align*}
Hence follows:
\begin{align*}
\tilde{\chi}_{0}^{R}\left(\vec{q},t-t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\frac{e^{2}}{V}\sum_{\vec{k},\vec{k}',\sigma,\sigma'}\left\langle \left[\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma},\hat{c}_{\vec{k}',\sigma'}^{\dagger}\hat{c}_{\vec{k}'-\vec{q},\sigma'}\right]\right\rangle _{0}\cdot\\
 & \qquad\cdot e^{\frac{\ii}{\hbar}\left(\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)t+\right)}e^{\frac{\ii}{\hbar}\left(\varepsilon_{\vec{k}'}-\varepsilon_{\vec{k}'-\vec{q}}\right)t'}
\end{align*}
With
\begin{align*}
\left[\hat{c}_{\nu}^{\dagger}\hat{c}_{\mu},\hat{c}_{\nu'}^{\dagger}\hat{c}_{\mu'}\right] & =\hat{c}_{\nu}^{\dagger}\hat{c}_{\mu'}\delta_{\mu\nu'}-\hat{c}_{\nu'}^{\dagger}\hat{c}_{\mu}\delta_{\nu'\mu}
\end{align*}
\begin{align*}
\left\langle \hat{c}_{\vec{k}}^{\dagger}\hat{c}_{\vec{k}}\right\rangle _{0} & =\left\langle \hat{n}_{\vec{k}}\right\rangle _{0}=f\left(\varepsilon_{\vec{k}}\right)
\end{align*}
one gets:
\begin{align}
\tilde{\chi}_{0}^{R}\left(\vec{q},t-t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\frac{e^{2}}{V}\sum_{\vec{k},\sigma}\left(f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)\right)e^{\frac{\ii}{\hbar}\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)\left(t-t'\right)}
\end{align}
The Fourier transformation is:
\begin{align}
\tilde{\chi}_{0}^{R}\left(\vec{q},\omega\right) & =\int_{-\infty}^{\infty}\dd\tau e^{\ii\omega\tau}\tilde{\chi}_{0}^{R}\left(\vec{q},\tau\right)e^{-\eta\tau}=\nonumber \\
 & =\frac{e^{2}}{\hbar V}\sum_{\vec{k},\sigma}\frac{f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)}{\frac{1}{\hbar}\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)+\omega+\ii\eta}
\end{align}
$\eta\searrow0$ is a convergence factor. This function is the \emph{Lindhard
function} (``the bubble''). We then have:
\begin{align*}
\tilde{\chi}_{0}^{R}\left(\vec{q},\omega\right) & =\text{Re}\left(\tilde{\chi}_{0}^{R}\right)+\ii\cdot\text{Im}\left(\tilde{\chi}_{0}^{R}\right)
\end{align*}
$\text{Re}\left(\tilde{\chi}_{0}^{R}\right)\left(\vec{q},\omega\right)$
is the principal part of the integral obtained for $\eta=0$. Using
$\text{Im}\left(\frac{1}{a+\ii\eta}\right)\to-\pi\delta\left(a\right)$
one gets:
\begin{align}
\text{Im}\left(\tilde{\chi}_{0}^{R}\right)\left(\vec{q},\omega\right) & =-\frac{\pi e^{2}}{V\hbar}\sum_{\vec{k},\sigma}\left(f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)\right)\delta\left(\frac{\varepsilon_{\vec{k}}}{\hbar}-\frac{\varepsilon_{\vec{k}+\vec{q}}}{\hbar}+\omega\right)
\end{align}
\textcolor{green}{TODO: Abb45; electron-hole excitations of free electron
gas}

%DATE: Di 29.01.13

Consider $T=0$, i.e. $f\left(\varepsilon_{k}\right)=\Theta\left(k_{F}-k\right)$,
and:
\begin{align*}
f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right) & \not=0\quad\begin{cases}
\text{if }k>k_{F}\text{ and }\abs{\vec{k}+\vec{q}}<k_{F}\quad\Rightarrow\quad\omega<0\\
\text{if }k>k_{F}\text{ and }\abs{\vec{k}+\vec{q}}>k_{F}\quad\Rightarrow\quad\omega>0
\end{cases}
\end{align*}
Moreover, conservation of energy implies for $\omega>0$ (this is
enough, since the imaginary part of $\tilde{\chi}_{0}^{R}$ is odd).
\begin{align*}
0 & <\omega=\frac{q^{2}}{2m}+\frac{\vec{k}\cdot\vec{q}}{m}
\end{align*}
The maximal and minimal values are ($q\gg k_{F}$):
\begin{align*}
\omega_{\text{max}} & =\frac{q^{2}}{2m}+v_{F}q\\
\omega_{\text{min}} & =\frac{q^{2}}{2m}-v_{F}q
\end{align*}
\textcolor{green}{TODO: Add46}

\emph{Note}: To lowest order in the electron-electron interaction
we get:
\begin{align*}
\widetilde{\varepsilon^{-1}}\left(\vec{q,}\omega\right) & =1+\tilde{u}_{ee}\left(q\right)\tilde{\chi}_{0}
\end{align*}
This quantity diverges for $q\to0$. ($\tilde{\chi}_{0}\left(\vec{q}=0,\omega=0\right)=-e^{2}\mathcal{D}\left(\varepsilon_{F}\right)$)
So at this stage, we don't get the screening.

We need to evaluate $\tilde{\chi}^{R}$ in a non perturbative way.
We use the \emph{equation of motion method} within the ``Random phase
approximation''.


\section{Random phase approximation}

The idea is to find the time evolution of the operator $\hat{\varrho}_{e,I}\left(\vec{q},t\right)$
and hence to obtain in turn $\tilde{\chi}^{R}\left(q,t-t'\right)$.


\subsubsection*{Equation of motion method applied to $\tilde{\chi}^{R}\left(\vec{q},t\right)$
and $\hat{\varrho}_{I}\left(t\right)$}

(see \noun{Bruus} and \noun{Flensberg}, chapter 9.4)

We start from the correlation function:
\begin{align*}
\tilde{\chi}^{R}\left(\vec{q,}\vec{k},\sigma,t-t'\right) & =-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\left\langle \left[\left(\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right)\left(t\right),\hat{\varrho}_{I}\left(-\vec{q},t'\right)\right]\right\rangle _{0}
\end{align*}
We consider $\ii\hbar\partial_{t}\tilde{\chi}^{R}$ and use the Schrödinger
equation for the time evolution:
\begin{align*}
\ii\hbar\partial_{t}\tilde{\chi}^{R}\left(\vec{q,}\vec{k},\sigma,t-t'\right) & =\delta\left(t-t'\right)\left\langle \left[\left(\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right)\left(t\right),\hat{\varrho}_{I}\left(-\vec{q},t'\right)\right]\right\rangle _{0}+\\
 & \qquad+\left(\frac{-\ii}{\hbar}\Theta\left(t-t'\right)\right)\left(\frac{-\hbar}{\ii}\right)\left\langle \frac{\ii}{\hbar}\left[\hat{H},\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right],\hat{\varrho}_{I}\left(-\vec{q},t'\right)\right\rangle _{0}
\end{align*}
Remember:
\begin{align*}
\hat{H} & =\hat{H}_{0}+\hat{V}_{ee}^{\text{jellium}}
\end{align*}
For the first commutator we obtain:
\begin{align*}
\left[\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma},\hat{\varrho}\left(-\vec{q}\right)\right] & =\sum_{\vec{k}',\sigma'}\left[\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma},\hat{c}_{\vec{k}',\sigma'}^{\dagger}\hat{c}_{\vec{k}'-\vec{q},\sigma'}\right]=\\
 & =\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k},\sigma}-\hat{c}_{\vec{k}+\vec{q},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}=\left(\hat{n}_{\vec{k},\sigma}-\hat{n}_{\vec{k}+\vec{q},\sigma}\right)
\end{align*}
\begin{align*}
\left[\hat{H}_{0},\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right] & =\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}
\end{align*}
\begin{align*}
\left[\hat{V}_{ee}^{\text{jellium}},\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right] & =-\frac{1}{2V}\sum_{\vec{k}',\vec{q}'\not=0,\sigma'}\tilde{v}_{ee}\left(q\right)\bigg(\hat{c}_{\vec{k}+\vec{q}',\sigma}^{\dagger}\hat{c}_{\vec{k}'-\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\hat{c}_{\vec{k}+\vec{q},\sigma}+\\
 & \qquad+\hat{c}_{\vec{k}'+\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}-\vec{q}',\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\hat{c}_{\vec{k}',\sigma'}-\hat{c}_{\vec{k}'+\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q}+\vec{q}',\sigma}\hat{c}_{\vec{k}',\sigma'}-\\
 & \qquad-\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}'-\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\hat{c}_{\vec{k}+\vec{q}-\vec{q}',\sigma}\bigg)
\end{align*}
This set of equations in general cannot be closed, because the nested
commutators generate operators, which contain each time a larger number
of $\hat{c}$ and $\hat{c}^{\dagger}$.

So truncation schemes are performed in the same spirit of the mean
field approximation. The idea is to keep only Hartree contributions,
as they are the most diverging ones. Hence we get:
\begin{align*}
 & \left[\hat{V}_{ee}^{\text{jellium}},\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right]\approx-\frac{1}{2V}\sum_{\vec{k}',\vec{q}'\not=0,\sigma'}\tilde{v}_{ee}\left(\vec{q}'\right)\bigg(\hat{c}_{\vec{k}+\vec{q}',\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\underbrace{\left\langle \hat{c}_{\vec{k}'-\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\right\rangle _{0}}_{=0}+\\
 & \qquad\qquad+\underbrace{\left\langle \hat{c}_{\vec{k}+\vec{q}',\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right\rangle _{0}}_{=\delta_{\vec{q},\vec{q}'}}\hat{c}_{\vec{k}'-\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}+\hat{c}_{\vec{k}'+\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\underbrace{\left\langle \hat{c}_{\vec{k}-\vec{q}',\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}\right\rangle _{0}}_{=\delta_{\vec{q},-\vec{q}'}}+\\
 & \qquad\qquad+\underbrace{\left\langle \hat{c}_{\vec{k}'+\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\right\rangle _{0}}_{=0}\hat{c}_{\vec{k}-\vec{q}',\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q},\sigma}-\hat{c}_{\vec{k}'+\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\underbrace{\left\langle \hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q}-\vec{q}',\sigma}\right\rangle _{0}}_{=\delta_{\vec{q},\vec{q}'}}-\\
 & \qquad\qquad-\underbrace{\left\langle \hat{c}_{\vec{k}'+\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\right\rangle }_{=0}\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q}-\vec{q}',\sigma}-\hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q}-\vec{q}',\sigma}\underbrace{\left\langle \hat{c}_{\vec{k}'-\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\right\rangle _{0}}_{=0}\\
 & \qquad\qquad-\underbrace{\left\langle \hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q}-\vec{q}',\sigma}\right\rangle _{0}}_{=\delta_{\vec{q},\vec{q}'}}\hat{c}_{\vec{k}'-\vec{q}',\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}+\text{const.}\bigg)=\\
 & \qquad=-\frac{1}{V}\tilde{v}_{ee}\left(\vec{q}'\right)\underbrace{\left(\sum_{\vec{k}',\sigma'}\hat{c}_{\vec{k}'-\vec{q},\sigma'}^{\dagger}\hat{c}_{\vec{k}',\sigma'}\right)}_{=\hat{\varrho}\left(\vec{q}\right)}\left(\left\langle \hat{n}_{\vec{k}+\vec{q},\sigma}\right\rangle -\left\langle \hat{n}_{\vec{k},\sigma}\right\rangle \right)
\end{align*}
This gives:
\begin{align*}
 & \ii\hbar\partial_{t}\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,t-t'\right)=\delta\left(t-t'\right)\left(\left\langle \hat{n}_{\vec{k},\sigma}\right\rangle -\left\langle \hat{n}_{\vec{k}+\vec{q},\sigma}\right\rangle \right)-\\
 & \qquad\qquad\qquad-\left(-\frac{\ii}{\hbar}\Theta\left(t-t'\right)\right)\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)\left\langle \hat{c}_{\vec{k},\sigma}^{\dagger}\hat{c}_{\vec{k}+\vec{q}}\left(t\right),\hat{\varrho}_{I}\left(-\vec{q},t'\right)\right\rangle _{0}-\\
 & \qquad\qquad\qquad-\left(\frac{-\ii}{\hbar}\Theta\left(t-t'\right)\right)\left(\left\langle \hat{n}_{\vec{k},\sigma}\right\rangle -\left\langle \hat{n}_{\vec{k}+\vec{q},\sigma}\right\rangle \right)\tilde{v}_{ee}\left(q\right)\frac{1}{V}\left\langle \left[\hat{\varrho}_{I}\left(\vec{q},t\right),\hat{\varrho}_{I}\left(-\vec{q},t\right)\right]\right\rangle 
\end{align*}
Hence follows:
\begin{align*}
\ii\hbar\partial_{t}\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,t-t'\right) & =\delta\left(t-t'\right)\left(f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)\right)-\\
 & \qquad-\left(\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,t-t'\right)-\\
 & \qquad-\left(f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)\right)\frac{\tilde{v}_{ee}\left(q\right)}{V}\sum_{\vec{k}',\sigma'}\tilde{\chi}\left(\vec{q},\vec{k}',\sigma',t-t'\right)
\end{align*}
Let us take the Fourier transformation:
\begin{align*}
\partial_{t} & \to-\ii\left(\omega+\ii\eta\right)\\
\text{FT}\left(\delta\left(t\right)\right) & =1
\end{align*}
\begin{align*}
\left(\hbar\omega+\ii\eta+\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,\omega\right) & =\frac{f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)}{1-\frac{\tilde{v}_{ee}\left(q\right)}{V}\sum_{\vec{k}',\sigma'}\tilde{\chi}\left(\vec{q},\vec{k}',\sigma',\omega\right)}
\end{align*}
Somewhere happen an error, because this should have a different sign:
\begin{align*}
\left(\hbar\omega+\ii\eta+\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}\right)\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,\omega\right) & =\frac{f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)}{1+\frac{\tilde{v}_{ee}\left(q\right)}{V}\sum_{\vec{k}',\sigma'}\tilde{\chi}\left(\vec{q},\vec{k}',\sigma',\omega\right)}
\end{align*}
\begin{align*}
\Rightarrow\qquad\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,\omega\right) & =\frac{f\left(\varepsilon_{\vec{k}}\right)-f\left(\varepsilon_{\vec{k}+\vec{q}}\right)}{\hbar\omega+\ii\eta+\varepsilon_{\vec{k}}-\varepsilon_{\vec{k}+\vec{q}}}\left(1-\frac{\tilde{v}_{ee}\left(q\right)}{V}\sum_{\vec{k}',\sigma'}\tilde{\chi}\left(\vec{q},\vec{k}',\sigma',\omega\right)\right)
\end{align*}
Remember:
\begin{align*}
\tilde{\chi}^{R}\left(\vec{q},\omega\right) & =\frac{e^{2}}{V}\sum_{\vec{k},\sigma}\tilde{\chi}^{R}\left(\vec{q},\vec{k},\sigma,\omega\right)
\end{align*}
\begin{align*}
\Rightarrow\qquad\tilde{\chi}^{R}\left(\vec{q},\omega\right) & =\tilde{\chi}_{0}\left(1-\tilde{u}_{ee}\left(q\right)\tilde{\chi}^{R}\left(\vec{q},\omega\right)\right)
\end{align*}
\begin{align*}
\Rightarrow\qquad\tilde{\chi}^{R}\left(\vec{q},\omega\right) & =\frac{\tilde{\chi}_{0}}{1+\tilde{u}_{ee}\left(q\right)\tilde{\chi}_{0}}=:\tilde{\chi}_{\text{RPA}}\left(\vec{q},\omega\right)
\end{align*}
\emph{Note}: $\tilde{\chi}_{\text{RPA}}$ is obtained from a Dyson
series:
\begin{align*}
\tilde{\chi}_{\text{RPA}} & =\tilde{\chi}_{0}+\tilde{\chi}_{0}\tilde{u}_{ee}\tilde{\chi}_{\text{RPA}}=\\
 & =\tilde{\chi}_{0}+\tilde{\chi}_{0}\tilde{u}_{ee}\tilde{\chi}_{0}+\tilde{\chi}_{0}\tilde{u}_{ee}\tilde{\chi}_{0}\tilde{u}_{ee}\tilde{\chi}_{\text{RPA}}=\ldots
\end{align*}
This tells us that also a diagrammatic solution would be possible.

\emph{Note}:
\begin{align*}
\widetilde{\varepsilon^{-1}}\left(\vec{q},\omega\right) & =1+\tilde{u}_{ee}\left(q\right)\tilde{\chi}_{\text{RPA}}\left(\vec{q},\omega\right)=1+\frac{\tilde{u}_{ee}\tilde{\chi}_{0}}{1-\tilde{u}_{ee}\left(q\right)\tilde{\chi}_{0}}=\frac{1}{1-\tilde{u}_{ee}\left(q\right)\tilde{\chi}_{0}\left(\vec{q},\omega\right)}
\end{align*}
We hence have screening. (cf. \noun{Flensberg}, section 9.3)
\begin{align*}
\lim_{\vec{q}\to0}\tilde{\chi}_{0}\left(\vec{q},\omega\right) & =-e^{2}\mathcal{D}\left(\varepsilon_{F}\right)
\end{align*}
\begin{align*}
\Rightarrow\qquad\widetilde{\varepsilon^{-1}} & =\frac{1}{1+\frac{e^{2}\mathcal{D}\left(\varepsilon_{F}\right)}{\varepsilon_{0}q^{2}}}=\frac{q^{2}}{q^{2}+k_{\text{TF}}^{2}}
\end{align*}
$\frac{2\pi}{k_{\text{TF}}}$ is the Thomas-Fermi wavelength.
\begin{align*}
k_{\text{TF}}^{2} & =\frac{e^{2}\mathcal{D}\left(\varepsilon_{F}\right)}{\varepsilon_{0}}
\end{align*}
So we get:
\begin{align*}
\tilde{u}_{ee}^{\text{RPA}} & =\widetilde{\varepsilon^{-1}}_{\text{RPA}}\tilde{u}_{ee}=\frac{1}{\varepsilon_{0}}\frac{1}{q^{2}+k_{\text{TF}}^{2}}
\end{align*}
In real space this gives:
\begin{align*}
u_{ee}^{\text{RPA}}\left(\vec{r}\right) & =\frac{e^{-rk_{\text{TF}}}}{r}
\end{align*}
So the Coulomb interaction is screened on a length $k_{\text{TF}}^{-1}$.

Besides electron-hole interactions, there are also plasmons.

\textcolor{green}{TODO: Abb47}

%DATE: Fr 01.02.13


\chapter{Phonons}

(see \noun{Bruus} and \noun{Flensberg}, chapter 3)

So far we have treated the ions as \emph{fixed} at the positions $\left\{ \vec{R}^{0}\right\} $
of the underlying lattice. In this chapter, we study the basic properties
of \emph{lattice vibrations}. Under the assumption that the ions perform
\emph{small oscillations} about their equilibrium positions, the set
of \emph{coupled equations} for the interacting ions can be diagonalized
yielding the so-called \emph{normal modes of vibrations}. We shall
see that we can represent each normal mode as a harmonic oscillator
with a given dispersion relation $\omega_{\lambda}\left(\vec{k}\right)$.
The quantized vibrations are denoted \emph{phonons}.

\emph{Note}: Phonons play a fundamental role in our understanding
of sound propagation, specific heat, elasticity and electrical resistivity
of solids. Moreover, the electron-phonon coupling is at the origin
of conventional superconductivity.


\section{Acoustic and optical phonons}

Let us consider the ionic part of the Hamiltonian of a solid:
\begin{align}
\hat{H}_{\text{ion}} & =\hat{T}_{\text{ion}}+\hat{V}_{ii}+\hat{V}_{ei}
\end{align}
Here we have:
\begin{align}
\hat{T}_{\text{ion}} & =\sum_{j=1}^{N_{\text{ion}}}\frac{\hat{p}_{j}^{2}}{2m} & \hat{V}_{ii} & =\frac{1}{2}\sum_{l\not=j}\hat{v}_{ii}\left(\vec{R_{l}}-\vec{R_{j}}\right)
\end{align}
We restrict the discussion here to a monoatomic Bravais lattice. Since
the atoms can move a little bit around the equilibrium position $\vec{R}_{j}^{\left(0\right)}$,
we write
\begin{align}
\vec{R_{j}} & =\vec{R_{j}}^{\left(0\right)}+\vec{u_{j}}\left(t\right)
\end{align}
with the displacement $\vec{u_{j}}\left(t\right)$ from the equilibrium
position.\\
The \emph{classical} equations of motion for the displacements read:
\begin{align*}
M\ddot{\vec{u_{j}}}\left(t\right) & =-\frac{\partial V_{ii}}{\partial\vec{u}_{j}}=-\sum_{l}\frac{\partial}{\partial\vec{u}_{j}}v_{ii}\left(\vec{R_{l}}-\vec{R_{j}}\right)
\end{align*}
In order to simplify this problem, we proceed in steps:
\begin{enumerate}[label=\roman*)]
\item We expand the ion-ion interaction up to second order in $\vec{u}$:
\begin{align}
V_{ii} & =\frac{1}{2}\sum_{l\not=j}v_{ii}\left(\vec{R_{l}}-\vec{R_{j}}\right)\approx V_{ii}^{\text{static}}+\frac{1}{2}\sum_{l\not=j}\left(\vec{u_{l}}-\vec{u_{j}}\right)\vec{\nabla}v_{ii}\left(\vec{R}_{l}-\vec{R}_{j}\right)\bigg|_{\vec{R_{l}}^{\left(0\right)},\vec{R_{j}}^{\left(0\right)}}+\nonumber \\
 & \qquad+\frac{1}{2}\sum_{l\not=j}\sum_{\mu,\nu\in\left\{ x,y,z\right\} }\left(\vec{u_{l}}-\vec{u_{j}}\right)_{\mu}\left(\vec{u_{l}}-\vec{u_{j}}\right)_{\nu}\frac{1}{2}\frac{\partial^{2}}{\left(\partial\vec{u_{l}}\right)_{\mu}\left(\partial\vec{u_{j}}\right)_{\nu}}v_{ii}\left(\vec{R_{l}}-\vec{R_{j}}\right)\bigg|_{\vec{R_{l}}^{\left(0\right)},\vec{R_{j}}^{\left(0\right)}}=\nonumber \\
 & \stackrel{\text{minimum}}{=}V_{ii}^{\text{static}}+\underbrace{\frac{1}{2}\sum_{l\not=j}\sum_{\mu,\nu}\left(\vec{u_{l}}\right)_{\mu}D_{\mu\nu}\left(\vec{R_{l}}^{\left(0\right)}-\vec{R}^{\left(0\right)}\right)\left(\vec{u_{j}}\right)_{\nu}}_{=\frac{1}{2}\sum_{l\not=j}\vec{u_{l}}\mat D\left(\vec{R_{l}}^{\left(0\right)}-\vec{R_{j}}^{\left(0\right)}\right)}
\end{align}
The linear term is zero, since the equilibrium positions are the places,
where the sum of the forces on an atom, $\vec{F_{j}}=\sum_{l\not=j}\vec{\nabla}v_{ii}\left(\vec{R_{l}}-\vec{R_{j}}\right)$,
vanishes.\\
The $D$-matrix has some important properties:

\begin{enumerate}[label=\alph*)]
\item Due to the interchangeability of the sequence of the derivative holds:
\begin{align*}
\mat D^{\TT}\left(\vec{R}^{\left(0\right)}\right) & =\mat D\left(\vec{R}^{\left(0\right)}\right)
\end{align*}

\item 
\begin{align*}
\sum_{\vec{R}^{\left(0\right)}}\mat D\left(\vec{R}^{\left(0\right)}\right) & =0
\end{align*}
This property follows from the fact, that $V_{ii}-V_{ii}^{\text{static}}=0$
if all the displacements are the same, given e.g. by a vector $\vec{d}$.
\begin{align*}
0 & =\sum_{ij}\vec{d}\mat D\left(\vec{R_{i}}^{\left(0\right)}-\vec{R_{j}}^{\left(0\right)}\right)\vec{d}
\end{align*}

\item From the reflection properties of the Bravais lattice follows:
\begin{align*}
\mat D\left(\vec{R}^{\left(0\right)}\right) & =\mat D\left(-\vec{R}^{\left(0\right)}\right)
\end{align*}

\end{enumerate}
\item We introduce now the \emph{dynamical matrix}:
\begin{align*}
D_{\mu\nu}\left(\vec{k}\right) & =\sum_{\vec{R}^{\left(0\right)}}D_{\mu\nu}\left(\vec{R}^{\left(0\right)}\right)e^{-\ii\vec{k}\cdot\vec{R}^{\left(0\right)}}
\end{align*}
Together with the properties a) - c) we find:
\begin{align*}
D_{\mu\nu}\left(\vec{k}\right) & =\frac{1}{2}\left(\sum_{\vec{R}^{\left(0\right)}}\mat D\left(\vec{R}^{\left(0\right)}\right)e^{-\ii\vec{k}\cdot\vec{R}^{\left(0\right)}}+\sum_{\vec{R}^{\left(0\right)}}\mat D\left(-\vec{R}^{\left(0\right)}\right)e^{+\ii\vec{k}\cdot\vec{R}^{\left(0\right)}}\right)=\\
 & \stackrel{\text{b), c)}}{=}\frac{1}{2}\sum_{\vec{R}^{\left(0\right)}}\mat D\left(\vec{R}^{\left(0\right)}\right)\left(e^{-\ii\vec{k}\cdot\vec{R}^{\left(0\right)}}+e^{+\ii\vec{k}\cdot\vec{R}^{\left(0\right)}}\right)
\end{align*}
And hence we get:
\begin{align}
\mat D\left(\vec{k}\right) & -2\sum_{\vec{R}^{\left(0\right)}}\mat D\left(\vec{R}^{\left(0\right)}\right)\sin^{2}\left(\frac{\vec{k}\cdot\vec{R}^{\left(0\right)}}{2}\right)
\end{align}
In other words, the matrix $\mat D\left(\vec{k}\right)$ is real and
symmetric and hence diagonalizable in an orthonormal basis.
\item Going back to the original coupled problem:
\begin{align}
M\ddot{\vec{u_{1}}} & =-\frac{\partial V_{ii}}{\partial\vec{u_{1}}} & \Rightarrow\qquad-M\ddot{\vec{u_{1}}} & =\sum_{l}\mat D\left(\vec{R_{l}}^{\left(0\right)}-\vec{R_{1}}^{\left(0\right)}\right)\vec{u_{l}}\label{eq:coupled-equations}
\end{align}
We look for harmonic solutions:
\begin{align*}
\vec{u_{1}}\left(t\right) & =\vec{\epsilon}e^{\ii\left(\vec{k}\cdot\vec{R}_{1}^{\left(0\right)}-\omega t\right)}
\end{align*}
Insertion in \eqref{eq:coupled-equations} yields:
\begin{align*}
M\omega^{2}\vec{\epsilon}e^{\ii\left(\vec{k}\cdot\vec{R}_{1}^{\left(0\right)}-\omega t\right)} & =\sum_{l}\mat D\left(\vec{R_{l}}^{\left(0\right)}-\vec{R_{1}}^{\left(0\right)}\right)\vec{\epsilon}e^{\ii\vec{k}\cdot\left(\vec{R_{l}}^{\left(0\right)}-\vec{R_{1}}^{\left(0\right)}\right)}e^{\ii\left(\vec{k}\cdot\vec{R_{1}}^{\left(0\right)}-\omega t\right)}
\end{align*}
Hence we get:
\begin{align}
\fbox{\ensuremath{{\displaystyle M\omega^{2}\vec{\epsilon}=\mat D\left(\vec{k}\right)\vec{\epsilon}}}}
\end{align}
Because $\mat D\left(\vec{k}\right)$ is real and symmetric, there
exist for any value of $\vec{k}$ an orthonormal basis set $\left\{ \vec{\epsilon_{k_{1}}},\vec{\epsilon_{k_{2}}},\vec{\epsilon_{k_{3}}}\right\} $
of vectors (polarization vectors), which diagonalizes $\mat D\left(\vec{k}\right)$.
In that basis holds:
\begin{align*}
\mat D\left(\vec{k}\right)\vec{\epsilon}_{\vec{k},\lambda} & =K_{\vec{k},\lambda}\vec{\epsilon}_{\vec{k},\lambda}
\end{align*}
$K_{\vec{k},\lambda}$ are the eigenvalues of $\mat D$ and $\vec{\epsilon}_{\vec{k},\lambda}\cdot\vec{\epsilon}_{\vec{k},\lambda'}=\delta_{\lambda\lambda'}$.
This in turn yields:
\begin{align*}
M\omega^{2}\vec{\epsilon}_{\vec{k},\lambda} & =K_{\vec{k},\lambda}\vec{\epsilon}_{\vec{k},\lambda}
\end{align*}
And so we get the normal mode frequencies:
\begin{align}
\fbox{\ensuremath{{\displaystyle \omega_{\lambda}\left(\vec{k}\right)=\sqrt{\frac{K_{\vec{k},\lambda}}{M}}}}}
\end{align}

\item We can also notice that the normal modes
\begin{align*}
\vec{U}_{\vec{k},\lambda}\left(\vec{R}^{\left(0\right)},t\right) & =\vec{\epsilon}_{\vec{k},\lambda}e^{\ii\left(\vec{k}\cdot\vec{R}^{\left(0\right)}-\omega_{\lambda}\left(\vec{k}\right)t\right)}
\end{align*}
satisfy the same equations as the harmonic oscillator. So they can
also be quantized.\\
How to quantize?\\
We introduce (bosonic) creation and annihilation operators, such that
the following holds:
\begin{align}
\begin{array}{c}
{\displaystyle \hat{\vec{U}}_{\vec{k},l}=l_{\vec{k},\lambda}\frac{1}{\sqrt{2}}\left(\hat{b}_{-\vec{k},\lambda}^{\dagger}+\hat{b}_{\vec{k},\lambda}\right)\vec{\epsilon}_{\vec{k},\lambda}}\ \ \ \\
{\displaystyle \hat{\vec{P}}_{\vec{k},l}=\frac{\hbar}{l_{\vec{k},\lambda}}\cdot\frac{\ii}{\sqrt{2}}\left(\hat{b}_{-\vec{k},\lambda}-\hat{b}_{\vec{k},\lambda}\right)\vec{\epsilon}_{\vec{k},\lambda}}
\end{array}\label{eq:U-P}
\end{align}
Here we introduced the oscillator length:
\begin{align*}
l_{\vec{k},\lambda} & =\sqrt{\frac{\hbar}{M\omega_{\lambda}\left(\vec{k}\right)}}
\end{align*}
Moreover it holds:
\begin{align*}
\left[\hat{b}_{\vec{k}_{1},\lambda_{1}},\hat{b}_{\vec{k}_{2},\lambda_{2}}\right] & =\delta_{\vec{k}_{1},\vec{k}_{2}}\delta_{\lambda_{1}\lambda_{2}}
\end{align*}
To find the Hamiltonian describing the lattice dynamics, we go back
to $\hat{H}_{\text{ion}}$ and look at:
\begin{align}
\hat{H}_{\text{ph}} & =\hat{T}_{\text{ion}}+\frac{1}{2}\sum_{i,j}\sum_{\mu,\nu}\left(\hat{\vec{U_{i}}}\right)_{\mu}D_{\mu\nu}\left(\hat{\vec{U_{j}}}\right)_{\nu}
\end{align}
Introducing now
\begin{align*}
\hat{\vec{P_{j}}} & =\frac{1}{\sqrt{N_{\text{ion}}}}\sum_{\vec{k}\in\text{1.BZ},\lambda}\hat{P}_{\vec{k},\lambda}e^{\ii\vec{k}\cdot\vec{R}_{j}^{\left(0\right)}}\\
\hat{\vec{U_{j}}} & =\frac{1}{\sqrt{N_{\text{ion}}}}\sum_{\vec{k}\in\text{1.BZ},\lambda}\hat{U}_{\vec{k},\lambda}e^{\ii\vec{k}\cdot\vec{R}_{j}^{\left(0\right)}}
\end{align*}
we find:
\begin{align}
\hat{H}_{\text{ph}} & =\frac{1}{2M}\sum_{\vec{k}}\sum_{\lambda,\lambda'}\hat{\vec{P}}_{\vec{k},\lambda}\cdot\hat{\vec{P}}_{-\vec{k},\lambda}+\frac{1}{2}\sum_{\vec{k},\lambda,\lambda'}\sum_{\mu,\nu}\left(\hat{\vec{U}}_{\vec{k},\lambda}\right)_{\mu}\cdot\underbrace{D_{\mu\nu}}_{=M\omega_{\lambda'}^{2}\left(-\vec{k}\right)}\cdot\left(\hat{\vec{U}}_{-\vec{k},\lambda'}\right)_{\nu}=\nonumber \\
 & \stackrel{\eqref{eq:U-P}}{=}\sum_{\vec{k}}\sum_{\lambda}\left(\hat{b}_{\vec{k},\lambda}^{\dagger}\hat{b}_{\vec{k},\lambda}+\frac{1}{2}\right)\hbar\omega_{\lambda}\left(\vec{k}\right)
\end{align}
It also means:
\begin{align*}
\hat{H}_{\text{ion}} & =\hat{T}_{\text{ion}}+\hat{V}_{ii}+\hat{V}_{ei}\sr{\approx}{\text{harmonic}}{\text{approximation}}\hat{V}_{ii}^{\text{static}}+\hat{H}_{\text{ph}}+\hat{V}_{ei}
\end{align*}
Then we can rewrite:
\begin{align*}
\hat{H} & =\hat{T}_{\text{ion}}+\hat{T}_{ee}+\hat{V}_{ee}+\underbrace{\hat{V}_{ii}}_{\approx\hat{V}_{ii}^{\text{static}}+\hat{V}_{ii}^{\text{harmonic}}}+\underbrace{\hat{V}_{ei}}_{=\hat{V}_{ei}^{\text{static}}+\hat{V}_{e\text{-ph}}}=\\
 & =\underbrace{\hat{T}_{\text{el}}+\hat{V}_{ee}+\hat{V}_{ei}^{\text{static}}+\hat{V}_{ii}^{\text{static}}}_{=\hat{H}_{\text{el}}}+\hat{H}_{\text{ph}}+\underbrace{\hat{V}_{ei}^{\text{dynamic}}}_{=\hat{V}_{e\text{-ph}}}+o_{0}\left(u^{2}\right)
\end{align*}
I.e. we are coupling dynamically electrons and ions via the electron-phonon
interaction (neglected in the Born-Oppenheimer approximation). Here
we have expanded in small displacements $\vec{u}_{\alpha}$ of the
ions around the equilibrium position $\vec{R}_{\alpha}^{0}$ with
$\vec{R}_{\alpha}=\vec{R}_{\alpha}^{0}+\vec{u}_{\alpha}$.\\
\emph{Note}: From
\begin{align*}
\mat D\left(\vec{k}\right) & =-2\sum_{\vec{R}^{\left(0\right)}}\mat D\left(\vec{R}^{\left(0\right)}\right)\sin^{2}\left(\frac{\vec{k}\cdot\vec{R}^{\left(0\right)}}{2}\right)
\end{align*}
it follows for $\vec{k}\approx0$:
\begin{align*}
\mat D\left(\vec{k}\right) & \sim k^{2}
\end{align*}
\begin{align*}
\fbox{\ensuremath{{\displaystyle \omega_{\lambda}\left(\vec{k}\right)=c_{\lambda}\left(\theta_{\vec{k}},\varphi_{\vec{k}}\right)k}}}
\end{align*}
This is typical of acoustic phonons.
\end{enumerate}
%DATE: Fr 8.2.13


\section{Electron-phonon interaction}

Let us remember
\begin{align*}
\hat{V}_{ei} & =-\sum_{j,\alpha}\frac{Ze^{2}}{\norm{\vec{R}_{\alpha}-\vec{r}_{j}}}
\end{align*}
with the electron density:
\begin{align*}
\hat{\varrho}_{\text{el}}\left(\vec{r}\right) & =\sum_{j=1}^{N_{\text{el}}}\delta\left(\vec{r}-\vec{r}_{j}\right)
\end{align*}
So we can write:
\begin{align*}
\hat{V}_{ei} & =\int\dd^{3}r\hat{\varrho}_{\text{el}}\left(\vec{r}\right)\left(-\sum_{\alpha=1}^{N_{\text{ion}}}\frac{Ze^{2}}{\norm{\vec{R}_{\alpha}-\vec{r}}}\right)=\\
 & =\int\dd^{3}r\hat{\varrho}_{\text{el}}\left(\vec{r}\right)\sum_{\alpha=1}^{N_{\text{ion}}}v_{ei}\left(\vec{r}-\vec{R}_{\alpha}\right)
\end{align*}
We again expand in $\vec{u}_{\alpha}$ to first order:
\begin{align*}
v_{ei}\left(\vec{r}-\vec{R}_{\alpha}\right) & \approx\underbrace{v_{ei}\left(\vec{r}-\vec{R}_{\alpha}^{0}\right)}_{\text{static contribution}}-\underbrace{\vec{\nabla}_{\vec{r}}v_{ei}\left(\vec{r}-\vec{R}_{\alpha}^{0}\right)\vec{u}_{\alpha}}_{\text{electron-phonon contribution}}
\end{align*}
This gives
\begin{align*}
\hat{V}_{ei} & =\hat{V}_{ei}^{\text{static}}+\hat{V}_{e\text{-ph}}
\end{align*}
with:
\begin{align*}
\fbox{\ensuremath{{\displaystyle \hat{V}_{e\text{-ph}}=\int\dd^{3}r\varrho_{\text{el}}\left(\vec{r}\right)\sum_{\alpha=1}^{N_{\text{ion}}}\vec{\nabla}_{\vec{r}}v_{ei}\left(\vec{r}-\vec{R}_{\alpha}^{0}\right)\hat{\vec{u}}_{\alpha}}}}
\end{align*}
Remembering now
\begin{align*}
\hat{\vec{u}}_{\alpha} & =\frac{1}{\sqrt{N_{\text{cell}}}}\sum_{\vec{k}\in\text{1.BZ}}\sum_{\lambda}l_{\vec{k},\lambda}\frac{1}{\sqrt{2}}\left(\hat{b}_{-\vec{k},\lambda}^{\dagger}+\hat{b}_{\vec{k},\lambda}\right)\vec{\epsilon}_{\vec{k},\lambda}e^{\ii\vec{k}\cdot\vec{R}_{\alpha}^{0}}
\end{align*}
and (for electrons moving in a periodic potential)
\begin{align*}
\hat{\varrho}_{\text{el}}\left(\vec{r}\right) & =\frac{1}{V}\sum_{\vec{k},\vec{p},\sigma,n}e^{-\ii\vec{p}\cdot\vec{r}}\hat{c}_{\vec{k}+\vec{p},n,\sigma}^{\dagger}\hat{c}_{\vec{k},n,\sigma}
\end{align*}
with the band index $n$, we get:
\begin{align*}
\hat{V}_{e\text{-ph}} & =\sum_{\vec{k},\sigma,n}\sum_{\vec{p},\lambda}g_{\lambda}\left(\vec{p}\right)\hat{c}_{\vec{k}+\vec{p},n,\sigma}^{\dagger}\hat{c}_{\vec{k},n,\sigma}\left(\hat{b}_{-\vec{p},\lambda}^{\dagger}+\hat{b}_{\vec{p},\lambda}\right)
\end{align*}


\textcolor{green}{TODO: Abb48}

It can yield effective electron-electron interaction.


\part*{Appendix\thispagestyle{empty}}

\addcontentsline{toc}{part}{Appendix}

\fancyhead[R]{Index}
\fancyhead[C]{\qquad \qquad \qquad Appendix}


\chapter*{Acknowledgements}

\addcontentsline{toc}{section}{\hspace*{2.7em}Acknowledgements}

\fancyhead[R]{Acknowledgements}

My special thanks goes to Professor Grifoni, who gave this lecture
and allowed me to publish this script of the lecture.

I would also like to thank all those, who found errors by careful
reading and told me of them.

\vspace{1cm}


\hfill{}Andreas Völklein

\label{END}
\end{document}
